import type { Env } from '../env.js';
import { updateSessionStatus, updateSessionMetrics, addActiveSeconds, updateSessionGitState, upsertSessionFileChanged, updateSessionTitle, createSession, createSessionGitState, getSession, getSessionGitState, getOAuthToken, getChildSessions, getSessionChannelBindings, listUserChannelBindings, listOrchestratorMemories, createOrchestratorMemory, deleteOrchestratorMemory, boostMemoryRelevance, listOrgRepositories, listPersonas, getUserById, createMailboxMessage, getSessionMailbox, markSessionMailboxRead, getOrchestratorIdentityByHandle, createSessionTask, getSessionTasks, getMyTasks, updateSessionTask, getUserTelegramToken, getOrgSettings, enqueueWorkflowApprovalNotificationIfMissing, markWorkflowApprovalNotificationsRead, isNotificationWebEnabled } from '../lib/db.js';
import { decryptString } from '../lib/crypto.js';
import { checkWorkflowConcurrency, createWorkflowSession, dispatchOrchestratorPrompt, enqueueWorkflowExecution, sha256Hex } from '../lib/workflow-runtime.js';
import { sendTelegramMessage, sendTelegramPhoto } from '../routes/telegram.js';
import { validateWorkflowDefinition } from '../lib/workflow-definition.js';

// ─── WebSocket Message Types ───────────────────────────────────────────────

interface PromptAttachment {
  type: 'file';
  mime: string;
  url: string;
  filename?: string;
}

interface WorkflowExecutionDispatchPayload {
  kind: 'run' | 'resume';
  executionId: string;
  workflowHash?: string;
  resumeToken?: string;
  decision?: 'approve' | 'deny';
  payload: Record<string, unknown>;
}

const MAX_PROMPT_ATTACHMENTS = 8;
const MAX_PROMPT_ATTACHMENT_URL_LENGTH = 12_000_000;

function parseBase64DataUrl(url: string): string | null {
  const commaIndex = url.indexOf(',');
  if (commaIndex === -1) return null;
  const data = url.slice(commaIndex + 1).replace(/\s+/g, '');
  return data.length > 0 ? data : null;
}

function sanitizePromptAttachments(input: unknown): PromptAttachment[] {
  if (!Array.isArray(input)) return [];
  const result: PromptAttachment[] = [];

  for (const item of input) {
    if (!item || typeof item !== 'object') continue;
    const record = item as Record<string, unknown>;
    if (record.type !== 'file') continue;
    if (typeof record.mime !== 'string' || typeof record.url !== 'string') continue;

    const mime = record.mime.trim().toLowerCase();
    const url = record.url.trim();
    if (!mime.startsWith('image/') && !mime.startsWith('audio/')) continue;
    if (!url.startsWith('data:') || !url.includes(';base64,')) continue;
    if (url.length > MAX_PROMPT_ATTACHMENT_URL_LENGTH) continue;

    const filename = typeof record.filename === 'string' ? record.filename.slice(0, 255) : undefined;
    result.push({ type: 'file', mime, url, filename });
    if (result.length >= MAX_PROMPT_ATTACHMENTS) break;
  }

  return result;
}

function attachmentPartsForMessage(attachments: PromptAttachment[]): Array<Record<string, unknown>> {
  const parts: Array<Record<string, unknown>> = [];
  for (const attachment of attachments) {
    const data = parseBase64DataUrl(attachment.url);
    if (!data) continue;

    if (attachment.mime.startsWith('image/')) {
      parts.push({
        type: 'image',
        data,
        mimeType: attachment.mime,
        ...(attachment.filename ? { filename: attachment.filename } : {}),
      });
    } else if (attachment.mime.startsWith('audio/')) {
      parts.push({
        type: 'audio',
        data,
        mimeType: attachment.mime,
        ...(attachment.filename ? { filename: attachment.filename } : {}),
      });
    }
  }
  return parts;
}

function parseQueuedPromptAttachments(raw: unknown): PromptAttachment[] {
  if (typeof raw !== 'string' || !raw) return [];
  try {
    return sanitizePromptAttachments(JSON.parse(raw));
  } catch {
    return [];
  }
}

function parseQueuedWorkflowPayload(raw: unknown): WorkflowExecutionDispatchPayload | null {
  if (typeof raw !== 'string' || !raw) return null;
  try {
    const parsed = JSON.parse(raw) as WorkflowExecutionDispatchPayload;
    if (!parsed || typeof parsed !== 'object') return null;
    if (parsed.kind !== 'run' && parsed.kind !== 'resume') return null;
    if (typeof parsed.executionId !== 'string' || !parsed.executionId) return null;
    if (!parsed.payload || typeof parsed.payload !== 'object' || Array.isArray(parsed.payload)) return null;
    return parsed;
  } catch {
    return null;
  }
}

/** Messages sent by browser clients to the DO */
interface ClientMessage {
  type: 'prompt' | 'answer' | 'ping' | 'abort' | 'revert' | 'diff' | 'review' | 'command';
  content?: string;
  model?: string;
  queueMode?: 'followup' | 'collect' | 'steer';
  attachments?: PromptAttachment[];
  questionId?: string;
  answer?: string | boolean;
  messageId?: string;
  requestId?: string;
  command?: string;
  args?: string;
  channelType?: string;
  channelId?: string;
}

/** Agent status values for activity indication */
type AgentStatus = 'idle' | 'thinking' | 'tool_calling' | 'streaming' | 'error';
type SessionLifecycleStatus = 'initializing' | 'running' | 'idle' | 'hibernating' | 'hibernated' | 'restoring' | 'terminated' | 'archived' | 'error';
type SandboxRuntimeState = 'starting' | 'running' | 'hibernating' | 'hibernated' | 'restoring' | 'stopped' | 'error';
type AgentRuntimeState = 'starting' | 'busy' | 'idle' | 'queued' | 'sleeping' | 'standby' | 'stopped' | 'error';
type JointRuntimeState = 'starting' | 'running_busy' | 'running_idle' | 'queued' | 'waking' | 'sleeping' | 'standby' | 'stopped' | 'error';

function deriveRuntimeStates(args: {
  lifecycleStatus: string;
  sandboxId?: string | null;
  runnerConnected: boolean;
  runnerBusy: boolean;
  queuedPrompts: number;
}): {
  sandboxState: SandboxRuntimeState;
  agentState: AgentRuntimeState;
  jointState: JointRuntimeState;
} {
  const lifecycle = args.lifecycleStatus as SessionLifecycleStatus;
  const hasSandbox = !!args.sandboxId;
  const hasQueue = args.queuedPrompts > 0;

  const sandboxState: SandboxRuntimeState = (() => {
    if (lifecycle === 'error') return 'error';
    if (lifecycle === 'terminated' || lifecycle === 'archived') return 'stopped';
    if (lifecycle === 'hibernating') return 'hibernating';
    if (lifecycle === 'hibernated') return 'hibernated';
    if (lifecycle === 'restoring') return 'restoring';
    if (lifecycle === 'initializing') return 'starting';
    if (hasSandbox) return 'running';
    if (hasQueue) return 'restoring';
    return 'stopped';
  })();

  const agentState: AgentRuntimeState = (() => {
    if (lifecycle === 'error') return 'error';
    if (lifecycle === 'terminated' || lifecycle === 'archived') return 'stopped';
    if (lifecycle === 'hibernating' || lifecycle === 'hibernated') return 'sleeping';
    if (lifecycle === 'initializing' || lifecycle === 'restoring') {
      return hasQueue ? 'queued' : 'starting';
    }
    if (hasQueue && !args.runnerConnected) return 'queued';
    if (args.runnerConnected && args.runnerBusy) return 'busy';
    if (hasQueue) return 'queued';
    if (hasSandbox && args.runnerConnected) return 'idle';
    if (hasSandbox && !args.runnerConnected) return 'standby';
    return 'standby';
  })();

  const jointState: JointRuntimeState = (() => {
    if (agentState === 'error') return 'error';
    if (agentState === 'stopped') return 'stopped';
    if (agentState === 'sleeping') return 'sleeping';
    if (sandboxState === 'starting') return 'starting';
    if (sandboxState === 'restoring') return hasQueue ? 'waking' : 'starting';
    if (agentState === 'busy') return 'running_busy';
    if (agentState === 'idle') return 'running_idle';
    if (agentState === 'queued') return hasSandbox ? 'queued' : 'waking';
    if (agentState === 'standby') return 'standby';
    return 'starting';
  })();

  return { sandboxState, agentState, jointState };
}

/** Messages sent by the runner to the DO */
/** Tool call status values */
type ToolCallStatus = 'pending' | 'running' | 'completed' | 'error';

interface RunnerMessage {
  type: 'stream' | 'result' | 'tool' | 'question' | 'screenshot' | 'error' | 'complete' | 'agentStatus' | 'create-pr' | 'update-pr' | 'list-pull-requests' | 'inspect-pull-request' | 'models' | 'aborted' | 'reverted' | 'diff' | 'review-result' | 'command-result' | 'ping' | 'git-state' | 'pr-created' | 'files-changed' | 'child-session' | 'title' | 'spawn-child' | 'session-message' | 'session-messages' | 'terminate-child' | 'self-terminate' | 'memory-read' | 'memory-write' | 'memory-delete' | 'list-repos' | 'list-personas' | 'list-channels' | 'get-session-status' | 'list-child-sessions' | 'forward-messages' | 'read-repo-file' | 'workflow-list' | 'workflow-sync' | 'workflow-run' | 'workflow-executions' | 'workflow-api' | 'trigger-api' | 'execution-api' | 'workflow-execution-result' | 'workflow-chat-message' | 'model-switched' | 'tunnels' | 'mailbox-send' | 'mailbox-check' | 'task-create' | 'task-list' | 'task-update' | 'task-my' | 'channel-reply' | 'audio-transcript' | 'channel-session-created' | 'session-reset';
  transcript?: string;
  prNumber?: number;
  targetSessionId?: string;
  interrupt?: boolean;
  limit?: number;
  after?: string;
  task?: string;
  workspace?: string;
  repoUrl?: string;
  messageId?: string;
  content?: string;
  questionId?: string;
  text?: string;
  options?: string[];
  callID?: string;
  toolName?: string;
  args?: unknown;
  result?: unknown;
  data?: string | { files?: { path: string; status: string; diff?: string }[] } | Record<string, unknown>; // base64 screenshot, diff payload, or review result
  description?: string;
  error?: string;
  status?: AgentStatus | ToolCallStatus;
  detail?: string;
  branch?: string;
  name?: string;
  title?: string;
  body?: string;
  base?: string;
  models?: { provider: string; models: { id: string; name: string }[] }[];
  requestId?: string;
  id?: string;
  messageIds?: string[];
  files?: { path: string; status: string; diff?: string }[];
  number?: number;
  url?: string;
  baseBranch?: string;
  commitCount?: number;
  sourceType?: string;
  sourcePrNumber?: number;
  sourceIssueNumber?: number;
  sourceRepoFullName?: string;
  labels?: string[];
  state?: string;
  owner?: string;
  repo?: string;
  filesLimit?: number;
  commentsLimit?: number;
  childSessionId?: string;
  diffFiles?: unknown;
  // Orchestrator memory fields
  category?: string;
  query?: string;
  memoryId?: string;
  relevance?: number;
  source?: string;
  // Model failover fields
  fromModel?: string;
  toModel?: string;
  reason?: string;
  model?: string;
  path?: string;
  ref?: string;
  executionId?: string;
  workflowId?: string;
  slug?: string;
  version?: string;
  dataJson?: Record<string, unknown>;
  variables?: Record<string, unknown>;
  action?: string;
  payload?: Record<string, unknown>;
  envelope?: {
    ok?: boolean;
    status?: 'ok' | 'needs_approval' | 'cancelled' | 'failed';
    executionId?: string;
    output?: Record<string, unknown>;
    steps?: Array<{
      stepId: string;
      status: string;
      attempt?: number;
      input?: unknown;
      output?: unknown;
      error?: string;
      startedAt?: string;
      completedAt?: string;
    }>;
    requiresApproval?: {
      stepId: string;
      prompt: string;
      items: unknown[];
      resumeToken: string;
    } | null;
    error?: string | null;
  };
  tunnels?: Array<{ name: string; port: number; protocol?: string; path: string }>;
  // Phase C: Mailbox + Task Board fields
  toSessionId?: string;
  toUserId?: string;
  toHandle?: string;
  messageType?: string;
  contextSessionId?: string;
  contextTaskId?: string;
  replyToId?: string;
  taskId?: string;
  sessionId?: string;
  parentTaskId?: string;
  blockedBy?: string[];
  // Phase D: Channel Reply fields
  channelType?: string;
  channelId?: string;
  message?: string;
  imageBase64?: string;
  imageMimeType?: string;
  followUp?: boolean;
  // Per-channel session tracking
  channelKey?: string;
  opencodeSessionId?: string;
  role?: 'user' | 'assistant' | 'system';
  parts?: Record<string, unknown>;
}

/** Messages sent from DO to clients */
interface ClientOutbound {
  type: 'message' | 'message.updated' | 'messages.removed' | 'stream' | 'chunk' | 'question' | 'status' | 'pong' | 'error' | 'user.joined' | 'user.left' | 'agentStatus' | 'models' | 'diff' | 'review-result' | 'command-result' | 'git-state' | 'pr-created' | 'files-changed' | 'child-session' | 'title' | 'audit_log' | 'model-switched' | 'toast';
  [key: string]: unknown;
}

/** Messages sent from DO to runner */
interface RunnerOutbound {
  type: 'prompt' | 'answer' | 'stop' | 'abort' | 'revert' | 'diff' | 'review' | 'opencode-command' | 'pong' | 'init' | 'spawn-child-result' | 'session-message-result' | 'session-messages-result' | 'create-pr-result' | 'update-pr-result' | 'list-pull-requests-result' | 'inspect-pull-request-result' | 'terminate-child-result' | 'memory-read-result' | 'memory-write-result' | 'memory-delete-result' | 'list-repos-result' | 'list-personas-result' | 'list-channels-result' | 'get-session-status-result' | 'list-child-sessions-result' | 'forward-messages-result' | 'read-repo-file-result' | 'workflow-list-result' | 'workflow-sync-result' | 'workflow-run-result' | 'workflow-executions-result' | 'workflow-api-result' | 'trigger-api-result' | 'execution-api-result' | 'workflow-execute' | 'tunnel-delete' | 'channel-reply-result';
  command?: string;
  messageId?: string;
  content?: string;
  model?: string;
  attachments?: PromptAttachment[];
  questionId?: string;
  answer?: string | boolean;
  requestId?: string;
  childSessionId?: string;
  success?: boolean;
  error?: string;
  messages?: Array<{ role: string; content: string; createdAt: string }>;
  number?: number;
  url?: string;
  title?: string;
  state?: string;
  // Author attribution (multiplayer)
  authorId?: string;
  authorEmail?: string;
  authorName?: string;
  gitName?: string;
  gitEmail?: string;
  // Channel metadata
  channelType?: string;
  channelId?: string;
  opencodeSessionId?: string;
  // Orchestrator result fields
  memories?: unknown[];
  memory?: unknown;
  repos?: unknown[];
  personas?: unknown[];
  channels?: unknown[];
  sessionStatus?: unknown;
  pulls?: unknown[];
  data?: unknown;
  // Forward messages result
  count?: number;
  sourceSessionId?: string;
  workflows?: unknown[];
  workflow?: unknown;
  execution?: unknown;
  executions?: unknown[];
  steps?: unknown[];
  executionId?: string;
  payload?: WorkflowExecutionDispatchPayload;
  // Model failover
  modelPreferences?: string[];
  encoding?: string;
  truncated?: boolean;
  path?: string;
  repo?: string;
  ref?: string;
  name?: string;
  actorId?: string;
  actorName?: string;
  actorEmail?: string;
}

// ─── Durable SQLite Table Schemas ──────────────────────────────────────────

const SCHEMA_SQL = `
  CREATE TABLE IF NOT EXISTS messages (
    id TEXT PRIMARY KEY,
    role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system', 'tool')),
    content TEXT NOT NULL,
    parts TEXT, -- JSON array of structured parts (tool calls, etc.)
    author_id TEXT,
    author_email TEXT,
    author_name TEXT,
    author_avatar_url TEXT,
    channel_type TEXT,
    channel_id TEXT,
    opencode_session_id TEXT,
    created_at INTEGER NOT NULL DEFAULT (unixepoch())
  );

  CREATE TABLE IF NOT EXISTS questions (
    id TEXT PRIMARY KEY,
    text TEXT NOT NULL,
    options TEXT, -- JSON array of option strings
    status TEXT NOT NULL DEFAULT 'pending' CHECK(status IN ('pending', 'answered', 'expired')),
    answer TEXT,
    created_at INTEGER NOT NULL DEFAULT (unixepoch()),
    expires_at INTEGER -- unix timestamp, NULL means no timeout
  );

  CREATE TABLE IF NOT EXISTS prompt_queue (
    id TEXT PRIMARY KEY,
    content TEXT NOT NULL,
    attachments TEXT, -- JSON array of prompt attachments
    model TEXT, -- user-selected model override
    queue_type TEXT NOT NULL DEFAULT 'prompt' CHECK(queue_type IN ('prompt', 'workflow_execute')),
    workflow_execution_id TEXT,
    workflow_payload TEXT,
    status TEXT NOT NULL DEFAULT 'queued' CHECK(status IN ('queued', 'processing', 'completed')),
    author_id TEXT,
    author_email TEXT,
    author_name TEXT,
    author_avatar_url TEXT,
    channel_type TEXT,
    channel_id TEXT,
    channel_key TEXT, -- computed key for per-channel queuing (e.g. "web:default", "telegram:12345")
    created_at INTEGER NOT NULL DEFAULT (unixepoch())
  );

  CREATE TABLE IF NOT EXISTS state (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL
  );

  CREATE TABLE IF NOT EXISTS connected_users (
    user_id TEXT PRIMARY KEY,
    connected_at INTEGER NOT NULL DEFAULT (unixepoch())
  );

  CREATE TABLE IF NOT EXISTS audit_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    event_type TEXT NOT NULL,
    summary TEXT NOT NULL,
    actor_id TEXT,
    metadata TEXT,
    created_at TEXT NOT NULL DEFAULT (datetime('now')),
    flushed INTEGER NOT NULL DEFAULT 0
  );

  CREATE TABLE IF NOT EXISTS channel_followups (
    id TEXT PRIMARY KEY,
    channel_type TEXT NOT NULL,
    channel_id TEXT NOT NULL,
    original_content TEXT,
    created_at INTEGER NOT NULL,
    next_reminder_at INTEGER NOT NULL,
    reminder_count INTEGER DEFAULT 0,
    status TEXT DEFAULT 'pending' CHECK(status IN ('pending', 'resolved'))
  );

  CREATE TABLE IF NOT EXISTS channel_state (
    channel_key TEXT PRIMARY KEY,
    busy INTEGER NOT NULL DEFAULT 0,
    opencode_session_id TEXT
  );
`;

// ─── SessionAgentDO ────────────────────────────────────────────────────────

interface CachedUserDetails {
  id: string;
  email: string;
  name?: string;
  avatarUrl?: string;
  gitName?: string;
  gitEmail?: string;
  modelPreferences?: string[];
}

export class SessionAgentDO {
  private ctx: DurableObjectState;
  private env: Env;
  private initialized = false;
  private userDetailsCache = new Map<string, CachedUserDetails>();

  // ─── Auto Channel Reply Tracking ─────────────────────────────────────
  // When a prompt arrives from an external channel (e.g. Telegram), we track
  // the channel context so we can auto-send the agent's response back to it.
  // If the agent explicitly calls channel_reply for that channel, we mark it
  // handled so we don't double-send.
  private pendingChannelReply: {
    channelType: string;
    channelId: string;
    resultContent: string | null;
    resultMessageId: string | null;
    handled: boolean;
  } | null = null;

  /** Returns the channel metadata for the currently active prompt, if any. */
  private get activeChannel(): { channelType: string; channelId: string } | null {
    return this.pendingChannelReply
      ? { channelType: this.pendingChannelReply.channelType, channelId: this.pendingChannelReply.channelId }
      : null;
  }

  constructor(ctx: DurableObjectState, env: Env) {
    this.ctx = ctx;
    this.env = env;

    // Run schema migration on construction (blockConcurrencyWhile ensures it completes before any request)
    this.ctx.blockConcurrencyWhile(async () => {
      this.ctx.storage.sql.exec(SCHEMA_SQL);

      // Migrate existing DOs: add author_avatar_url columns if missing
      try { this.ctx.storage.sql.exec('ALTER TABLE messages ADD COLUMN author_avatar_url TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN author_avatar_url TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN attachments TEXT'); } catch { /* already exists */ }

      // Migrate existing DOs: add channel metadata columns
      try { this.ctx.storage.sql.exec('ALTER TABLE messages ADD COLUMN channel_type TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE messages ADD COLUMN channel_id TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN channel_type TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN channel_id TEXT'); } catch { /* already exists */ }

      // Migrate existing DOs: add per-channel session tracking columns
      try { this.ctx.storage.sql.exec('ALTER TABLE messages ADD COLUMN opencode_session_id TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN channel_key TEXT'); } catch { /* already exists */ }

      // Migrate existing DOs: add model column to prompt_queue
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN model TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec("ALTER TABLE prompt_queue ADD COLUMN queue_type TEXT NOT NULL DEFAULT 'prompt'"); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN workflow_execution_id TEXT'); } catch { /* already exists */ }
      try { this.ctx.storage.sql.exec('ALTER TABLE prompt_queue ADD COLUMN workflow_payload TEXT'); } catch { /* already exists */ }
      this.ctx.storage.sql.exec("UPDATE prompt_queue SET queue_type = 'prompt' WHERE queue_type IS NULL OR queue_type = ''");

      this.initialized = true;
    });
  }

  private async getUserDetails(userId: string): Promise<CachedUserDetails | undefined> {
    const cached = this.userDetailsCache.get(userId);
    if (cached) return cached;

    try {
      const userRow = await getUserById(this.env.DB, userId);
      if (!userRow) return undefined;
      const details: CachedUserDetails = {
        id: userRow.id,
        email: userRow.email,
        name: userRow.name,
        avatarUrl: userRow.avatarUrl,
        gitName: userRow.gitName,
        gitEmail: userRow.gitEmail,
        modelPreferences: userRow.modelPreferences,
      };
      this.userDetailsCache.set(userId, details);
      return details;
    } catch (err) {
      console.error('[SessionAgentDO] Failed to fetch user details:', err);
      return undefined;
    }
  }

  /**
   * Resolve model preferences: user prefs if set, otherwise org prefs as fallback.
   */
  private async resolveModelPreferences(ownerDetails?: CachedUserDetails): Promise<string[] | undefined> {
    if (ownerDetails?.modelPreferences && ownerDetails.modelPreferences.length > 0) {
      return ownerDetails.modelPreferences;
    }
    try {
      const orgSettings = await getOrgSettings(this.env.DB);
      return orgSettings.modelPreferences;
    } catch (err) {
      console.error('[SessionAgentDO] Failed to fetch org settings for model preferences:', err);
      return undefined;
    }
  }

  // ─── Entry Point ───────────────────────────────────────────────────────

  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);

    // WebSocket upgrade
    if (request.headers.get('Upgrade') === 'websocket') {
      return this.handleWebSocketUpgrade(request, url);
    }

    // Internal control endpoints
    switch (url.pathname) {
      case '/start':
        return this.handleStart(request);
      case '/stop': {
        let reason: string | undefined;
        if (request.method === 'POST') {
          try {
            const body = await request.json() as { reason?: string };
            if (body?.reason) reason = body.reason;
          } catch {
            // ignore missing/invalid body
          }
        }
        return this.handleStop(reason);
      }
      case '/status':
        return this.handleStatus();
      case '/wake':
        return this.handleWake();
      case '/hibernate':
        return this.handleHibernate();
      case '/clear-queue':
        return this.handleClearQueue();
      case '/flush-metrics':
        return this.handleFlushMetrics();
      case '/messages':
        return this.handleMessagesEndpoint(url);
      case '/gc':
        return this.handleGarbageCollect();
      case '/webhook-update':
        return this.handleWebhookUpdate(request);
      case '/models': {
        const raw = this.getStateValue('availableModels');
        const models = raw ? JSON.parse(raw) : [];
        return Response.json({ models });
      }
      case '/queue-mode': {
        const body = await request.json() as { queueMode: string; collectDebounceMs?: number };
        this.setStateValue('queueMode', body.queueMode);
        if (body.collectDebounceMs !== undefined) {
          this.setStateValue('collectDebounceMs', String(body.collectDebounceMs));
        }
        return Response.json({ success: true });
      }
      case '/prompt': {
        // HTTP-based prompt submission (alternative to WebSocket)
        const body = await request.json() as { content?: string; model?: string; attachments?: PromptAttachment[]; interrupt?: boolean; queueMode?: string; channelType?: string; channelId?: string; authorName?: string; authorEmail?: string; authorId?: string };
        const content = body.content ?? '';
        const attachments = sanitizePromptAttachments(body.attachments);
        if (!content && attachments.length === 0) {
          return new Response(JSON.stringify({ error: 'Missing content or attachments' }), { status: 400 });
        }
        // Route prompts through the selected queue mode. If none is provided,
        // fall back to the DO's configured default.
        const effectiveMode = body.interrupt ? 'steer' : (body.queueMode || this.getStateValue('queueMode') || 'followup');

        const author = (body.authorId || body.authorEmail) ? {
          id: body.authorId || '',
          email: body.authorEmail || '',
          name: body.authorName,
        } : undefined;

        switch (effectiveMode) {
          case 'steer':
            await this.handleInterruptPrompt(content, body.model, author, attachments, body.channelType, body.channelId);
            break;
          case 'collect':
            await this.handleCollectPrompt(content, body.model, author, attachments, body.channelType, body.channelId);
            break;
          default:
            await this.handlePrompt(content, body.model, author, attachments, body.channelType, body.channelId);
            break;
        }
        return Response.json({ success: true });
      }
      case '/system-message': {
        const body = await request.json() as { content: string; parts?: Record<string, unknown>; wake?: boolean };
        if (!body.content) {
          return new Response(JSON.stringify({ error: 'Missing content' }), { status: 400 });
        }
        await this.handleSystemMessage(body.content, body.parts, body.wake);
        return Response.json({ success: true });
      }
      case '/workflow-execute': {
        if (request.method !== 'POST') {
          return new Response(JSON.stringify({ error: 'Method not allowed' }), { status: 405 });
        }
        const body = await request.json() as {
          executionId?: string;
          payload?: WorkflowExecutionDispatchPayload;
        };
        return this.handleWorkflowExecuteDispatch(body.executionId, body.payload);
      }
      case '/tunnels': {
        if (request.method !== 'POST') {
          return new Response(JSON.stringify({ error: 'Method not allowed' }), { status: 405 });
        }
        const body = await request.json() as { action?: 'delete'; name?: string; actorId?: string; actorName?: string; actorEmail?: string };
        if (body.action !== 'delete' || !body.name) {
          return new Response(JSON.stringify({ error: 'Invalid action or missing name' }), { status: 400 });
        }
        await this.handleTunnelDelete(body.name, {
          actorId: body.actorId,
          actorName: body.actorName,
          actorEmail: body.actorEmail,
        });
        return Response.json({ success: true });
      }
    }

    // Proxy to sandbox
    if (url.pathname.startsWith('/proxy/')) {
      return this.handleProxy(request, url);
    }

    return new Response('Not found', { status: 404 });
  }

  // ─── WebSocket Upgrade ─────────────────────────────────────────────────

  private async handleWebSocketUpgrade(request: Request, url: URL): Promise<Response> {
    const role = url.searchParams.get('role');

    if (role === 'runner') {
      return this.upgradeRunner(request, url);
    }
    if (role === 'client') {
      return this.upgradeClient(request, url);
    }

    return new Response('Missing or invalid role parameter', { status: 400 });
  }

  private async upgradeClient(_request: Request, url: URL): Promise<Response> {
    const userId = url.searchParams.get('userId');
    if (!userId) {
      return new Response('Missing userId parameter', { status: 400 });
    }

    const pair = new WebSocketPair();
    const [client, server] = Object.values(pair);

    // Tag with client:{userId} for hibernation identification
    this.ctx.acceptWebSocket(server, [`client:${userId}`]);

    // Track connected user
    this.ctx.storage.sql.exec(
      'INSERT OR IGNORE INTO connected_users (user_id) VALUES (?)',
      userId
    );

    // Cache user details for author attribution (only fetch if not already cached)
    if (!this.userDetailsCache.has(userId)) {
      try {
        const userRow = await this.env.DB.prepare(
          'SELECT id, email, name, avatar_url, git_name, git_email, model_preferences FROM users WHERE id = ?'
        ).bind(userId).first<{ id: string; email: string; name: string | null; avatar_url: string | null; git_name: string | null; git_email: string | null; model_preferences: string | null }>();
        if (userRow) {
          this.userDetailsCache.set(userId, {
            id: userRow.id,
            email: userRow.email,
            name: userRow.name || undefined,
            avatarUrl: userRow.avatar_url || undefined,
            gitName: userRow.git_name || undefined,
            gitEmail: userRow.git_email || undefined,
            modelPreferences: userRow.model_preferences ? JSON.parse(userRow.model_preferences) : undefined,
          });
        }
      } catch (err) {
        console.error('Failed to fetch user details for cache:', err);
      }
    }

    // Send full session state as a single init message (prevents duplicates on reconnect)
    const messages = this.ctx.storage.sql
      .exec('SELECT id, role, content, parts, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, created_at FROM messages ORDER BY created_at ASC')
      .toArray();

    const status = this.getStateValue('status') || 'idle';
    const sandboxId = this.getStateValue('sandboxId');
    const connectedUsers = await this.getConnectedUsersWithDetails();
    const sessionId = this.getStateValue('sessionId');
    const workspace = this.getStateValue('workspace') || '';
    const title = this.getStateValue('title');

    const availableModelsRaw = this.getStateValue('availableModels');
    const availableModels = availableModelsRaw ? JSON.parse(availableModelsRaw) : undefined;

    // Load audit log for late joiners
    const auditLogRows = this.ctx.storage.sql
      .exec('SELECT event_type, summary, actor_id, metadata, created_at FROM audit_log ORDER BY id ASC')
      .toArray();

    server.send(JSON.stringify({
      type: 'init',
      session: {
        id: sessionId,
        status,
        workspace,
        title,
        messages: messages.map((msg) => ({
          id: msg.id,
          role: msg.role,
          content: msg.content,
          parts: msg.parts ? JSON.parse(msg.parts as string) : undefined,
          authorId: msg.author_id || undefined,
          authorEmail: msg.author_email || undefined,
          authorName: msg.author_name || undefined,
          authorAvatarUrl: msg.author_avatar_url || undefined,
          channelType: msg.channel_type || undefined,
          channelId: msg.channel_id || undefined,
          createdAt: msg.created_at,
        })),
      },
      data: {
        sandboxRunning: !!sandboxId,
        runnerConnected: this.ctx.getWebSockets('runner').length > 0,
        runnerBusy: this.getStateValue('runnerBusy') === 'true',
        promptsQueued: this.getQueueLength(),
        connectedClients: this.getClientSockets().length + 1,
        connectedUsers,
        availableModels,
        auditLog: auditLogRows.map((row) => ({
          eventType: row.event_type,
          summary: row.summary,
          actorId: row.actor_id || undefined,
          metadata: row.metadata ? JSON.parse(row.metadata as string) : undefined,
          createdAt: row.created_at,
        })),
      },
    }));

    // Send any pending questions
    const pendingQuestions = this.ctx.storage.sql
      .exec("SELECT id, text, options FROM questions WHERE status = 'pending'")
      .toArray();

    for (const q of pendingQuestions) {
      server.send(JSON.stringify({
        type: 'question',
        questionId: q.id,
        text: q.text,
        options: q.options ? JSON.parse(q.options as string) : undefined,
      }));
    }

    // Notify other clients that a user joined (with enriched user details)
    const userDetails = this.userDetailsCache.get(userId);
    this.broadcastToClients({
      type: 'user.joined',
      userId,
      userDetails: userDetails ? { name: userDetails.name, email: userDetails.email, avatarUrl: userDetails.avatarUrl } : undefined,
      connectedUsers,
    });

    this.appendAuditLog('user.joined', `${userDetails?.name || userDetails?.email || userId} joined`, userId);

    // Notify EventBus
    this.notifyEventBus({
      type: 'session.update',
      sessionId: this.getStateValue('sessionId'),
      userId,
      data: { event: 'user.joined', connectedUsers },
      timestamp: new Date().toISOString(),
    });

    return new Response(null, { status: 101, webSocket: client });
  }

  private async upgradeRunner(_request: Request, url: URL): Promise<Response> {
    const token = url.searchParams.get('token');
    const expectedToken = this.getStateValue('runnerToken');

    // DO not yet initialized — runner connected before /start was called (race condition)
    if (!expectedToken) {
      return new Response('Session not initialized yet', { status: 503 });
    }

    if (!token || token !== expectedToken) {
      return new Response('Unauthorized', { status: 401 });
    }

    // Only one runner connection at a time — close existing
    const existingRunners = this.ctx.getWebSockets('runner');
    for (const ws of existingRunners) {
      try {
        ws.close(1000, 'Replaced by new runner connection');
      } catch {
        // ignore
      }
    }

    const pair = new WebSocketPair();
    const [client, server] = Object.values(pair);

    this.ctx.acceptWebSocket(server, ['runner']);
    console.log('[SessionAgentDO] Runner connected');

    // Send init message to runner
    server.send(JSON.stringify({ type: 'init' }));

    // Check if there's queued work (prompt/workflow dispatch) to send immediately.
    if (await this.sendNextQueuedPrompt()) {
      console.log('[SessionAgentDO] Runner connected: dispatched queued work item');
    } else {
      // Check for initial prompt (from create-from-PR/Issue)
      const initialPrompt = this.getStateValue('initialPrompt');
      if (initialPrompt) {
        // Clear it so it only fires once
        this.setStateValue('initialPrompt', '');
        const messageId = crypto.randomUUID();
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
          messageId, 'user', initialPrompt
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: messageId,
            role: 'user',
            content: initialPrompt,
            createdAt: Math.floor(Date.now() / 1000),
          },
        });
        // Insert into prompt_queue as 'processing' so it can be recovered on disconnect
        this.ctx.storage.sql.exec(
          "INSERT INTO prompt_queue (id, content, status) VALUES (?, ?, 'processing')",
          messageId, initialPrompt
        );
        const ipOwnerId = this.getStateValue('userId');
        const ipOwnerDetails = ipOwnerId ? await this.getUserDetails(ipOwnerId) : undefined;
        const ipModelPrefs = await this.resolveModelPreferences(ipOwnerDetails);
        const initialModel = this.getStateValue('initialModel');
        if (initialModel) {
          this.setStateValue('initialModel', ''); // Clear so it only applies once
        }
        server.send(JSON.stringify({
          type: 'prompt',
          messageId,
          content: initialPrompt,
          model: initialModel || undefined,
          opencodeSessionId: this.getChannelOcSessionId(this.channelKeyFrom(undefined, undefined)),
          modelPreferences: ipModelPrefs,
        }));
        this.setStateValue('runnerBusy', 'true');
        console.log('[SessionAgentDO] Runner connected: dispatched initial prompt', messageId);
      }
    }

    this.broadcastToClients({
      type: 'status',
      data: { runnerConnected: true },
    });

    return new Response(null, { status: 101, webSocket: client });
  }

  // ─── Hibernation Handlers ──────────────────────────────────────────────

  async webSocketMessage(ws: WebSocket, message: string | ArrayBuffer) {
    const data = typeof message === 'string' ? message : new TextDecoder().decode(message);
    let parsed: ClientMessage | RunnerMessage;

    try {
      parsed = JSON.parse(data);
    } catch {
      ws.send(JSON.stringify({ type: 'error', message: 'Invalid JSON' }));
      return;
    }

    // Determine if this is a runner or client socket
    const tags = this.ctx.getTags(ws);
    const isRunner = tags.includes('runner');

    console.log(`[SessionAgentDO] WebSocket message: isRunner=${isRunner}, type=${parsed.type}, data=${data.slice(0, 200)}`);

    if (isRunner) {
      await this.handleRunnerMessage(parsed as RunnerMessage);
    } else {
      await this.handleClientMessage(ws, parsed as ClientMessage);
    }
  }

  async webSocketClose(ws: WebSocket, code: number, reason: string, _wasClean: boolean) {
    const tags = this.ctx.getTags(ws);
    const isRunner = tags.includes('runner');

    if (isRunner) {
      console.log(`[SessionAgentDO] Runner disconnected: code=${code} reason="${reason || 'unknown'}"`);
      // Revert any processing prompt back to queued so it can be retried
      this.ctx.storage.sql.exec(
        "UPDATE prompt_queue SET status = 'queued' WHERE status = 'processing'"
      );
      this.setStateValue('runnerBusy', 'false');

      const queueLength = this.getQueueLength();
      this.broadcastToClients({
        type: 'status',
        data: {
          runnerConnected: false,
          queuedPrompts: queueLength,
          runnerDisconnected: true,
        },
      });
    } else {
      // Extract userId from tag like "client:abc123"
      const clientTag = tags.find((t) => t.startsWith('client:'));
      if (clientTag) {
        const userId = clientTag.replace('client:', '');

        // Check if user has other connections still open
        const remaining = this.ctx.getWebSockets(`client:${userId}`).filter((s) => s !== ws);
        if (remaining.length === 0) {
          // Last connection for this user — remove from connected_users
          this.ctx.storage.sql.exec('DELETE FROM connected_users WHERE user_id = ?', userId);

          // Grab user details before cleaning up the cache
          const departingUserDetails = this.userDetailsCache.get(userId);
          const connectedUsers = await this.getConnectedUsersWithDetails();
          this.broadcastToClients({
            type: 'user.left',
            userId,
            userDetails: departingUserDetails
              ? { name: departingUserDetails.name, email: departingUserDetails.email, avatarUrl: departingUserDetails.avatarUrl }
              : undefined,
            connectedUsers,
          });

          this.appendAuditLog('user.left', `${departingUserDetails?.name || departingUserDetails?.email || userId} left`, userId);

          // Clean up user details cache if no longer connected
          this.userDetailsCache.delete(userId);

          this.notifyEventBus({
            type: 'session.update',
            sessionId: this.getStateValue('sessionId'),
            userId,
            data: { event: 'user.left', connectedUsers: this.getConnectedUserIds() },
            timestamp: new Date().toISOString(),
          });
        }
      }
    }

    // The socket is already closed when webSocketClose fires in hibernation mode.
    // Only attempt close with valid codes (1000-4999, excluding reserved 1005/1006/1015).
    try {
      ws.close(code || 1000, reason || 'Connection closed');
    } catch {
      // Socket already closed or invalid close code — ignore
    }
  }

  async webSocketError(ws: WebSocket, error: unknown) {
    console.error('WebSocket error:', error);
    ws.close(1011, 'Internal error');
  }

  // ─── Alarm Handler ────────────────────────────────────────────────────

  async alarm() {
    const now = Date.now();
    const nowSecs = Math.floor(now / 1000);

    // ─── Collect Mode Flush Check (Phase D) ──────────────────────────
    const collectFlushAt = this.getStateValue('collectFlushAt');
    if (collectFlushAt && now >= parseInt(collectFlushAt)) {
      await this.flushCollectBuffer();
    }

    // ─── Idle Hibernate Check ─────────────────────────────────────────
    const status = this.getStateValue('status');
    const idleTimeoutMsStr = this.getStateValue('idleTimeoutMs');
    const lastActivityStr = this.getStateValue('lastUserActivityAt');

    if (status === 'running' && idleTimeoutMsStr && lastActivityStr) {
      const idleTimeoutMs = parseInt(idleTimeoutMsStr);
      const lastActivity = parseInt(lastActivityStr);

      if (now - lastActivity >= idleTimeoutMs) {
        // Trigger hibernate
        this.ctx.waitUntil(this.performHibernate());
        // Don't return — still process question expiry below
      }
    }

    // ─── Periodic Metrics Flush ──────────────────────────────────────
    this.ctx.waitUntil(this.flushMetrics());

    // ─── Question Expiry ──────────────────────────────────────────────
    const expired = this.ctx.storage.sql
      .exec(
        "SELECT id, text FROM questions WHERE status = 'pending' AND expires_at IS NOT NULL AND expires_at <= ?",
        nowSecs
      )
      .toArray();

    for (const q of expired) {
      this.ctx.storage.sql.exec(
        "UPDATE questions SET status = 'expired' WHERE id = ?",
        q.id as string
      );

      this.broadcastToClients({
        type: 'status',
        data: { questionExpired: q.id },
      });

      // Tell runner the question timed out (treated as no answer)
      this.sendToRunner({
        type: 'answer',
        questionId: q.id as string,
        answer: '__expired__',
      });
    }

    // ─── Channel Follow-up Reminders ────────────────────────────────
    const dueFollowups = this.ctx.storage.sql
      .exec(
        "SELECT id, channel_type, channel_id, original_content, created_at, reminder_count FROM channel_followups WHERE status = 'pending' AND next_reminder_at <= ?",
        now
      )
      .toArray();

    for (const fu of dueFollowups) {
      const channelType = fu.channel_type as string;
      const channelId = fu.channel_id as string;

      // Web chat does not require channel_reply follow-ups.
      if (!this.requiresExplicitChannelReply(channelType)) {
        this.resolveChannelFollowups(channelType, channelId);
        continue;
      }

      const createdMs = fu.created_at as number;
      const elapsed = now - createdMs;
      const minutes = Math.floor(elapsed / 60_000);
      const timeAgo = minutes < 60 ? `${minutes}m` : `${Math.floor(minutes / 60)}h ${minutes % 60}m`;
      const count = ((fu.reminder_count as number) || 0) + 1;
      const truncatedContent = ((fu.original_content as string) || '').slice(0, 200);

      const reminderContent = [
        `\u23F0 Reminder: You received a message via ${channelType} (chatId: ${channelId}) ${timeAgo} ago:`,
        `"${truncatedContent}"`,
        `You acknowledged it but haven't sent a substantive follow-up yet. If the work is done or has meaningful progress, use channel_reply to update the requester. If you need more time, that's fine \u2014 this reminder will repeat.`,
        `(Reminder #${count}, use channel_reply with follow_up=true to clear)`,
      ].join('\n');

      // Inject as a wake-able system message
      await this.handleSystemMessage(reminderContent, undefined, true);

      // Bump reminder count and schedule next reminder
      const intervalMs = parseInt(this.getStateValue('channelFollowupIntervalMs') || '300000');
      this.ctx.storage.sql.exec(
        'UPDATE channel_followups SET reminder_count = ?, next_reminder_at = ? WHERE id = ?',
        count, now + intervalMs, fu.id as string
      );
    }

    // If there are still pending questions with future expiry, or pending followups, schedule next alarm
    let nextAlarmMs: number | null = null;

    const nextExpiry = this.ctx.storage.sql
      .exec(
        "SELECT MIN(expires_at) as next FROM questions WHERE status = 'pending' AND expires_at IS NOT NULL"
      )
      .toArray();

    if (nextExpiry.length > 0 && nextExpiry[0].next) {
      const questionMs = (nextExpiry[0].next as number) * 1000;
      if (questionMs > now) {
        nextAlarmMs = questionMs;
      }
    }

    const nextFollowup = this.ctx.storage.sql
      .exec("SELECT MIN(next_reminder_at) as next FROM channel_followups WHERE status = 'pending'")
      .toArray();
    if (nextFollowup.length > 0 && nextFollowup[0].next) {
      const followupMs = nextFollowup[0].next as number;
      if (followupMs > now && (nextAlarmMs === null || followupMs < nextAlarmMs)) {
        nextAlarmMs = followupMs;
      }
    }

    // Also consider idle timeout for next alarm
    const alarmStatus = this.getStateValue('status');
    const alarmIdleTimeoutMsStr = this.getStateValue('idleTimeoutMs');
    const alarmLastActivityStr = this.getStateValue('lastUserActivityAt');
    if (alarmStatus === 'running' && alarmIdleTimeoutMsStr && alarmLastActivityStr) {
      const idleTimeoutMs = parseInt(alarmIdleTimeoutMsStr);
      const lastActivity = parseInt(alarmLastActivityStr);
      const idleAlarmMs = lastActivity + idleTimeoutMs;
      if (idleAlarmMs > now && (nextAlarmMs === null || idleAlarmMs < nextAlarmMs)) {
        nextAlarmMs = idleAlarmMs;
      }
    }

    if (nextAlarmMs !== null) {
      this.ctx.storage.setAlarm(nextAlarmMs);
    }
  }

  // ─── Client Message Handling ───────────────────────────────────────────

  private async handleClientMessage(ws: WebSocket, msg: ClientMessage) {
    switch (msg.type) {
      case 'prompt': {
        const attachments = sanitizePromptAttachments(msg.attachments);
        if (!msg.content && attachments.length === 0) {
          ws.send(JSON.stringify({ type: 'error', message: 'Missing content or attachments' }));
          return;
        }
        // Extract userId from WebSocket tag for authorship tracking
        const clientTag = this.ctx.getTags(ws).find((t: string) => t.startsWith('client:'));
        const userId = clientTag?.replace('client:', '');
        const userDetails = userId ? this.userDetailsCache.get(userId) : undefined;
        const author = userDetails ? {
          id: userDetails.id,
          email: userDetails.email,
          name: userDetails.name,
          avatarUrl: userDetails.avatarUrl,
          gitName: userDetails.gitName,
          gitEmail: userDetails.gitEmail,
        } : userId ? { id: userId, email: '', name: undefined, avatarUrl: undefined, gitName: undefined, gitEmail: undefined } : undefined;
        // Route through queue mode (Phase D)
        const wsChannelType = (msg as any).channelType as string | undefined;
        const wsChannelId = (msg as any).channelId as string | undefined;
        const wsQueueMode = (msg as any).queueMode || this.getStateValue('queueMode') || 'followup';
        switch (wsQueueMode) {
          case 'steer':
            await this.handleInterruptPrompt(msg.content || '', msg.model, author, attachments, wsChannelType, wsChannelId);
            break;
          case 'collect':
            await this.handleCollectPrompt(msg.content || '', msg.model, author, attachments, wsChannelType, wsChannelId);
            break;
          default:
            await this.handlePrompt(msg.content || '', msg.model, author, attachments, wsChannelType, wsChannelId);
            break;
        }
        break;
      }

      case 'answer':
        if (!msg.questionId || msg.answer === undefined) {
          ws.send(JSON.stringify({ type: 'error', message: 'Missing questionId or answer' }));
          return;
        }
        await this.handleAnswer(msg.questionId, msg.answer);
        break;

      case 'ping':
        ws.send(JSON.stringify({ type: 'pong' }));
        break;

      case 'abort':
        await this.handleAbort();
        break;

      case 'revert':
        if (!msg.messageId) {
          ws.send(JSON.stringify({ type: 'error', message: 'Missing messageId' }));
          return;
        }
        await this.handleRevert(msg.messageId);
        break;

      case 'diff':
        await this.handleDiff();
        break;

      case 'review': {
        const reviewRequestId = crypto.randomUUID();
        this.sendToRunner({ type: 'review', requestId: reviewRequestId });
        break;
      }

      case 'command': {
        const { command: cmd, args: cmdArgs } = msg;
        if (!cmd) {
          ws.send(JSON.stringify({ type: 'error', message: 'Missing command name' }));
          return;
        }
        switch (cmd) {
          // OpenCode passthrough commands
          case 'undo':
          case 'redo':
          case 'compact':
            this.sendToRunner({
              type: 'opencode-command',
              command: cmd,
              args: cmdArgs,
              requestId: crypto.randomUUID(),
            } as any);
            break;
          case 'new-session': {
            const channelType = msg.channelType || 'web';
            const channelId = msg.channelId || 'default';
            this.sendToRunner({
              type: 'new-session',
              channelType,
              channelId,
              requestId: crypto.randomUUID(),
            } as any);
            break;
          }
          default:
            ws.send(JSON.stringify({ type: 'error', message: `Unknown command: ${cmd}` }));
        }
        break;
      }
    }
  }

  private async handlePrompt(
    content: string,
    model?: string,
    author?: { id: string; email: string; name?: string; avatarUrl?: string; gitName?: string; gitEmail?: string },
    attachments?: PromptAttachment[],
    channelType?: string,
    channelId?: string
  ) {
    // Update idle tracking
    this.setStateValue('lastUserActivityAt', String(Date.now()));
    this.rescheduleIdleAlarm();

    // Track the current prompt author for PR attribution (Part 6)
    if (author?.id) {
      this.setStateValue('currentPromptAuthorId', author.id);
    }

    // If hibernated, auto-trigger wake before processing
    const currentStatus = this.getStateValue('status');
    if (currentStatus === 'hibernated') {
      // Fire wake in background — prompt will be queued since runner won't be connected yet
      this.ctx.waitUntil(this.performWake());
    }

    const normalizedAttachments = sanitizePromptAttachments(attachments);
    const attachmentParts = attachmentPartsForMessage(normalizedAttachments);
    const serializedAttachmentParts = attachmentParts.length > 0 ? JSON.stringify(attachmentParts) : null;
    const serializedQueuedAttachments = normalizedAttachments.length > 0 ? JSON.stringify(normalizedAttachments) : null;

    // Store user message with author info and channel metadata
    const messageId = crypto.randomUUID();
    this.ctx.storage.sql.exec(
      'INSERT INTO messages (id, role, content, parts, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
      messageId, 'user', content, serializedAttachmentParts,
      author?.id || null, author?.email || null, author?.name || null, author?.avatarUrl || null,
      channelType || null, channelId || null
    );

    // Broadcast user message to all clients (includes author info + channel metadata)
    this.broadcastToClients({
      type: 'message',
      data: {
        id: messageId,
        role: 'user',
        content,
        parts: attachmentParts.length > 0 ? attachmentParts : undefined,
        authorId: author?.id,
        authorEmail: author?.email,
        authorName: author?.name,
        authorAvatarUrl: author?.avatarUrl,
        channelType,
        channelId,
        createdAt: Math.floor(Date.now() / 1000),
      },
    });

    this.appendAuditLog(
      'user.prompt',
      content
        ? content.slice(0, 120)
        : `[${normalizedAttachments.length} image attachment(s)]`,
      author?.id
    );

    // Check if runner is busy
    const channelKey = this.channelKeyFrom(channelType, channelId);
    const runnerBusy = this.getStateValue('runnerBusy') === 'true';
    const runnerSockets = this.ctx.getWebSockets('runner');
    const runnerConnected = runnerSockets.length > 0;
    const status = this.getStateValue('status');
    const sandboxId = this.getStateValue('sandboxId');
    const queuedCount = this.getQueueLength();

    console.log(
      `[SessionAgentDO] handlePrompt: channel=${channelKey} runnerConnected=${runnerConnected} runnerBusy=${runnerBusy} status=${status} sandboxId=${sandboxId || 'none'} queued=${queuedCount}`
    );

    if (!runnerConnected) {
      // No runner connected — queue the prompt with author info + channel metadata
      this.ctx.storage.sql.exec(
        "INSERT INTO prompt_queue (id, content, attachments, model, status, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, channel_key) VALUES (?, ?, ?, ?, 'queued', ?, ?, ?, ?, ?, ?, ?)",
        messageId, content, serializedQueuedAttachments, model || null,
        author?.id || null, author?.email || null, author?.name || null, author?.avatarUrl || null,
        channelType || null, channelId || null, channelKey
      );
      this.appendAuditLog(
        'prompt.queued',
        `Queued: no runner connected (status=${status || 'unknown'}, sandbox=${sandboxId ? 'yes' : 'no'}, queued=${this.getQueueLength()})`,
        author?.id
      );
      this.broadcastToClients({
        type: 'status',
        data: { promptQueued: true, queuePosition: this.getQueueLength() },
      });
      return;
    }

    if (runnerBusy) {
      // Runner is processing another prompt — queue with author info + channel metadata
      this.ctx.storage.sql.exec(
        "INSERT INTO prompt_queue (id, content, attachments, model, status, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, channel_key) VALUES (?, ?, ?, ?, 'queued', ?, ?, ?, ?, ?, ?, ?)",
        messageId, content, serializedQueuedAttachments, model || null,
        author?.id || null, author?.email || null, author?.name || null, author?.avatarUrl || null,
        channelType || null, channelId || null, channelKey
      );
      this.appendAuditLog(
        'prompt.queued',
        `Queued: runner busy (status=${status || 'unknown'}, sandbox=${sandboxId ? 'yes' : 'no'}, queued=${this.getQueueLength()})`,
        author?.id
      );
      this.broadcastToClients({
        type: 'status',
        data: { promptQueued: true, queuePosition: this.getQueueLength() },
      });
      return;
    }

    // Insert into prompt_queue as 'processing' so it can be recovered if the runner disconnects
    this.ctx.storage.sql.exec(
      "INSERT INTO prompt_queue (id, content, attachments, model, status, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, channel_key) VALUES (?, ?, ?, ?, 'processing', ?, ?, ?, ?, ?, ?, ?)",
      messageId, content, serializedQueuedAttachments, model || null,
      author?.id || null, author?.email || null, author?.name || null, author?.avatarUrl || null,
      channelType || null, channelId || null, channelKey
    );

    // Forward directly to runner with author info + channel metadata
    this.setStateValue('runnerBusy', 'true');
    console.log('[SessionAgentDO] handlePrompt: dispatching to runner');

    // Track channel context for auto-reply on completion
    if (channelType && channelId) {
      this.pendingChannelReply = { channelType, channelId, resultContent: null, resultMessageId: null, handled: false };

      // Record a follow-up reminder so the agent gets nudged if it doesn't send a substantive reply
      this.insertChannelFollowup(channelType, channelId, content);
    } else {
      this.pendingChannelReply = null;
    }

    // Resolve model preferences: user prefs > org prefs fallback
    const ownerId = this.getStateValue('userId');
    const ownerDetails = ownerId ? await this.getUserDetails(ownerId) : undefined;
    const resolvedModelPrefs = await this.resolveModelPreferences(ownerDetails);
    const channelOcSessionId = this.getChannelOcSessionId(channelKey);
    this.sendToRunner({
      type: 'prompt',
      messageId,
      content,
      model,
      attachments: normalizedAttachments.length > 0 ? normalizedAttachments : undefined,
      channelType,
      channelId,
      authorId: author?.id,
      authorEmail: author?.email,
      authorName: author?.name,
      gitName: author?.gitName,
      gitEmail: author?.gitEmail,
      opencodeSessionId: channelOcSessionId,
      modelPreferences: resolvedModelPrefs,
    });
  }

  private async handleAnswer(questionId: string, answer: string | boolean) {
    // Only answer if still pending
    const existing = this.ctx.storage.sql
      .exec("SELECT status FROM questions WHERE id = ?", questionId)
      .toArray();
    if (existing.length === 0 || existing[0].status !== 'pending') {
      return; // Already answered or expired
    }

    // Update question in DB
    this.ctx.storage.sql.exec(
      "UPDATE questions SET status = 'answered', answer = ? WHERE id = ?",
      String(answer), questionId
    );

    // Forward to runner
    this.sendToRunner({
      type: 'answer',
      questionId,
      answer,
    });

    // Broadcast to other clients that question was answered
    this.broadcastToClients({
      type: 'status',
      data: { questionAnswered: questionId, answer: String(answer) },
    });

    this.appendAuditLog('user.answer', `Answered question: ${String(answer).slice(0, 80)}`, undefined, { questionId });

    // Notify EventBus
    this.notifyEventBus({
      type: 'question.answered',
      sessionId: this.getStateValue('sessionId'),
      data: { questionId, answer: String(answer) },
      timestamp: new Date().toISOString(),
    });
  }

  private async handleAbort(channelType?: string, channelId?: string) {
    if (channelType && channelId) {
      // Channel-scoped abort — only clear this channel's queued prompts
      const channelKey = this.channelKeyFrom(channelType, channelId);
      this.ctx.storage.sql.exec(
        "DELETE FROM prompt_queue WHERE status = 'queued' AND channel_key = ?",
        channelKey
      );
      this.sendToRunner({ type: 'abort', channelType, channelId });
    } else {
      // Global abort — clear all queued prompts
      this.ctx.storage.sql.exec("DELETE FROM prompt_queue WHERE status = 'queued'");
      this.sendToRunner({ type: 'abort' });
    }

    // Broadcast status immediately (runner will confirm with 'aborted')
    this.broadcastToClients({
      type: 'agentStatus',
      status: 'idle',
    });

    this.appendAuditLog('user.abort', `User aborted agent${channelType ? ` (channel: ${channelType}:${channelId})` : ''}`);
  }

  private async handleInterruptPrompt(
    content: string,
    model?: string,
    author?: { id: string; email: string; name?: string; avatarUrl?: string; gitName?: string; gitEmail?: string },
    attachments?: PromptAttachment[],
    channelType?: string,
    channelId?: string,
  ) {
    const runnerBusy = this.getStateValue('runnerBusy') === 'true';
    if (runnerBusy) {
      // Abort current work (channel-scoped if channel info provided)
      await this.handleAbort(channelType, channelId);
    }
    // Queue the new prompt — when the runner confirms abort, handlePromptComplete
    // will drain the queue and send this prompt to the runner
    await this.handlePrompt(content, model, author, attachments, channelType, channelId);
  }

  // ─── Collect Mode (Phase D) ──────────────────────────────────────────

  private async handleCollectPrompt(
    content: string,
    model?: string,
    author?: { id: string; email: string; name?: string; avatarUrl?: string; gitName?: string; gitEmail?: string },
    attachments?: PromptAttachment[],
    channelType?: string,
    channelId?: string,
  ) {
    // Update idle tracking
    this.setStateValue('lastUserActivityAt', String(Date.now()));
    this.rescheduleIdleAlarm();

    const normalizedAttachments = sanitizePromptAttachments(attachments);
    const attachmentParts = attachmentPartsForMessage(normalizedAttachments);
    const serializedAttachmentParts = attachmentParts.length > 0 ? JSON.stringify(attachmentParts) : null;

    // Store user message immediately for display (including channel metadata)
    const messageId = crypto.randomUUID();
    this.ctx.storage.sql.exec(
      'INSERT INTO messages (id, role, content, parts, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
      messageId, 'user', content, serializedAttachmentParts,
      author?.id || null, author?.email || null, author?.name || null, author?.avatarUrl || null,
      channelType || null, channelId || null,
    );

    // Broadcast user message to clients (including channel metadata)
    this.broadcastToClients({
      type: 'message',
      data: {
        id: messageId,
        role: 'user',
        content,
        parts: attachmentParts.length > 0 ? attachmentParts : undefined,
        authorId: author?.id,
        authorEmail: author?.email,
        authorName: author?.name,
        authorAvatarUrl: author?.avatarUrl,
        channelType,
        channelId,
        createdAt: Math.floor(Date.now() / 1000),
      },
    });

    // Append to collect buffer (stored as JSON in state table, keyed by channel)
    const collectChannelKey = this.channelKeyFrom(channelType, channelId);
    const bufferStateKey = `collectBuffer:${collectChannelKey}`;
    const bufferRaw = this.getStateValue(bufferStateKey);
    const buffer: Array<{ content: string; model?: string; author?: typeof author; attachments?: PromptAttachment[]; channelType?: string; channelId?: string }> =
      bufferRaw ? JSON.parse(bufferRaw) : [];
    buffer.push({ content, model, author, attachments: normalizedAttachments.length > 0 ? normalizedAttachments : undefined, channelType, channelId });
    this.setStateValue(bufferStateKey, JSON.stringify(buffer));

    // Set flush time (per-channel)
    const debounceMs = parseInt(this.getStateValue('collectDebounceMs') || '3000');
    const flushAt = Date.now() + debounceMs;
    this.setStateValue(`collectFlushAt:${collectChannelKey}`, String(flushAt));

    // Schedule alarm for collect flush (uses min of flush and existing idle alarm)
    this.rescheduleCollectAlarm(flushAt);

    // Broadcast collect status
    this.broadcastToClients({
      type: 'status',
      data: { collectPending: true, collectCount: buffer.length },
    });
  }

  private rescheduleCollectAlarm(flushAt: number): void {
    // Use the earliest of: collect flush, idle timeout, question expiry, channel followups
    let earliestAlarm = flushAt;

    const idleTimeoutMsStr = this.getStateValue('idleTimeoutMs');
    const lastActivityStr = this.getStateValue('lastUserActivityAt');
    if (idleTimeoutMsStr && lastActivityStr) {
      const idleAlarm = parseInt(lastActivityStr) + parseInt(idleTimeoutMsStr);
      if (idleAlarm < earliestAlarm) earliestAlarm = idleAlarm;
    }

    const nextExpiry = this.ctx.storage.sql
      .exec("SELECT MIN(expires_at) as next FROM questions WHERE status = 'pending' AND expires_at IS NOT NULL")
      .toArray();
    if (nextExpiry.length > 0 && nextExpiry[0].next) {
      const questionMs = (nextExpiry[0].next as number) * 1000;
      if (questionMs < earliestAlarm) earliestAlarm = questionMs;
    }

    const nextFollowup = this.ctx.storage.sql
      .exec("SELECT MIN(next_reminder_at) as next FROM channel_followups WHERE status = 'pending'")
      .toArray();
    if (nextFollowup.length > 0 && nextFollowup[0].next) {
      const followupMs = nextFollowup[0].next as number;
      if (followupMs < earliestAlarm) earliestAlarm = followupMs;
    }

    this.ctx.storage.setAlarm(earliestAlarm);
  }

  private async flushCollectBuffer(): Promise<void> {
    // Flush all per-channel collect buffers that are ready
    const stateRows = this.ctx.storage.sql
      .exec("SELECT key, value FROM state WHERE key LIKE 'collectFlushAt:%'")
      .toArray();

    const now = Date.now();
    let flushed = false;

    for (const row of stateRows) {
      const key = row.key as string;
      const flushAt = parseInt(row.value as string);
      if (!flushAt || now < flushAt) continue;

      const channelKey = key.replace('collectFlushAt:', '');
      const bufferStateKey = `collectBuffer:${channelKey}`;
      const bufferRaw = this.getStateValue(bufferStateKey);
      if (!bufferRaw) {
        this.setStateValue(key, '');
        continue;
      }

      const buffer: Array<{ content: string; model?: string; author?: any; attachments?: PromptAttachment[]; channelType?: string; channelId?: string }> = JSON.parse(bufferRaw);
      if (buffer.length === 0) {
        this.setStateValue(bufferStateKey, '');
        this.setStateValue(key, '');
        continue;
      }

      // Clear buffer and flush state for this channel
      this.setStateValue(bufferStateKey, '');
      this.setStateValue(key, '');

      // Merge messages
      const mergedContent = buffer.map((b) => b.content).join('\n\n---\n\n');
      const lastEntry = buffer[buffer.length - 1];
      const allAttachments = buffer.flatMap((b) => b.attachments || []);
      const channelType = lastEntry.channelType;
      const channelId = lastEntry.channelId;

      // Send merged prompt through normal flow with channel info
      await this.handlePrompt(mergedContent, lastEntry.model, lastEntry.author, allAttachments, channelType, channelId);
      flushed = true;
    }

    // Also check legacy non-keyed buffer for backward compatibility
    const legacyBufferRaw = this.getStateValue('collectBuffer');
    if (legacyBufferRaw) {
      const legacyFlushAt = this.getStateValue('collectFlushAt');
      if (legacyFlushAt && now >= parseInt(legacyFlushAt)) {
        const buffer: Array<{ content: string; model?: string; author?: any; attachments?: PromptAttachment[] }> = JSON.parse(legacyBufferRaw);
        if (buffer.length > 0) {
          this.setStateValue('collectBuffer', '');
          this.setStateValue('collectFlushAt', '');
          const mergedContent = buffer.map((b) => b.content).join('\n\n---\n\n');
          const lastEntry = buffer[buffer.length - 1];
          const allAttachments = buffer.flatMap((b) => b.attachments || []);
          await this.handlePrompt(mergedContent, lastEntry.model, lastEntry.author, allAttachments);
          flushed = true;
        }
      }
    }

    if (flushed) {
      // Broadcast collect complete
      this.broadcastToClients({
        type: 'status',
        data: { collectPending: false, collectCount: 0 },
      });
    }

    // Reschedule idle alarm (since we consumed the collect alarm slot)
    this.rescheduleIdleAlarm();
  }

  private async handleRevert(messageId: string) {
    // Find the message and all messages created at or after it
    const targetMsg = this.ctx.storage.sql
      .exec('SELECT created_at FROM messages WHERE id = ?', messageId)
      .toArray();

    if (targetMsg.length === 0) {
      return; // Message not found
    }

    const createdAt = targetMsg[0].created_at as number;
    const affectedMessages = this.ctx.storage.sql
      .exec('SELECT id FROM messages WHERE created_at >= ? ORDER BY created_at ASC', createdAt)
      .toArray();

    const removedIds = affectedMessages.map((m) => m.id as string);

    // Delete the messages from SQLite
    if (removedIds.length > 0) {
      const placeholders = removedIds.map(() => '?').join(',');
      this.ctx.storage.sql.exec(
        `DELETE FROM messages WHERE id IN (${placeholders})`,
        ...removedIds
      );
    }

    // Forward to runner so OpenCode can revert too
    this.sendToRunner({ type: 'revert', messageId });

    // Broadcast removal to all clients
    this.broadcastToClients({
      type: 'messages.removed',
      messageIds: removedIds,
    });
  }

  private async handleDiff() {
    const requestId = crypto.randomUUID();
    this.sendToRunner({ type: 'diff', requestId });
  }

  // ─── Runner Message Handling ───────────────────────────────────────────

  private async handleRunnerMessage(msg: RunnerMessage) {
    console.log(`[SessionAgentDO] Runner message: type=${msg.type}`);

    // Reset idle timer on any runner activity — agent work counts as session activity
    if (msg.type === 'tool' || msg.type === 'result' || msg.type === 'stream' || msg.type === 'agentStatus') {
      this.setStateValue('lastUserActivityAt', String(Date.now()));
      this.rescheduleIdleAlarm();
    }

    switch (msg.type) {
      case 'tunnels': {
        if (Array.isArray(msg.tunnels)) {
          this.setStateValue('tunnels', JSON.stringify(msg.tunnels));
        } else {
          this.setStateValue('tunnels', '');
        }
        break;
      }

      case 'stream': {
        // Forward stream chunks to all clients (don't store)
        // Client expects 'chunk' type for streaming content
        const streamCh = this.activeChannel;
        this.broadcastToClients({
          type: 'chunk',
          content: msg.content,
          ...(streamCh ? { channelType: streamCh.channelType, channelId: streamCh.channelId } : {}),
        });
        break;
      }

      case 'result': {
        // Store final assistant message and broadcast
        // Always generate a new ID - msg.messageId is the prompt ID which is already used for the user message
        const resultId = crypto.randomUUID();
        const resultCh = this.activeChannel;
        console.log(`[SessionAgentDO] Storing assistant result: id=${resultId}, content length=${(msg.content || '').length}`);
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, channel_type, channel_id) VALUES (?, ?, ?, ?, ?)',
          resultId, 'assistant', msg.content || '', resultCh?.channelType ?? null, resultCh?.channelId ?? null
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: resultId,
            role: 'assistant',
            content: msg.content,
            createdAt: Math.floor(Date.now() / 1000),
            ...(resultCh ? { channelType: resultCh.channelType, channelId: resultCh.channelId } : {}),
          },
        });
        console.log(`[SessionAgentDO] Assistant result stored and broadcast`);

        // Track result content for auto channel reply
        if (this.pendingChannelReply && !this.pendingChannelReply.handled && msg.content) {
          this.pendingChannelReply.resultContent = msg.content;
          this.pendingChannelReply.resultMessageId = resultId;
        }
        break;
      }

      case 'workflow-chat-message': {
        const role = msg.role === 'assistant' || msg.role === 'system' ? msg.role : 'user';
        const content = (msg.content || '').trim();
        if (!content) break;

        const workflowMsgId = crypto.randomUUID();
        const partsObj = msg.parts && typeof msg.parts === 'object' ? msg.parts as Record<string, unknown> : null;
        const partsJson = partsObj ? JSON.stringify(partsObj) : null;
        const workflowChannelType = typeof msg.channelType === 'string'
          ? msg.channelType
          : (partsObj && typeof partsObj.channelType === 'string' ? partsObj.channelType : null);
        const workflowChannelId = typeof msg.channelId === 'string'
          ? msg.channelId
          : (partsObj && typeof partsObj.channelId === 'string' ? partsObj.channelId : null);
        const workflowOcSessionId = typeof msg.opencodeSessionId === 'string'
          ? msg.opencodeSessionId
          : (partsObj && typeof partsObj.opencodeSessionId === 'string' ? partsObj.opencodeSessionId : null);
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, parts, channel_type, channel_id, opencode_session_id) VALUES (?, ?, ?, ?, ?, ?, ?)',
          workflowMsgId,
          role,
          content,
          partsJson,
          workflowChannelType,
          workflowChannelId,
          workflowOcSessionId,
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: workflowMsgId,
            role,
            content,
            ...(partsJson ? { parts: JSON.parse(partsJson) } : {}),
            ...(workflowChannelType && workflowChannelId ? { channelType: workflowChannelType, channelId: workflowChannelId } : {}),
            createdAt: Math.floor(Date.now() / 1000),
          },
        });
        break;
      }

      case 'tool': {
        // Upsert tool call by callID — each tool gets one row that updates in place
        const toolId = msg.callID || crypto.randomUUID();
        const toolStatus = (msg.status as ToolCallStatus) || 'completed';
        const toolCh = this.activeChannel;
        const parts = JSON.stringify({
          toolName: msg.toolName,
          status: toolStatus,
          args: msg.args,
          result: msg.result,
        });
        const content = msg.content || `Tool: ${msg.toolName}`;

        // Check if this tool message already exists
        const existing = this.ctx.storage.sql
          .exec('SELECT id FROM messages WHERE id = ?', toolId)
          .toArray();

        if (existing.length === 0) {
          // First time seeing this callID — insert and broadcast as new message
          this.ctx.storage.sql.exec(
            'INSERT INTO messages (id, role, content, parts, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?)',
            toolId, 'tool', content, parts, toolCh?.channelType ?? null, toolCh?.channelId ?? null
          );
          this.broadcastToClients({
            type: 'message',
            data: {
              id: toolId,
              role: 'tool',
              content,
              parts: { toolName: msg.toolName, status: toolStatus, args: msg.args, result: msg.result },
              createdAt: Math.floor(Date.now() / 1000),
              ...(toolCh ? { channelType: toolCh.channelType, channelId: toolCh.channelId } : {}),
            },
          });
          this.appendAuditLog('agent.tool_call', `${msg.toolName || 'unknown'}`, undefined, { toolId, toolName: msg.toolName });
        } else {
          // Update existing row and broadcast as message.updated
          this.ctx.storage.sql.exec(
            'UPDATE messages SET content = ?, parts = ?, channel_type = COALESCE(channel_type, ?), channel_id = COALESCE(channel_id, ?) WHERE id = ?',
            content, parts, toolCh?.channelType ?? null, toolCh?.channelId ?? null, toolId
          );
          this.broadcastToClients({
            type: 'message.updated',
            data: {
              id: toolId,
              role: 'tool',
              content,
              parts: { toolName: msg.toolName, status: toolStatus, args: msg.args, result: msg.result },
              createdAt: Math.floor(Date.now() / 1000),
              ...(toolCh ? { channelType: toolCh.channelType, channelId: toolCh.channelId } : {}),
            },
          });
          if (toolStatus === 'completed' || toolStatus === 'error') {
            this.appendAuditLog('agent.tool_completed', `${msg.toolName || 'unknown'} ${toolStatus}`, undefined, { toolId, toolName: msg.toolName, status: toolStatus });
          }
        }
        if (msg.toolName === 'wait_for_event' && toolStatus === 'completed') {
          // Don't set runnerBusy=false or dequeue here — the current agent turn
          // is still active. The runner will send 'complete' when the full turn
          // finishes, which triggers handlePromptComplete → sendNextQueuedPrompt.
          // Setting runnerBusy=false here would allow a new prompt to be dispatched
          // concurrently, causing double-dispatch and queue corruption.
          console.log('[SessionAgentDO] wait_for_event completed — agent turn continues');
        }
        break;
      }

      case 'question': {
        // Store question and broadcast to all clients
        const qId = msg.questionId || crypto.randomUUID();
        const questionCh = this.activeChannel;
        const QUESTION_TIMEOUT_SECS = 5 * 60; // 5 minutes
        const expiresAt = Math.floor(Date.now() / 1000) + QUESTION_TIMEOUT_SECS;
        this.ctx.storage.sql.exec(
          "INSERT INTO questions (id, text, options, status, expires_at) VALUES (?, ?, ?, 'pending', ?)",
          qId, msg.text || '', msg.options ? JSON.stringify(msg.options) : null, expiresAt
        );
        this.broadcastToClients({
          type: 'question',
          questionId: qId,
          text: msg.text,
          options: msg.options,
          expiresAt,
          ...(questionCh ? { channelType: questionCh.channelType, channelId: questionCh.channelId } : {}),
        });

        // Schedule an alarm to expire the question if unanswered
        this.ctx.storage.setAlarm(Date.now() + QUESTION_TIMEOUT_SECS * 1000);

        // Notify EventBus
        this.notifyEventBus({
          type: 'question.asked',
          sessionId: this.getStateValue('sessionId'),
          data: { questionId: qId, text: msg.text || '' },
          timestamp: new Date().toISOString(),
        });
        const ownerUserId = this.getStateValue('userId') || undefined;
        const questionSummary = msg.text?.trim()
          ? `Agent question: ${msg.text.trim()}`
          : 'Agent requested a decision.';
        if (ownerUserId && this.isUserConnected(ownerUserId)) {
          this.sendToastToUser(ownerUserId, {
            title: 'Agent question',
            description: questionSummary.slice(0, 240),
            variant: 'warning',
          });
        } else {
          await this.enqueueOwnerNotification({
            messageType: 'question',
            content: questionSummary,
            contextSessionId: this.getStateValue('sessionId') || undefined,
          });
        }
        break;
      }

      case 'screenshot': {
        // Store screenshot reference and broadcast
        const ssId = crypto.randomUUID();
        const ssCh = this.activeChannel;
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, parts, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?)',
          ssId, 'system', msg.description || 'Screenshot',
          JSON.stringify({ type: 'screenshot', data: msg.data }),
          ssCh?.channelType ?? null, ssCh?.channelId ?? null
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: ssId,
            role: 'system',
            content: msg.description || 'Screenshot',
            parts: { type: 'screenshot', data: msg.data },
            createdAt: Math.floor(Date.now() / 1000),
            ...(ssCh ? { channelType: ssCh.channelType, channelId: ssCh.channelId } : {}),
          },
        });
        break;
      }

      case 'audio-transcript': {
        // Runner transcribed audio attachments — update the original user message parts with transcript
        if (msg.messageId && msg.transcript) {
          const existing = this.ctx.storage.sql.exec(
            'SELECT parts FROM messages WHERE id = ?', msg.messageId,
          ).toArray();
          if (existing.length > 0) {
            const rawParts = existing[0].parts as string | null;
            let parts: Array<Record<string, unknown>> = [];
            if (rawParts) {
              try {
                const parsed = JSON.parse(rawParts);
                parts = Array.isArray(parsed) ? parsed : [parsed];
              } catch { /* ignore */ }
            }
            // Add transcript to each audio part
            for (const part of parts) {
              if (part.type === 'audio') {
                part.transcript = msg.transcript;
              }
            }
            this.ctx.storage.sql.exec(
              'UPDATE messages SET parts = ? WHERE id = ?',
              JSON.stringify(parts), msg.messageId,
            );
            // Broadcast updated message to all clients
            this.broadcastToClients({
              type: 'message.updated',
              data: { id: msg.messageId, parts },
            });
          }
        }
        break;
      }

      case 'error': {
        // Store error and broadcast
        // Always generate a new ID — msg.messageId is the prompt's user message ID,
        // which already exists in the messages table (PRIMARY KEY conflict).
        const errId = crypto.randomUUID();
        const errCh = this.activeChannel;
        const errorText = msg.error || msg.content || 'Unknown error';
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, channel_type, channel_id) VALUES (?, ?, ?, ?, ?)',
          errId, 'system', `Error: ${errorText}`, errCh?.channelType ?? null, errCh?.channelId ?? null
        );
        this.broadcastToClients({
          type: 'error',
          messageId: errId,
          error: msg.error || msg.content,
          ...(errCh ? { channelType: errCh.channelType, channelId: errCh.channelId } : {}),
        });
        this.appendAuditLog('agent.error', errorText.slice(0, 120));

        // Publish session.errored to EventBus
        this.notifyEventBus({
          type: 'session.errored',
          sessionId: this.getStateValue('sessionId') || undefined,
          userId: this.getStateValue('userId') || undefined,
          data: { error: errorText, messageId: errId },
          timestamp: new Date().toISOString(),
        });
        await this.enqueueOwnerNotification({
          messageType: 'escalation',
          content: `Session error: ${errorText}`,
          contextSessionId: this.getStateValue('sessionId') || undefined,
        });
        break;
      }

      case 'complete':
        // Prompt finished — auto-reply to originating channel if needed
        await this.flushPendingChannelReply();
        // Check queue for next
        console.log(`[SessionAgentDO] Complete received, processing queue`);
        await this.handlePromptComplete();
        // Flush metrics after each agent turn
        this.ctx.waitUntil(this.flushMetrics());
        break;

      case 'agentStatus': {
        // Forward agent status to all clients for real-time activity indication
        const statusCh = this.activeChannel;
        this.broadcastToClients({
          type: 'agentStatus',
          status: msg.status,
          detail: msg.detail,
          ...(statusCh ? { channelType: statusCh.channelType, channelId: statusCh.channelId } : {}),
        });
        if (msg.status === 'idle') {
          console.log(`[SessionAgentDO] agentStatus: idle (runnerConnected=${this.ctx.getWebSockets('runner').length > 0}, queued=${this.getQueueLength()})`);
          // Don't set runnerBusy=false here — wait for the authoritative `complete`
          // message. Setting it here creates a window where a new prompt can bypass
          // the queue and be dispatched directly, resulting in two concurrent prompts.
          // The `complete` handler (handlePromptComplete) is the single source of truth.
          await this.notifyParentIfIdle();
        } else if (msg.status === 'thinking' || msg.status === 'tool_calling' || msg.status === 'streaming') {
          this.setStateValue('runnerBusy', 'true');
          this.setStateValue('lastParentIdleNotice', '');
        }
        break;
      }

      case 'create-pr': {
        // Runner requests PR creation — call GitHub API directly
        await this.handleCreatePR({
          requestId: msg.requestId,
          branch: msg.branch!,
          title: msg.title!,
          body: msg.body,
          base: msg.base,
        });
        break;
      }

      case 'update-pr': {
        // Runner requests PR update — call GitHub API directly
        await this.handleUpdatePR({
          requestId: msg.requestId,
          prNumber: msg.prNumber!,
          title: msg.title,
          body: msg.body,
          state: msg.state,
          labels: msg.labels,
        });
        break;
      }

      case 'models':
        // Runner discovered available models — store and broadcast to clients
        if (msg.models) {
          this.setStateValue('availableModels', JSON.stringify(msg.models));
          this.broadcastToClients({
            type: 'models',
            models: msg.models,
          });
          // Persist to D1 so the settings typeahead works without a running session
          const userId = this.getStateValue('userId');
          if (userId) {
            this.env.DB.prepare('UPDATE users SET discovered_models = ? WHERE id = ?')
              .bind(JSON.stringify(msg.models), userId)
              .run()
              .catch((err: unknown) => console.error('[SessionAgentDO] Failed to cache models to D1:', err));
          }
        }
        break;

      case 'model-switched': {
        // Runner switched models due to provider error — store notice and broadcast
        const switchId = crypto.randomUUID();
        const switchText = `Model switched from ${msg.fromModel} to ${msg.toModel}: ${msg.reason}`;
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
          switchId, 'system', switchText
        );
        this.broadcastToClients({
          type: 'model-switched',
          messageId: switchId,
          fromModel: msg.fromModel,
          toModel: msg.toModel,
          reason: msg.reason,
        });
        this.appendAuditLog('agent.error', switchText.slice(0, 120));
        break;
      }

      case 'aborted':
        // Runner confirmed abort — mark idle, broadcast
        this.setStateValue('runnerBusy', 'false');
        this.broadcastToClients({
          type: 'agentStatus',
          status: 'idle',
        });
        this.broadcastToClients({
          type: 'status',
          data: { runnerBusy: false, aborted: true },
        });
        // Drain the queue — if prompts were queued after abort, process them now
        await this.handlePromptComplete();
        break;

      case 'reverted':
        // Runner confirmed revert — log for now
        console.log(`[SessionAgentDO] Revert confirmed for messages: ${msg.messageIds?.join(', ')}`);
        break;

      case 'diff':
        // Runner returned diff data — broadcast to clients
        // Runner sends { type, requestId, data: { files } } or { type, requestId, files }
        const diffPayload = typeof msg.data === 'object' && msg.data !== null ? msg.data as Record<string, unknown> : null;
        const diffFiles = diffPayload?.files ?? msg.files ?? [];
        this.broadcastToClients({
          type: 'diff',
          requestId: msg.requestId,
          data: { files: diffFiles },
        });
        break;

      case 'review-result':
        // Runner returned structured review result — broadcast to clients (not stored in DB)
        this.broadcastToClients({
          type: 'review-result',
          requestId: msg.requestId,
          data: msg.data,
          diffFiles: msg.diffFiles,
          error: msg.error,
        });
        break;

      case 'command-result':
        // Runner returned OpenCode command result — broadcast to clients
        this.broadcastToClients({
          type: 'command-result',
          requestId: msg.requestId,
          command: (msg as any).command,
          result: (msg as any).result ?? msg.data,
          error: msg.error,
        });
        break;

      case 'git-state': {
        // Runner reports current git branch/commit state
        const sessionId = this.getStateValue('sessionId');
        if (sessionId) {
          const gitUpdates: Record<string, string | number> = {};
          if (msg.branch !== undefined) gitUpdates.branch = msg.branch;
          if (msg.baseBranch !== undefined) gitUpdates.baseBranch = msg.baseBranch;
          if (msg.commitCount !== undefined) gitUpdates.commitCount = msg.commitCount;

          if (Object.keys(gitUpdates).length > 0) {
            updateSessionGitState(this.env.DB, sessionId, gitUpdates as any).catch((err) =>
              console.error('[SessionAgentDO] Failed to update git state in D1:', err),
            );
          }
        }
        this.broadcastToClients({
          type: 'git-state',
          data: {
            branch: msg.branch,
            baseBranch: msg.baseBranch,
            commitCount: msg.commitCount,
          },
        } as any);
        break;
      }

      case 'pr-created': {
        // Runner reports a PR was created
        const sessionIdPr = this.getStateValue('sessionId');
        if (sessionIdPr && msg.number) {
          updateSessionGitState(this.env.DB, sessionIdPr, {
            prNumber: msg.number,
            prTitle: msg.title,
            prUrl: msg.url,
            prState: (msg.status as any) || 'open',
            prCreatedAt: new Date().toISOString(),
          }).catch((err) =>
            console.error('[SessionAgentDO] Failed to update PR state in D1:', err),
          );
        }
        this.broadcastToClients({
          type: 'pr-created',
          data: {
            number: msg.number,
            title: msg.title,
            url: msg.url,
            state: msg.status || 'open',
          },
        } as any);
        this.appendAuditLog('git.pr_created', `PR #${msg.number}: ${msg.title || ''}`, undefined, { prNumber: msg.number, prUrl: msg.url });
        break;
      }

      case 'files-changed': {
        // Runner reports files changed — upsert in D1, broadcast to clients
        const sessionIdFc = this.getStateValue('sessionId');
        const filesChanged = (msg as any).files as Array<{ path: string; status: string; additions?: number; deletions?: number }> | undefined;
        if (sessionIdFc && Array.isArray(filesChanged)) {
          for (const file of filesChanged) {
            upsertSessionFileChanged(this.env.DB, sessionIdFc, {
              filePath: file.path,
              status: file.status,
              additions: file.additions,
              deletions: file.deletions,
            }).catch((err) =>
              console.error('[SessionAgentDO] Failed to upsert file changed:', err),
            );
          }
        }
        this.broadcastToClients({
          type: 'files-changed',
          files: filesChanged ?? [],
        } as any);
        break;
      }

      case 'child-session': {
        // Runner reports a child/sub-agent session was spawned
        this.broadcastToClients({
          type: 'child-session',
          childSessionId: (msg as any).childSessionId,
          title: msg.title,
        } as any);
        break;
      }

      case 'title': {
        // Runner reports session title update
        const sessionIdTitle = this.getStateValue('sessionId');
        const newTitle = msg.title || msg.content;
        if (sessionIdTitle && newTitle) {
          this.setStateValue('title', newTitle);
          updateSessionTitle(this.env.DB, sessionIdTitle, newTitle).catch((err) =>
            console.error('[SessionAgentDO] Failed to update session title:', err),
          );
        }
        this.broadcastToClients({
          type: 'title',
          title: newTitle,
        } as any);
        break;
      }

      case 'spawn-child':
        await this.handleSpawnChild(msg.requestId!, {
          task: msg.task!,
          workspace: msg.workspace!,
          repoUrl: msg.repoUrl,
          branch: msg.branch,
          ref: msg.ref,
          title: msg.title,
          sourceType: msg.sourceType,
          sourcePrNumber: msg.sourcePrNumber,
          sourceIssueNumber: msg.sourceIssueNumber,
          sourceRepoFullName: msg.sourceRepoFullName,
          model: msg.model,
        });
        break;

      case 'session-message':
        await this.handleSessionMessage(msg.requestId!, msg.targetSessionId!, msg.content!, msg.interrupt);
        break;

      case 'session-messages':
        await this.handleSessionMessages(msg.requestId!, msg.targetSessionId!, msg.limit, msg.after);
        break;

      case 'terminate-child':
        await this.handleTerminateChild(msg.requestId!, msg.childSessionId!);
        break;

      case 'channel-session-created': {
        // Runner reports a new per-channel OpenCode session — store in channel_state
        const csChannelKey = msg.channelKey as string | undefined;
        const csOcSessionId = msg.opencodeSessionId as string | undefined;
        if (csChannelKey && csOcSessionId) {
          this.setChannelOcSessionId(csChannelKey, csOcSessionId);
          console.log(`[SessionAgentDO] Channel session created: ${csChannelKey} -> ${csOcSessionId}`);
        }
        break;
      }

      case 'session-reset': {
        // Runner confirmed session rotation — insert visual break marker
        const breakId = crypto.randomUUID();
        const srChannelType = (msg as any).channelType as string | undefined;
        const srChannelId = (msg as any).channelId as string | undefined;
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, parts, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?)',
          breakId, 'system', 'New session started',
          JSON.stringify({ type: 'session-break' }),
          srChannelType ?? null, srChannelId ?? null
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: breakId,
            role: 'system',
            content: 'New session started',
            parts: { type: 'session-break' },
            createdAt: Math.floor(Date.now() / 1000),
            channelType: srChannelType,
            channelId: srChannelId,
          },
        });
        break;
      }

      case 'self-terminate':
        await this.handleSelfTerminate();
        break;

      // ─── Orchestrator Operations ──────────────────────────────────────
      case 'memory-read':
        await this.handleMemoryRead(msg.requestId!, msg.category, msg.query, msg.limit);
        break;

      case 'memory-write':
        await this.handleMemoryWrite(msg.requestId!, msg.content!, msg.category!);
        break;

      case 'memory-delete':
        await this.handleMemoryDelete(msg.requestId!, msg.memoryId!);
        break;

      case 'list-repos':
        await this.handleListRepos(msg.requestId!, msg.source);
        break;

      case 'list-pull-requests':
        await this.handleListPullRequests(msg.requestId!, {
          owner: msg.owner,
          repo: msg.repo,
          state: msg.state,
          limit: msg.limit,
        });
        break;

      case 'inspect-pull-request':
        await this.handleInspectPullRequest(msg.requestId!, {
          prNumber: msg.prNumber!,
          owner: msg.owner,
          repo: msg.repo,
          filesLimit: msg.filesLimit,
          commentsLimit: msg.commentsLimit,
        });
        break;

      case 'list-personas':
        await this.handleListPersonas(msg.requestId!);
        break;

      case 'list-channels':
        await this.handleListChannels(msg.requestId!);
        break;

      case 'get-session-status':
        await this.handleGetSessionStatus(msg.requestId!, msg.targetSessionId!);
        break;

      case 'list-child-sessions':
        await this.handleListChildSessions(msg.requestId!);
        break;
      case 'read-repo-file':
        await this.handleReadRepoFile(msg.requestId!, {
          owner: msg.owner,
          repo: msg.repo,
          repoUrl: msg.repoUrl,
          path: msg.path,
          ref: msg.ref,
        });
        break;

      case 'forward-messages':
        await this.handleForwardMessages(msg.requestId!, msg.targetSessionId!, msg.limit, msg.after);
        break;

      case 'workflow-list':
        await this.handleWorkflowList(msg.requestId!);
        break;

      case 'workflow-sync':
        await this.handleWorkflowSync(msg.requestId!, {
          id: msg.id || msg.workflowId,
          slug: msg.slug,
          name: msg.name || msg.title,
          description: msg.description,
          version: msg.version,
          data: (typeof msg.data === 'object' && msg.data !== null && !Array.isArray(msg.data))
            ? (msg.data as Record<string, unknown>)
            : msg.dataJson,
        });
        break;

      case 'workflow-run':
        await this.handleWorkflowRun(msg.requestId!, msg.workflowId!, msg.variables, {
          repoUrl: msg.repoUrl,
          branch: msg.branch,
          ref: msg.ref,
          sourceRepoFullName: msg.sourceRepoFullName,
        });
        break;

      case 'workflow-executions':
        await this.handleWorkflowExecutions(msg.requestId!, msg.workflowId, msg.limit);
        break;

      case 'workflow-api':
        await this.handleWorkflowApi(msg.requestId!, msg.action || '', msg.payload);
        break;

      case 'trigger-api':
        await this.handleTriggerApi(msg.requestId!, msg.action || '', msg.payload);
        break;

      case 'execution-api':
        await this.handleExecutionApi(msg.requestId!, msg.action || '', msg.payload);
        break;

      case 'workflow-execution-result':
        await this.handleWorkflowExecutionResult(msg);
        break;

      // ─── Phase C: Mailbox + Task Board ──────────────────────────────
      case 'mailbox-send':
        await this.handleMailboxSend(msg.requestId!, msg);
        break;

      case 'mailbox-check':
        await this.handleMailboxCheck(msg.requestId!, msg.limit, msg.after);
        break;

      case 'task-create':
        await this.handleTaskCreate(msg.requestId!, msg);
        break;

      case 'task-list':
        await this.handleTaskList(msg.requestId!, msg.status, msg.limit);
        break;

      case 'task-update':
        await this.handleTaskUpdate(msg.requestId!, msg.taskId!, msg);
        break;

      case 'task-my':
        await this.handleTaskMy(msg.requestId!, msg.status);
        break;

      // ─── Phase D: Channel Reply ──────────────────────────────────────
      case 'channel-reply':
        await this.handleChannelReply(msg.requestId!, msg.channelType!, msg.channelId!, msg.message || '', msg.imageBase64, msg.imageMimeType, msg.followUp);
        break;


      case 'ping':
        // Keepalive from runner — respond with pong
        this.sendToRunner({ type: 'pong' });
        break;
    }
  }

  // ─── Cross-Session Operations ─────────────────────────────────────────

  private async handleSpawnChild(
    requestId: string,
    params: {
      task: string; workspace: string; repoUrl?: string; branch?: string; ref?: string; title?: string;
      sourceType?: string; sourcePrNumber?: number; sourceIssueNumber?: number; sourceRepoFullName?: string;
      model?: string;
    },
  ) {
    try {
      const parentSessionId = this.getStateValue('sessionId')!;
      const userId = this.getStateValue('userId')!;
      const spawnRequestStr = this.getStateValue('spawnRequest');
      const backendUrl = this.getStateValue('backendUrl');
      const terminateUrl = this.getStateValue('terminateUrl');
      const hibernateUrl = this.getStateValue('hibernateUrl');
      const restoreUrl = this.getStateValue('restoreUrl');

      if (!spawnRequestStr || !backendUrl) {
        this.sendToRunner({ type: 'spawn-child-result', requestId, error: 'Session not configured for spawning children (missing spawnRequest or backendUrl)' });
        return;
      }

      const parentSpawnRequest = JSON.parse(spawnRequestStr);

      // Query parent's git state to use as defaults for the child
      const parentGitState = await getSessionGitState(this.env.DB, parentSessionId);

      // Merge: explicit params override parent defaults
      const mergedRepoUrl = params.repoUrl || parentGitState?.sourceRepoUrl || undefined;
      const mergedBranch = params.branch || parentGitState?.branch || undefined;
      const mergedRef = params.ref || parentGitState?.ref || undefined;
      const mergedSourceType = params.sourceType || parentGitState?.sourceType || undefined;
      const mergedSourcePrNumber = params.sourcePrNumber ?? parentGitState?.sourcePrNumber ?? undefined;
      const mergedSourceIssueNumber = params.sourceIssueNumber ?? parentGitState?.sourceIssueNumber ?? undefined;
      const mergedSourceRepoFullName = params.sourceRepoFullName || parentGitState?.sourceRepoFullName || undefined;

      // Generate child session identifiers
      const childSessionId = crypto.randomUUID();
      const childRunnerToken = Array.from(crypto.getRandomValues(new Uint8Array(32)))
        .map((b) => b.toString(16).padStart(2, '0'))
        .join('');

      // Create child session in D1
      await createSession(this.env.DB, {
        id: childSessionId,
        userId,
        workspace: params.workspace,
        title: params.title || params.workspace,
        parentSessionId,
      });

      // Create git state for child (always create if we have any git context)
      if (mergedRepoUrl || mergedSourceType) {
        // Derive sourceRepoFullName from URL if not explicitly set
        let derivedRepoFullName = mergedSourceRepoFullName;
        if (!derivedRepoFullName && mergedRepoUrl) {
          const match = mergedRepoUrl.match(/github\.com[/:]([^/]+\/[^/.]+)/);
          if (match) derivedRepoFullName = match[1];
        }

        await createSessionGitState(this.env.DB, {
          sessionId: childSessionId,
          sourceType: (mergedSourceType as any) || 'branch',
          sourceRepoUrl: mergedRepoUrl,
          sourceRepoFullName: derivedRepoFullName,
          branch: mergedBranch,
          ref: mergedRef,
          sourcePrNumber: mergedSourcePrNumber,
          sourceIssueNumber: mergedSourceIssueNumber,
        });
      }

      // Build child DO WebSocket URL
      // Extract host from backendUrl or use the parent's DO WebSocket pattern
      const parentDoWsUrl = parentSpawnRequest.doWsUrl as string;
      // Replace parent sessionId with child sessionId in the URL
      const childDoWsUrl = parentDoWsUrl.replace(parentSessionId, childSessionId);

      // Build child spawn request, inheriting parent env vars
      const childSpawnRequest = {
        ...parentSpawnRequest,
        sessionId: childSessionId,
        doWsUrl: childDoWsUrl,
        runnerToken: childRunnerToken,
        workspace: params.workspace,
        envVars: {
          ...parentSpawnRequest.envVars,
          PARENT_SESSION_ID: parentSessionId,
        },
      };

      // Override repo-specific env vars if we have repo info (explicit or inherited)
      if (mergedRepoUrl) {
        childSpawnRequest.envVars = {
          ...childSpawnRequest.envVars,
          REPO_URL: mergedRepoUrl,
        };
        if (mergedBranch) {
          childSpawnRequest.envVars.REPO_BRANCH = mergedBranch;
        }
        if (mergedRef) {
          childSpawnRequest.envVars.REPO_REF = mergedRef;
        }

        // Inject git credentials if the parent doesn't have them (e.g. orchestrator)
        if (!childSpawnRequest.envVars.GITHUB_TOKEN) {
          try {
            const oauthToken = await getOAuthToken(this.env.DB, userId, 'github');
            if (oauthToken) {
              childSpawnRequest.envVars.GITHUB_TOKEN = await decryptString(
                oauthToken.encryptedAccessToken,
                this.env.ENCRYPTION_KEY,
              );
            }
          } catch (err) {
            console.warn('[SessionAgentDO] Failed to fetch GitHub token for child:', err);
          }
        }

        // Inject git user identity if missing
        if (!childSpawnRequest.envVars.GIT_USER_NAME || !childSpawnRequest.envVars.GIT_USER_EMAIL) {
          try {
            const userRow = await getUserById(this.env.DB, userId);
            if (userRow) {
              if (!childSpawnRequest.envVars.GIT_USER_NAME) {
                childSpawnRequest.envVars.GIT_USER_NAME = userRow.gitName || userRow.name || userRow.githubUsername || 'Agent Ops User';
              }
              if (!childSpawnRequest.envVars.GIT_USER_EMAIL) {
                childSpawnRequest.envVars.GIT_USER_EMAIL = userRow.gitEmail || userRow.email;
              }
            }
          } catch (err) {
            console.warn('[SessionAgentDO] Failed to fetch user info for child git config:', err);
          }
        }
      }

      // Initialize child SessionAgentDO
      const childDoId = this.env.SESSIONS.idFromName(childSessionId);
      const childDO = this.env.SESSIONS.get(childDoId);

      const idleTimeoutMsStr = this.getStateValue('idleTimeoutMs');
      const idleTimeoutMs = idleTimeoutMsStr ? parseInt(idleTimeoutMsStr) : 900_000;

      await childDO.fetch(new Request('http://do/start', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          sessionId: childSessionId,
          userId,
          workspace: params.workspace,
          runnerToken: childRunnerToken,
          backendUrl,
          terminateUrl: terminateUrl || undefined,
          hibernateUrl: hibernateUrl || undefined,
          restoreUrl: restoreUrl || undefined,
          idleTimeoutMs,
          spawnRequest: childSpawnRequest,
          initialPrompt: params.task,
          initialModel: params.model,
        }),
      }));

      this.sendToRunner({ type: 'spawn-child-result', requestId, childSessionId });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to spawn child:', err);
      this.sendToRunner({
        type: 'spawn-child-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  private async handleSessionMessage(requestId: string, targetSessionId: string, content: string, interrupt?: boolean) {
    try {
      const userId = this.getStateValue('userId')!;

      // Verify target session belongs to the same user
      const targetSession = await getSession(this.env.DB, targetSessionId);
      if (!targetSession || targetSession.userId !== userId) {
        this.sendToRunner({ type: 'session-message-result', requestId, error: 'Session not found or access denied' });
        return;
      }

      // Forward prompt to target DO
      const targetDoId = this.env.SESSIONS.idFromName(targetSessionId);
      const targetDO = this.env.SESSIONS.get(targetDoId);

      const resp = await targetDO.fetch(new Request('http://do/prompt', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ content, interrupt: interrupt ?? false }),
      }));

      if (!resp.ok) {
        const errText = await resp.text();
        this.sendToRunner({ type: 'session-message-result', requestId, error: `Target DO returned ${resp.status}: ${errText}` });
        return;
      }

      this.sendToRunner({ type: 'session-message-result', requestId, success: true });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to send message:', err);
      this.sendToRunner({
        type: 'session-message-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  private async handleSessionMessages(requestId: string, targetSessionId: string, limit?: number, after?: string) {
    try {
      const userId = this.getStateValue('userId')!;

      // Verify target session belongs to the same user
      const targetSession = await getSession(this.env.DB, targetSessionId);
      if (!targetSession || targetSession.userId !== userId) {
        this.sendToRunner({ type: 'session-messages-result', requestId, error: 'Session not found or access denied' });
        return;
      }

      // Fetch messages from the target DO's local SQLite (not D1)
      const messages = await this.fetchMessagesFromDO(targetSessionId, limit || 20, after);

      this.sendToRunner({
        type: 'session-messages-result',
        requestId,
        messages: messages.map((m: { role: string; content: string; createdAt: string }) => ({
          role: m.role,
          content: m.content,
          createdAt: m.createdAt,
        })),
      });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to read messages:', err);
      this.sendToRunner({
        type: 'session-messages-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  private async handleForwardMessages(requestId: string, targetSessionId: string, limit?: number, after?: string) {
    try {
      const userId = this.getStateValue('userId')!;

      // Verify target session belongs to the same user
      const targetSession = await getSession(this.env.DB, targetSessionId);
      if (!targetSession || targetSession.userId !== userId) {
        this.sendToRunner({ type: 'forward-messages-result', requestId, error: 'Session not found or access denied' });
        return;
      }

      // Fetch messages from target DO
      const messages = await this.fetchMessagesFromDO(targetSessionId, limit || 20, after);

      if (messages.length === 0) {
        this.sendToRunner({ type: 'forward-messages-result', requestId, count: 0, sourceSessionId: targetSessionId });
        return;
      }

      // Insert each message into our own messages table with forwarded metadata
      const sessionTitle = targetSession.title || targetSession.workspace || targetSessionId.slice(0, 8);
      for (const msg of messages) {
        const newId = crypto.randomUUID();
        const parts = JSON.stringify({
          forwarded: true,
          sourceSessionId: targetSessionId,
          sourceSessionTitle: sessionTitle,
          originalRole: msg.role,
          originalCreatedAt: msg.createdAt,
        });

        // Store all forwarded messages as 'assistant' role for consistent left-aligned rendering
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, parts) VALUES (?, ?, ?, ?)',
          newId, 'assistant', msg.content, parts
        );

        this.broadcastToClients({
          type: 'message',
          data: {
            id: newId,
            role: 'assistant',
            content: msg.content,
            parts: {
              forwarded: true,
              sourceSessionId: targetSessionId,
              sourceSessionTitle: sessionTitle,
              originalRole: msg.role,
              originalCreatedAt: msg.createdAt,
            },
            createdAt: Math.floor(Date.now() / 1000),
          },
        });
      }

      this.sendToRunner({
        type: 'forward-messages-result',
        requestId,
        count: messages.length,
        sourceSessionId: targetSessionId,
      });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to forward messages:', err);
      this.sendToRunner({
        type: 'forward-messages-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  /** Fetch messages from another session's DO via internal HTTP endpoint. */
  private async fetchMessagesFromDO(
    targetSessionId: string,
    limit: number,
    after?: string,
  ): Promise<Array<{ role: string; content: string; createdAt: string }>> {
    const doId = this.env.SESSIONS.idFromName(targetSessionId);
    const targetDO = this.env.SESSIONS.get(doId);

    const params = new URLSearchParams({ limit: String(limit) });
    if (after) params.set('after', after);

    const res = await targetDO.fetch(new Request(`http://do/messages?${params}`));
    if (!res.ok) {
      throw new Error(`Target DO returned ${res.status}: ${await res.text()}`);
    }

    const data = await res.json() as { messages: Array<{ role: string; content: string; createdAt: string }> };
    return data.messages;
  }

  private async handleTerminateChild(requestId: string, childSessionId: string) {
    try {
      const sessionId = this.getStateValue('sessionId')!;
      const userId = this.getStateValue('userId')!;

      // Verify the child belongs to this parent session
      const childSession = await getSession(this.env.DB, childSessionId);
      if (!childSession || childSession.userId !== userId) {
        this.sendToRunner({ type: 'terminate-child-result', requestId, error: 'Child session not found or access denied' });
        return;
      }
      if (childSession.parentSessionId !== sessionId) {
        this.sendToRunner({ type: 'terminate-child-result', requestId, error: 'Session is not a child of this session' });
        return;
      }

      // Stop the child via its DO
      const childDoId = this.env.SESSIONS.idFromName(childSessionId);
      const childDO = this.env.SESSIONS.get(childDoId);
      const resp = await childDO.fetch(new Request('http://do/stop', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ reason: 'parent_stopped' }),
      }));

      if (!resp.ok) {
        const errText = await resp.text();
        this.sendToRunner({ type: 'terminate-child-result', requestId, error: `Child DO returned ${resp.status}: ${errText}` });
        return;
      }

      this.sendToRunner({ type: 'terminate-child-result', requestId, success: true });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to terminate child:', err);
      this.sendToRunner({
        type: 'terminate-child-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  private async handleSelfTerminate() {
    const sessionId = this.getStateValue('sessionId');
    console.log(`[SessionAgentDO] Session ${sessionId} self-terminating (task complete)`);

    // Reuse handleStop which handles sandbox teardown, cascade, etc.
    return await this.handleStop('completed');
  }

  // ─── Orchestrator Operations ────────────────────────────────────────────

  private async handleMemoryRead(requestId: string, category?: string, query?: string, limit?: number) {
    try {
      const userId = this.getStateValue('userId')!;
      const memories = await listOrchestratorMemories(this.env.DB, userId, { category, query, limit });

      // Boost relevance for accessed memories
      for (const mem of memories) {
        boostMemoryRelevance(this.env.DB, mem.id).catch(() => {});
      }

      this.sendToRunner({ type: 'memory-read-result', requestId, memories } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to read memories:', err);
      this.sendToRunner({ type: 'memory-read-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleMemoryWrite(requestId: string, content: string, category: string) {
    try {
      const userId = this.getStateValue('userId')!;
      const id = crypto.randomUUID();
      const memory = await createOrchestratorMemory(this.env.DB, {
        id,
        userId,
        category: category as any,
        content,
      });
      this.sendToRunner({ type: 'memory-write-result', requestId, memory, success: true } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to write memory:', err);
      this.sendToRunner({ type: 'memory-write-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleMemoryDelete(requestId: string, memoryId: string) {
    try {
      const userId = this.getStateValue('userId')!;
      const deleted = await deleteOrchestratorMemory(this.env.DB, memoryId, userId);
      this.sendToRunner({ type: 'memory-delete-result', requestId, success: deleted } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to delete memory:', err);
      this.sendToRunner({ type: 'memory-delete-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleListRepos(requestId: string, source?: string) {
    try {
      if (source === 'github') {
        const githubToken = await this.getGitHubToken();
        if (!githubToken) {
          this.sendToRunner({ type: 'list-repos-result', requestId, error: 'No GitHub token found — user must connect GitHub in settings' } as any);
          return;
        }
        // Fetch user's repos from GitHub API (up to 100, sorted by last push)
        const res = await fetch('https://api.github.com/user/repos?per_page=100&sort=pushed&affiliation=owner,collaborator,organization_member', {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        });
        if (!res.ok) {
          const errText = await res.text();
          this.sendToRunner({ type: 'list-repos-result', requestId, error: `GitHub API error (${res.status}): ${errText}` } as any);
          return;
        }
        const ghRepos = await res.json() as { full_name: string; html_url: string; clone_url: string; description: string | null; language: string | null; default_branch: string; private: boolean; pushed_at: string }[];
        const repos = ghRepos.map(r => ({
          fullName: r.full_name,
          url: r.clone_url,
          htmlUrl: r.html_url,
          description: r.description,
          language: r.language,
          defaultBranch: r.default_branch,
          visibility: r.private ? 'private' : 'public',
          lastPushed: r.pushed_at,
        }));
        this.sendToRunner({ type: 'list-repos-result', requestId, repos } as any);
      } else {
        const repos = await listOrgRepositories(this.env.DB);
        this.sendToRunner({ type: 'list-repos-result', requestId, repos } as any);
      }
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list repos:', err);
      this.sendToRunner({ type: 'list-repos-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleWorkflowList(requestId: string) {
    try {
      const userId = this.getStateValue('userId')!;
      const result = await this.env.DB.prepare(`
        SELECT id, slug, name, description, version, data, enabled, tags, created_at, updated_at
        FROM workflows
        WHERE user_id = ?
        ORDER BY updated_at DESC
      `).bind(userId).all();

      const workflows = (result.results || []).map((row) => {
        let data: Record<string, unknown> = {};
        let tags: string[] = [];
        try { data = JSON.parse(String(row.data || '{}')); } catch {}
        try { tags = row.tags ? JSON.parse(String(row.tags)) : []; } catch {}
        return {
          id: row.id,
          slug: row.slug,
          name: row.name,
          description: row.description,
          version: row.version,
          data,
          enabled: Boolean(row.enabled),
          tags,
          createdAt: row.created_at,
          updatedAt: row.updated_at,
        };
      });

      this.sendToRunner({ type: 'workflow-list-result', requestId, workflows } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list workflows:', err);
      this.sendToRunner({ type: 'workflow-list-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleWorkflowSync(
    requestId: string,
    params: {
      id?: string;
      slug?: string;
      name?: string;
      description?: string;
      version?: string;
      data?: Record<string, unknown>;
    },
  ) {
    try {
      const userId = this.getStateValue('userId')!;
      const name = (params.name || '').trim();
      if (!name) {
        this.sendToRunner({ type: 'workflow-sync-result', requestId, error: 'Workflow name is required' } as any);
        return;
      }
      const validation = validateWorkflowDefinition(params.data);
      if (!validation.valid) {
        this.sendToRunner({ type: 'workflow-sync-result', requestId, error: `Invalid workflow definition: ${validation.errors[0]}` } as any);
        return;
      }

      const workflowId = (params.id || '').trim() || `wf_${crypto.randomUUID().replace(/-/g, '').slice(0, 12)}`;
      const slug = (params.slug || '')
        .trim()
        .toLowerCase()
        .replace(/[^a-z0-9]+/g, '-')
        .replace(/^-+|-+$/g, '')
        .slice(0, 80) || null;
      const version = (params.version || '1.0.0').trim() || '1.0.0';
      const now = new Date().toISOString();

      await this.env.DB.prepare(`
        INSERT INTO workflows (id, user_id, slug, name, description, version, data, enabled, updated_at, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, 1, ?, ?)
        ON CONFLICT(id) DO UPDATE SET
          slug = excluded.slug,
          name = excluded.name,
          description = excluded.description,
          version = excluded.version,
          data = excluded.data,
          updated_at = excluded.updated_at
      `).bind(
        workflowId,
        userId,
        slug,
        name,
        params.description || null,
        version,
        JSON.stringify(params.data),
        now,
        now,
      ).run();

      const workflow = {
        id: workflowId,
        slug,
        name,
        description: params.description || null,
        version,
        data: params.data,
        enabled: true,
        tags: [],
        createdAt: now,
        updatedAt: now,
      };

      this.sendToRunner({ type: 'workflow-sync-result', requestId, success: true, workflow } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to sync workflow:', err);
      this.sendToRunner({ type: 'workflow-sync-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private deriveRepoFullName(repoUrl?: string, sourceRepoFullName?: string): string | undefined {
    const explicit = sourceRepoFullName?.trim();
    if (explicit) return explicit;

    const rawUrl = repoUrl?.trim();
    if (!rawUrl) return undefined;

    const match = rawUrl.match(/github\.com[/:]([^/]+\/[^/.]+)/i);
    return match?.[1] || undefined;
  }

  private deriveWorkerOriginFromSpawnRequest(): string | undefined {
    const spawnRequestRaw = this.getStateValue('spawnRequest');
    if (!spawnRequestRaw) return undefined;

    try {
      const parsed = JSON.parse(spawnRequestRaw) as { doWsUrl?: unknown };
      const doWsUrl = typeof parsed?.doWsUrl === 'string' ? parsed.doWsUrl.trim() : '';
      if (!doWsUrl) return undefined;
      return new URL(doWsUrl).origin;
    } catch {
      return undefined;
    }
  }

  private async handleWorkflowRun(
    requestId: string,
    workflowId: string,
    variables?: Record<string, unknown>,
    repoContext?: { repoUrl?: string; branch?: string; ref?: string; sourceRepoFullName?: string },
  ) {
    try {
      const userId = this.getStateValue('userId')!;
      const workflowLookupId = (workflowId || '').trim();
      if (!workflowLookupId) {
        this.sendToRunner({ type: 'workflow-run-result', requestId, error: 'workflowId is required' } as any);
        return;
      }

      const workflow = await this.env.DB.prepare(`
        SELECT id, name, version, data
        FROM workflows
        WHERE (id = ? OR slug = ?) AND user_id = ?
        LIMIT 1
      `).bind(workflowLookupId, workflowLookupId, userId).first<{
        id: string;
        name: string;
        version: string | null;
        data: string;
      }>();

      if (!workflow) {
        this.sendToRunner({ type: 'workflow-run-result', requestId, error: `Workflow not found: ${workflowLookupId}` } as any);
        return;
      }

      const concurrency = await checkWorkflowConcurrency(this.env.DB, userId);
      if (!concurrency.allowed) {
        this.sendToRunner({
          type: 'workflow-run-result',
          requestId,
          error: `Too many concurrent executions (${concurrency.reason})`,
        } as any);
        return;
      }

      const idempotencyKey = `agent:${workflow.id}:${userId}:${requestId}`;
      const existing = await this.env.DB.prepare(`
        SELECT id, status, session_id
        FROM workflow_executions
        WHERE workflow_id = ? AND idempotency_key = ?
        LIMIT 1
      `).bind(workflow.id, idempotencyKey).first<{
        id: string;
        status: string;
        session_id: string | null;
      }>();

      if (existing) {
        this.sendToRunner({
          type: 'workflow-run-result',
          requestId,
          execution: {
            executionId: existing.id,
            workflowId: workflow.id,
            workflowName: workflow.name,
            status: existing.status,
            sessionId: existing.session_id,
            deduplicated: true,
          },
        } as any);
        return;
      }

      const executionId = crypto.randomUUID();
      const now = new Date().toISOString();
      const workflowHash = await sha256Hex(String(workflow.data || '{}'));
      const repoUrl = repoContext?.repoUrl?.trim() || undefined;
      const branch = repoContext?.branch?.trim() || undefined;
      const ref = repoContext?.ref?.trim() || undefined;
      const workerOrigin = this.deriveWorkerOriginFromSpawnRequest();
      const sourceRepoFullName = this.deriveRepoFullName(repoUrl, repoContext?.sourceRepoFullName);
      const sessionId = await createWorkflowSession(this.env.DB, {
        userId,
        workflowId: workflow.id,
        executionId,
        sourceRepoUrl: repoUrl,
        sourceRepoFullName,
        branch,
        ref,
      });

      await this.env.DB.prepare(`
        INSERT INTO workflow_executions
          (id, workflow_id, user_id, trigger_id, status, trigger_type, trigger_metadata, variables, started_at,
           workflow_version, workflow_hash, workflow_snapshot, idempotency_key, session_id, initiator_type, initiator_user_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `).bind(
        executionId,
        workflow.id,
        userId,
        null,
        'pending',
        'manual',
        JSON.stringify({ triggeredBy: 'agent_tool', direct: true }),
        JSON.stringify(variables || {}),
        now,
        workflow.version || null,
        workflowHash,
        workflow.data,
        idempotencyKey,
        sessionId,
        'manual',
        userId,
      ).run();

      const dispatched = await enqueueWorkflowExecution(this.env, {
        executionId,
        workflowId: workflow.id,
        userId,
        sessionId,
        triggerType: 'manual',
        workerOrigin,
      });

      this.sendToRunner({
        type: 'workflow-run-result',
        requestId,
        execution: {
          executionId,
          workflowId: workflow.id,
          workflowName: workflow.name,
          status: 'pending',
          sessionId,
          dispatched,
        },
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to run workflow:', err);
      this.sendToRunner({ type: 'workflow-run-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleWorkflowExecutions(requestId: string, workflowId?: string, limit?: number) {
    try {
      const userId = this.getStateValue('userId')!;
      const max = Math.min(Math.max(limit || 20, 1), 200);
      const parseMaybeJson = (raw: unknown) => {
        if (raw === null || raw === undefined) return null;
        try {
          return JSON.parse(String(raw));
        } catch {
          return null;
        }
      };

      let workflowFilterId: string | null = null;
      if (workflowId) {
        const workflow = await this.env.DB.prepare(`
          SELECT id
          FROM workflows
          WHERE (id = ? OR slug = ?) AND user_id = ?
          LIMIT 1
        `).bind(workflowId, workflowId, userId).first<{ id: string }>();
        if (!workflow) {
          this.sendToRunner({ type: 'workflow-executions-result', requestId, executions: [] } as any);
          return;
        }
        workflowFilterId = workflow.id;
      }

      const result = workflowFilterId
        ? await this.env.DB.prepare(`
            SELECT id, workflow_id, trigger_id, status, trigger_type, trigger_metadata, variables, outputs, steps, error, started_at, completed_at, session_id
            FROM workflow_executions
            WHERE user_id = ? AND workflow_id = ?
            ORDER BY started_at DESC
            LIMIT ?
          `).bind(userId, workflowFilterId, max).all()
        : await this.env.DB.prepare(`
            SELECT id, workflow_id, trigger_id, status, trigger_type, trigger_metadata, variables, outputs, steps, error, started_at, completed_at, session_id
            FROM workflow_executions
            WHERE user_id = ?
            ORDER BY started_at DESC
            LIMIT ?
          `).bind(userId, max).all();

      const executions = (result.results || []).map((row) => ({
        id: row.id,
        workflowId: row.workflow_id,
        triggerId: row.trigger_id,
        status: row.status,
        triggerType: row.trigger_type,
        triggerMetadata: parseMaybeJson(row.trigger_metadata),
        variables: parseMaybeJson(row.variables),
        outputs: parseMaybeJson(row.outputs),
        steps: parseMaybeJson(row.steps),
        error: row.error,
        startedAt: row.started_at,
        completedAt: row.completed_at,
        sessionId: row.session_id,
      }));

      this.sendToRunner({ type: 'workflow-executions-result', requestId, executions } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list workflow executions:', err);
      this.sendToRunner({ type: 'workflow-executions-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private parseJsonOrNull(raw: unknown): unknown | null {
    if (raw === null || raw === undefined) return null;
    try {
      return JSON.parse(String(raw));
    } catch {
      return null;
    }
  }

  private normalizeWorkflowRow(row: Record<string, unknown>) {
    let data: Record<string, unknown> = {};
    let tags: string[] = [];
    try { data = JSON.parse(String(row.data || '{}')); } catch {}
    try { tags = row.tags ? JSON.parse(String(row.tags)) : []; } catch {}
    return {
      id: row.id,
      slug: row.slug,
      name: row.name,
      description: row.description,
      version: row.version,
      data,
      enabled: Boolean(row.enabled),
      tags,
      createdAt: row.created_at,
      updatedAt: row.updated_at,
    };
  }

  private async resolveWorkflowIdForUser(userId: string, workflowIdOrSlug?: string | null): Promise<string | null> {
    const lookup = (workflowIdOrSlug || '').trim();
    if (!lookup) return null;
    const row = await this.env.DB.prepare(`
      SELECT id FROM workflows WHERE (id = ? OR slug = ?) AND user_id = ? LIMIT 1
    `).bind(lookup, lookup, userId).first<{ id: string }>();
    return row?.id || null;
  }

  private async handleWorkflowApi(requestId: string, action: string, payload?: Record<string, unknown>) {
    try {
      const userId = this.getStateValue('userId')!;
      const workflowIdOrSlug = typeof payload?.workflowId === 'string' ? payload.workflowId.trim() : '';
      if (!workflowIdOrSlug) {
        this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'workflowId is required' } as any);
        return;
      }

      const existing = await this.env.DB.prepare(`
        SELECT id, slug, name, description, version, data, enabled, tags, created_at, updated_at
        FROM workflows
        WHERE (id = ? OR slug = ?) AND user_id = ?
        LIMIT 1
      `).bind(workflowIdOrSlug, workflowIdOrSlug, userId).first<Record<string, unknown>>();

      if (!existing) {
        this.sendToRunner({ type: 'workflow-api-result', requestId, error: `Workflow not found: ${workflowIdOrSlug}` } as any);
        return;
      }

      if (action === 'get') {
        this.sendToRunner({ type: 'workflow-api-result', requestId, data: { workflow: this.normalizeWorkflowRow(existing) } } as any);
        return;
      }

      if (action === 'delete') {
        await this.env.DB.prepare(`DELETE FROM triggers WHERE workflow_id = ? AND user_id = ?`).bind(existing.id, userId).run();
        await this.env.DB.prepare(`DELETE FROM workflows WHERE id = ? AND user_id = ?`).bind(existing.id, userId).run();
        this.sendToRunner({ type: 'workflow-api-result', requestId, data: { success: true } } as any);
        return;
      }

      if (action !== 'update') {
        this.sendToRunner({ type: 'workflow-api-result', requestId, error: `Unsupported workflow action: ${action}` } as any);
        return;
      }

      const updates: string[] = [];
      const values: unknown[] = [];

      if (payload && Object.prototype.hasOwnProperty.call(payload, 'name')) {
        const nextName = typeof payload.name === 'string' ? payload.name : '';
        if (!nextName.trim()) {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'name must be a non-empty string' } as any);
          return;
        }
        updates.push('name = ?');
        values.push(nextName.trim());
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'description')) {
        const nextDescription = payload.description;
        if (nextDescription !== null && typeof nextDescription !== 'string') {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'description must be a string or null' } as any);
          return;
        }
        updates.push('description = ?');
        values.push(nextDescription === null ? null : nextDescription);
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'slug')) {
        const nextSlug = payload.slug;
        if (nextSlug !== null && typeof nextSlug !== 'string') {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'slug must be a string or null' } as any);
          return;
        }
        updates.push('slug = ?');
        values.push(nextSlug === null ? null : nextSlug);
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'version')) {
        const nextVersion = payload.version;
        if (typeof nextVersion !== 'string' || !nextVersion.trim()) {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'version must be a non-empty string' } as any);
          return;
        }
        updates.push('version = ?');
        values.push(nextVersion.trim());
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'enabled')) {
        const nextEnabled = payload.enabled;
        if (typeof nextEnabled !== 'boolean') {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'enabled must be a boolean' } as any);
          return;
        }
        updates.push('enabled = ?');
        values.push(nextEnabled ? 1 : 0);
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'tags')) {
        const nextTags = payload.tags;
        if (!Array.isArray(nextTags) || nextTags.some((tag) => typeof tag !== 'string')) {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'tags must be an array of strings' } as any);
          return;
        }
        updates.push('tags = ?');
        values.push(JSON.stringify(nextTags));
      }
      if (payload && Object.prototype.hasOwnProperty.call(payload, 'data')) {
        const nextData = payload.data;
        if (!nextData || typeof nextData !== 'object' || Array.isArray(nextData)) {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: 'data must be an object' } as any);
          return;
        }
        const validation = validateWorkflowDefinition(nextData);
        if (!validation.valid) {
          this.sendToRunner({ type: 'workflow-api-result', requestId, error: `Invalid workflow definition: ${validation.errors[0]}` } as any);
          return;
        }
        updates.push('data = ?');
        values.push(JSON.stringify(nextData));
      }

      if (updates.length === 0) {
        this.sendToRunner({ type: 'workflow-api-result', requestId, data: { workflow: this.normalizeWorkflowRow(existing) } } as any);
        return;
      }

      const updatedAt = new Date().toISOString();
      updates.push('updated_at = ?');
      values.push(updatedAt);
      values.push(existing.id);

      await this.env.DB.prepare(`UPDATE workflows SET ${updates.join(', ')} WHERE id = ?`).bind(...values).run();
      const updated = await this.env.DB.prepare(`
        SELECT id, slug, name, description, version, data, enabled, tags, created_at, updated_at
        FROM workflows WHERE id = ? LIMIT 1
      `).bind(existing.id).first<Record<string, unknown>>();

      this.sendToRunner({
        type: 'workflow-api-result',
        requestId,
        data: { workflow: this.normalizeWorkflowRow(updated || existing) },
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Workflow API error:', err);
      this.sendToRunner({ type: 'workflow-api-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private scheduleTargetFromConfig(config: Record<string, unknown>): 'workflow' | 'orchestrator' {
    if (config.type !== 'schedule') return 'workflow';
    return config.target === 'orchestrator' ? 'orchestrator' : 'workflow';
  }

  private requiresWorkflowForTriggerConfig(config: Record<string, unknown>): boolean {
    return config.type !== 'schedule' || this.scheduleTargetFromConfig(config) === 'workflow';
  }

  private async handleTriggerApi(requestId: string, action: string, payload?: Record<string, unknown>) {
    try {
      const userId = this.getStateValue('userId')!;

      if (action === 'list') {
        const result = await this.env.DB.prepare(`
          SELECT t.*, w.name as workflow_name
          FROM triggers t
          LEFT JOIN workflows w ON t.workflow_id = w.id
          WHERE t.user_id = ?
          ORDER BY t.created_at DESC
        `).bind(userId).all();

        const workflowFilter = typeof payload?.workflowId === 'string' ? payload.workflowId : undefined;
        const typeFilter = typeof payload?.type === 'string' ? payload.type : undefined;
        const enabledFilter = typeof payload?.enabled === 'boolean' ? payload.enabled : undefined;

        let triggers = (result.results || []).map((row) => ({
          id: row.id,
          workflowId: row.workflow_id,
          workflowName: row.workflow_name,
          name: row.name,
          enabled: Boolean(row.enabled),
          type: row.type,
          config: this.parseJsonOrNull(row.config) || {},
          variableMapping: this.parseJsonOrNull(row.variable_mapping) || null,
          lastRunAt: row.last_run_at,
          createdAt: row.created_at,
          updatedAt: row.updated_at,
        }));

        if (workflowFilter) {
          triggers = triggers.filter((trigger) => trigger.workflowId === workflowFilter || trigger.workflowName === workflowFilter);
        }
        if (typeFilter) {
          triggers = triggers.filter((trigger) => trigger.type === typeFilter);
        }
        if (enabledFilter !== undefined) {
          triggers = triggers.filter((trigger) => trigger.enabled === enabledFilter);
        }

        this.sendToRunner({ type: 'trigger-api-result', requestId, data: { triggers } } as any);
        return;
      }

      if (action === 'delete') {
        const triggerId = typeof payload?.triggerId === 'string' ? payload.triggerId.trim() : '';
        if (!triggerId) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'triggerId is required' } as any);
          return;
        }
        const result = await this.env.DB.prepare(`
          DELETE FROM triggers WHERE id = ? AND user_id = ?
        `).bind(triggerId, userId).run();
        if ((result.meta?.changes || 0) === 0) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: `Trigger not found: ${triggerId}` } as any);
          return;
        }
        this.sendToRunner({ type: 'trigger-api-result', requestId, data: { success: true } } as any);
        return;
      }

      if (action === 'create' || action === 'update') {
        const triggerId = typeof payload?.triggerId === 'string' ? payload.triggerId.trim() : '';
        const isUpdate = action === 'update';
        const hasWorkflowIdPayload = Object.prototype.hasOwnProperty.call(payload || {}, 'workflowId');
        let fallbackToUpdate = false;

        let existing = isUpdate
          ? await this.env.DB.prepare(`
              SELECT *
              FROM triggers
              WHERE id = ? AND user_id = ?
              LIMIT 1
            `).bind(triggerId, userId).first<Record<string, unknown>>()
          : null;

        if (isUpdate && !existing) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: `Trigger not found: ${triggerId}` } as any);
          return;
        }

        const rawConfig = payload?.config && typeof payload.config === 'object' && !Array.isArray(payload.config)
          ? payload.config as Record<string, unknown>
          : existing?.config
            ? (this.parseJsonOrNull(existing.config) as Record<string, unknown> | null)
            : null;
        if (!rawConfig || typeof rawConfig.type !== 'string') {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'config with type is required' } as any);
          return;
        }

        const nextNameRaw = typeof payload?.name === 'string' ? payload.name : (typeof existing?.name === 'string' ? existing.name : '');
        const nextName = (nextNameRaw || '').trim();
        if (!nextName) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'name is required' } as any);
          return;
        }

        const workflowIdPayload = Object.prototype.hasOwnProperty.call(payload || {}, 'workflowId')
          ? payload?.workflowId
          : existing?.workflow_id;
        let workflowId: string | null = null;
        if (typeof workflowIdPayload === 'string' && workflowIdPayload.trim()) {
          workflowId = await this.resolveWorkflowIdForUser(userId, workflowIdPayload);
          if (!workflowId) {
            this.sendToRunner({ type: 'trigger-api-result', requestId, error: `Workflow not found: ${workflowIdPayload}` } as any);
            return;
          }
        } else if (workflowIdPayload === null) {
          workflowId = null;
        }

        const target = this.scheduleTargetFromConfig(rawConfig);
        if (rawConfig.type === 'schedule' && target === 'orchestrator') {
          const prompt = typeof rawConfig.prompt === 'string' ? rawConfig.prompt.trim() : '';
          if (!prompt) {
            this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'schedule prompt is required when target=orchestrator' } as any);
            return;
          }
        }

        // Fallback upsert path for schedule triggers when a create call omits triggerId.
        // This prevents accidental duplicate schedules from repeated "update" attempts.
        if (!isUpdate && rawConfig.type === 'schedule') {
          if (hasWorkflowIdPayload) {
            const sameName = await this.env.DB.prepare(`
              SELECT *
              FROM triggers
              WHERE user_id = ?
                AND type = 'schedule'
                AND ((? IS NULL AND workflow_id IS NULL) OR workflow_id = ?)
                AND lower(name) = lower(?)
              ORDER BY datetime(updated_at) DESC
              LIMIT 1
            `).bind(userId, workflowId, workflowId, nextName).first<Record<string, unknown>>();

            if (sameName) {
              existing = sameName;
              fallbackToUpdate = true;
            } else {
              const workflowMatches = await this.env.DB.prepare(`
                SELECT *
                FROM triggers
                WHERE user_id = ?
                  AND type = 'schedule'
                  AND ((? IS NULL AND workflow_id IS NULL) OR workflow_id = ?)
                ORDER BY datetime(updated_at) DESC
                LIMIT 2
              `).bind(userId, workflowId, workflowId).all<Record<string, unknown>>();
              const candidates = workflowMatches.results || [];
              if (candidates.length === 1) {
                existing = candidates[0];
                fallbackToUpdate = true;
              }
            }
          } else {
            const sameName = await this.env.DB.prepare(`
              SELECT *
              FROM triggers
              WHERE user_id = ?
                AND type = 'schedule'
                AND lower(name) = lower(?)
              ORDER BY datetime(updated_at) DESC
              LIMIT 2
            `).bind(userId, nextName).all<Record<string, unknown>>();
            const candidates = sameName.results || [];
            if (candidates.length === 1) {
              existing = candidates[0];
              fallbackToUpdate = true;
              workflowId = typeof existing.workflow_id === 'string' && existing.workflow_id.trim()
                ? existing.workflow_id
                : null;
            }
          }
        }

        if (fallbackToUpdate && !hasWorkflowIdPayload) {
          workflowId = typeof existing?.workflow_id === 'string' && existing.workflow_id.trim()
            ? existing.workflow_id
            : null;
        }

        if (this.requiresWorkflowForTriggerConfig(rawConfig) && !workflowId) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'workflowId is required for this trigger type' } as any);
          return;
        }

        const nextEnabled = typeof payload?.enabled === 'boolean'
          ? payload.enabled
          : existing
            ? Boolean(existing.enabled)
            : true;

        const variableMapping = payload?.variableMapping && typeof payload.variableMapping === 'object' && !Array.isArray(payload.variableMapping)
          ? payload.variableMapping as Record<string, unknown>
          : existing?.variable_mapping
            ? (this.parseJsonOrNull(existing.variable_mapping) as Record<string, unknown> | null)
            : undefined;

        if (variableMapping) {
          for (const [key, value] of Object.entries(variableMapping)) {
            if (typeof value !== 'string') {
              this.sendToRunner({ type: 'trigger-api-result', requestId, error: `variableMapping.${key} must be a string` } as any);
              return;
            }
          }
        }

        const now = new Date().toISOString();
        const shouldUpdate = isUpdate || fallbackToUpdate;
        const targetTriggerId = shouldUpdate
          ? (typeof existing?.id === 'string' ? existing.id : triggerId)
          : crypto.randomUUID();
        if (shouldUpdate) {
          await this.env.DB.prepare(`
            UPDATE triggers
            SET workflow_id = ?,
                name = ?,
                enabled = ?,
                type = ?,
                config = ?,
                variable_mapping = ?,
                updated_at = ?
            WHERE id = ? AND user_id = ?
          `).bind(
            workflowId,
            nextName,
            nextEnabled ? 1 : 0,
            String(rawConfig.type),
            JSON.stringify(rawConfig),
            variableMapping ? JSON.stringify(variableMapping) : null,
            now,
            targetTriggerId,
            userId,
          ).run();
        } else {
          await this.env.DB.prepare(`
            INSERT INTO triggers (id, workflow_id, user_id, name, enabled, type, config, variable_mapping, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
          `).bind(
            targetTriggerId,
            workflowId,
            userId,
            nextName,
            nextEnabled ? 1 : 0,
            String(rawConfig.type),
            JSON.stringify(rawConfig),
            variableMapping ? JSON.stringify(variableMapping) : null,
            now,
            now,
          ).run();
        }

        const row = await this.env.DB.prepare(`
          SELECT t.*, w.name AS workflow_name
          FROM triggers t
          LEFT JOIN workflows w ON t.workflow_id = w.id
          WHERE t.id = ? AND t.user_id = ?
          LIMIT 1
        `).bind(targetTriggerId, userId).first<Record<string, unknown>>();

        this.sendToRunner({
          type: 'trigger-api-result',
          requestId,
          data: {
            trigger: row
              ? {
                  id: row.id,
                  workflowId: row.workflow_id,
                  workflowName: row.workflow_name,
                  name: row.name,
                  enabled: Boolean(row.enabled),
                  type: row.type,
                  config: this.parseJsonOrNull(row.config) || {},
                  variableMapping: this.parseJsonOrNull(row.variable_mapping) || null,
                  lastRunAt: row.last_run_at,
                  createdAt: row.created_at,
                  updatedAt: row.updated_at,
                }
              : null,
            success: true,
          },
        } as any);
        return;
      }

      if (action === 'run') {
        const triggerId = typeof payload?.triggerId === 'string' ? payload.triggerId.trim() : '';
        if (!triggerId) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'triggerId is required' } as any);
          return;
        }

        const row = await this.env.DB.prepare(`
          SELECT t.*, w.id as wf_id, w.name as workflow_name, w.version as workflow_version, w.data as workflow_data
          FROM triggers t
          LEFT JOIN workflows w ON t.workflow_id = w.id
          WHERE t.id = ? AND t.user_id = ?
          LIMIT 1
        `).bind(triggerId, userId).first<{
          id: string;
          type: string;
          config: string;
          wf_id: string | null;
          workflow_name: string | null;
          workflow_version: string | null;
          workflow_data: string | null;
          variable_mapping: string | null;
        }>();

        if (!row) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: `Trigger not found: ${triggerId}` } as any);
          return;
        }

        const config = this.parseJsonOrNull(row.config) as Record<string, unknown> | null;
        if (!config) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'Invalid trigger config' } as any);
          return;
        }
        const target = this.scheduleTargetFromConfig(config);

        if (config.type === 'schedule' && target === 'orchestrator') {
          const prompt = typeof config.prompt === 'string' ? config.prompt.trim() : '';
          if (!prompt) {
            this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'Schedule orchestrator trigger requires prompt' } as any);
            return;
          }

          const dispatch = await dispatchOrchestratorPrompt(this.env, {
            userId,
            content: prompt,
          });
          const now = new Date().toISOString();
          if (dispatch.dispatched) {
            await this.env.DB.prepare(`UPDATE triggers SET last_run_at = ? WHERE id = ?`).bind(now, triggerId).run();
          }
          this.sendToRunner({
            type: 'trigger-api-result',
            requestId,
            data: dispatch.dispatched
              ? {
                  status: 'queued',
                  workflowId: row.wf_id,
                  workflowName: row.workflow_name,
                  sessionId: dispatch.sessionId,
                  message: 'Orchestrator prompt dispatched.',
                }
              : {
                  status: 'failed',
                  workflowId: row.wf_id,
                  workflowName: row.workflow_name,
                  sessionId: dispatch.sessionId,
                  reason: dispatch.reason || 'unknown_error',
                },
          } as any);
          return;
        }

        if (!row.wf_id || !row.workflow_data) {
          this.sendToRunner({ type: 'trigger-api-result', requestId, error: 'Trigger is not linked to a workflow' } as any);
          return;
        }

        const concurrency = await checkWorkflowConcurrency(this.env.DB, userId);
        if (!concurrency.allowed) {
          this.sendToRunner({
            type: 'trigger-api-result',
            requestId,
            error: `Too many concurrent workflow executions (${concurrency.reason})`,
          } as any);
          return;
        }

        const variableMapping = row.variable_mapping ? (this.parseJsonOrNull(row.variable_mapping) as Record<string, string> | null) : null;
        const extractedVariables: Record<string, unknown> = {};
        for (const [varName, path] of Object.entries(variableMapping || {})) {
          if (!path.startsWith('$.')) continue;
          const key = path.slice(2).split('.')[0];
          if (payload && Object.prototype.hasOwnProperty.call(payload, key)) {
            extractedVariables[varName] = payload[key];
          }
        }

        const runtimeVariables = (payload?.variables && typeof payload.variables === 'object' && !Array.isArray(payload.variables))
          ? payload.variables as Record<string, unknown>
          : {};
        const variables = {
          ...extractedVariables,
          ...runtimeVariables,
          _trigger: { type: 'manual', triggerId },
        };

        const idempotencyKey = `manual-trigger:${triggerId}:${userId}:${requestId}`;
        const existingExecution = await this.env.DB.prepare(`
          SELECT id, status, session_id
          FROM workflow_executions
          WHERE workflow_id = ? AND idempotency_key = ?
          LIMIT 1
        `).bind(row.wf_id, idempotencyKey).first<{ id: string; status: string; session_id: string | null }>();

        if (existingExecution) {
          this.sendToRunner({
            type: 'trigger-api-result',
            requestId,
            data: {
              executionId: existingExecution.id,
              workflowId: row.wf_id,
              workflowName: row.workflow_name,
              status: existingExecution.status,
              variables,
              sessionId: existingExecution.session_id,
              message: 'Workflow execution already exists for this request.',
            },
          } as any);
          return;
        }

        const executionId = crypto.randomUUID();
        const now = new Date().toISOString();
        const workflowHash = await sha256Hex(String(row.workflow_data ?? '{}'));
        const repoUrl = typeof payload?.repoUrl === 'string' ? payload.repoUrl.trim() || undefined : undefined;
        const branch = typeof payload?.branch === 'string' ? payload.branch.trim() || undefined : undefined;
        const ref = typeof payload?.ref === 'string' ? payload.ref.trim() || undefined : undefined;
        const workerOrigin = this.deriveWorkerOriginFromSpawnRequest();
        const sourceRepoFullName = this.deriveRepoFullName(
          repoUrl,
          typeof payload?.sourceRepoFullName === 'string' ? payload.sourceRepoFullName : undefined,
        );
        const sessionId = await createWorkflowSession(this.env.DB, {
          userId,
          workflowId: row.wf_id,
          executionId,
          sourceRepoUrl: repoUrl,
          sourceRepoFullName,
          branch,
          ref,
        });

        await this.env.DB.prepare(`
          INSERT INTO workflow_executions
            (id, workflow_id, user_id, trigger_id, status, trigger_type, trigger_metadata, variables, started_at,
             workflow_version, workflow_hash, workflow_snapshot, idempotency_key, session_id, initiator_type, initiator_user_id)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).bind(
          executionId,
          row.wf_id,
          userId,
          triggerId,
          'pending',
          'manual',
          JSON.stringify({ triggeredBy: 'api' }),
          JSON.stringify(variables),
          now,
          row.workflow_version || null,
          workflowHash,
          row.workflow_data,
          idempotencyKey,
          sessionId,
          'manual',
          userId,
        ).run();

        await this.env.DB.prepare(`UPDATE triggers SET last_run_at = ? WHERE id = ?`).bind(now, triggerId).run();

        const dispatched = await enqueueWorkflowExecution(this.env, {
          executionId,
          workflowId: row.wf_id,
          userId,
          sessionId,
          triggerType: 'manual',
          workerOrigin,
        });

        this.sendToRunner({
          type: 'trigger-api-result',
          requestId,
          data: {
            executionId,
            workflowId: row.wf_id,
            workflowName: row.workflow_name,
            status: 'pending',
            variables,
            sessionId,
            dispatched,
            message: dispatched
              ? 'Trigger run accepted and dispatched.'
              : 'Trigger run accepted but dispatch failed.',
          },
        } as any);
        return;
      }

      this.sendToRunner({ type: 'trigger-api-result', requestId, error: `Unsupported trigger action: ${action}` } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Trigger API error:', err);
      this.sendToRunner({ type: 'trigger-api-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleExecutionApi(requestId: string, action: string, payload?: Record<string, unknown>) {
    try {
      const userId = this.getStateValue('userId')!;
      const executionId = typeof payload?.executionId === 'string' ? payload.executionId.trim() : '';
      if (!executionId) {
        this.sendToRunner({ type: 'execution-api-result', requestId, error: 'executionId is required' } as any);
        return;
      }

      if (action === 'get') {
        const row = await this.env.DB.prepare(`
          SELECT e.*, w.name as workflow_name, t.name as trigger_name
          FROM workflow_executions e
          LEFT JOIN workflows w ON e.workflow_id = w.id
          LEFT JOIN triggers t ON e.trigger_id = t.id
          WHERE e.id = ? AND e.user_id = ?
          LIMIT 1
        `).bind(executionId, userId).first<Record<string, unknown>>();

        if (!row) {
          this.sendToRunner({ type: 'execution-api-result', requestId, error: `Execution not found: ${executionId}` } as any);
          return;
        }

        this.sendToRunner({
          type: 'execution-api-result',
          requestId,
          data: {
            execution: {
              id: row.id,
              workflowId: row.workflow_id,
              workflowName: row.workflow_name,
              sessionId: row.session_id,
              triggerId: row.trigger_id,
              triggerName: row.trigger_name,
              status: row.status,
              triggerType: row.trigger_type,
              triggerMetadata: this.parseJsonOrNull(row.trigger_metadata),
              variables: this.parseJsonOrNull(row.variables),
              resumeToken: row.resume_token || null,
              outputs: this.parseJsonOrNull(row.outputs),
              steps: this.parseJsonOrNull(row.steps),
              error: row.error,
              startedAt: row.started_at,
              completedAt: row.completed_at,
            },
          },
        } as any);
        return;
      }

      if (action === 'steps') {
        const execution = await this.env.DB.prepare(`
          SELECT id, user_id, workflow_snapshot
          FROM workflow_executions
          WHERE id = ?
          LIMIT 1
        `).bind(executionId).first<{ id: string; user_id: string; workflow_snapshot: string | null }>();

        if (!execution || execution.user_id !== userId) {
          this.sendToRunner({ type: 'execution-api-result', requestId, error: `Execution not found: ${executionId}` } as any);
          return;
        }

        const buildWorkflowStepOrderMap = (workflowSnapshotRaw: string | null): Map<string, number> => {
          if (!workflowSnapshotRaw) return new Map();
          let parsed: unknown;
          try {
            parsed = JSON.parse(workflowSnapshotRaw);
          } catch {
            return new Map();
          }
          const order = new Map<string, number>();
          let index = 0;
          const visitStepList = (rawSteps: unknown): void => {
            if (!Array.isArray(rawSteps)) return;
            for (const entry of rawSteps) {
              if (!entry || typeof entry !== 'object' || Array.isArray(entry)) continue;
              const stepRecord = entry as Record<string, unknown>;
              const stepId = typeof stepRecord.id === 'string' ? stepRecord.id : '';
              if (stepId && !order.has(stepId)) {
                order.set(stepId, index);
                index += 1;
              }
              visitStepList(stepRecord.then);
              visitStepList(stepRecord.else);
              visitStepList(stepRecord.steps);
            }
          };
          if (parsed && typeof parsed === 'object' && !Array.isArray(parsed)) {
            visitStepList((parsed as Record<string, unknown>).steps);
          } else if (Array.isArray(parsed)) {
            visitStepList(parsed);
          }
          return order;
        };

        const workflowStepOrder = buildWorkflowStepOrderMap(execution.workflow_snapshot);
        const rankStepOrderIndex = (value: number | null): number => value ?? Number.MAX_SAFE_INTEGER;

        const result = await this.env.DB.prepare(`
          SELECT rowid AS insertion_order,
                 id, execution_id, step_id, attempt, status, input_json, output_json, error, started_at, completed_at, created_at
          FROM workflow_execution_steps
          WHERE execution_id = ?
          ORDER BY attempt ASC, insertion_order ASC
        `).bind(executionId).all();

        const steps = (result.results || [])
          .map((row) => ({
            id: row.id,
            executionId: row.execution_id,
            stepId: String(row.step_id),
            attempt: Number(row.attempt || 1),
            status: String(row.status),
            input: this.parseJsonOrNull((row.input_json as string | null) || null),
            output: this.parseJsonOrNull((row.output_json as string | null) || null),
            error: (row.error as string | null) || null,
            startedAt: (row.started_at as string | null) || null,
            completedAt: (row.completed_at as string | null) || null,
            createdAt: String(row.created_at),
            workflowStepIndex: workflowStepOrder.get(String(row.step_id)) ?? null,
            insertionOrder: Number(row.insertion_order || 0),
          }))
          .sort((left, right) => {
            if (left.attempt !== right.attempt) return left.attempt - right.attempt;
            const leftIndex = rankStepOrderIndex(left.workflowStepIndex);
            const rightIndex = rankStepOrderIndex(right.workflowStepIndex);
            if (leftIndex !== rightIndex) return leftIndex - rightIndex;
            if (left.insertionOrder !== right.insertionOrder) return left.insertionOrder - right.insertionOrder;
            return left.stepId.localeCompare(right.stepId);
          })
          .map((step, sequence) => ({
            id: step.id,
            executionId: step.executionId,
            stepId: step.stepId,
            attempt: step.attempt,
            status: step.status,
            input: step.input,
            output: step.output,
            error: step.error,
            startedAt: step.startedAt,
            completedAt: step.completedAt,
            createdAt: step.createdAt,
            workflowStepIndex: step.workflowStepIndex,
            sequence,
          }));

        this.sendToRunner({ type: 'execution-api-result', requestId, data: { steps } } as any);
        return;
      }

      if (action === 'approve') {
        const approve = payload?.approve === true;
        const resumeToken = typeof payload?.resumeToken === 'string' ? payload.resumeToken : '';
        const reason = typeof payload?.reason === 'string' ? payload.reason : undefined;
        if (!resumeToken) {
          this.sendToRunner({ type: 'execution-api-result', requestId, error: 'resumeToken is required' } as any);
          return;
        }

        const execution = await this.env.DB.prepare(`
          SELECT user_id FROM workflow_executions WHERE id = ? LIMIT 1
        `).bind(executionId).first<{ user_id: string }>();
        if (!execution || execution.user_id !== userId) {
          this.sendToRunner({ type: 'execution-api-result', requestId, error: `Execution not found: ${executionId}` } as any);
          return;
        }

        const doId = this.env.WORKFLOW_EXECUTOR.idFromName(executionId);
        const stub = this.env.WORKFLOW_EXECUTOR.get(doId);
        const response = await stub.fetch(new Request('https://workflow-executor/resume', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            executionId,
            resumeToken,
            approve,
            reason,
          }),
        }));

        if (!response.ok) {
          const errorBody = await response.json<{ error?: string }>().catch((): { error?: string } => ({ error: undefined }));
          this.sendToRunner({
            type: 'execution-api-result',
            requestId,
            error: errorBody.error || `Failed to apply approval decision (${response.status})`,
          } as any);
          return;
        }

        const result = await response.json<{ ok: boolean; status: string }>();
        this.sendToRunner({ type: 'execution-api-result', requestId, data: { success: true, status: result.status } } as any);
        return;
      }

      if (action === 'cancel') {
        const reason = typeof payload?.reason === 'string' ? payload.reason : undefined;
        const execution = await this.env.DB.prepare(`
          SELECT user_id FROM workflow_executions WHERE id = ? LIMIT 1
        `).bind(executionId).first<{ user_id: string }>();
        if (!execution || execution.user_id !== userId) {
          this.sendToRunner({ type: 'execution-api-result', requestId, error: `Execution not found: ${executionId}` } as any);
          return;
        }

        const doId = this.env.WORKFLOW_EXECUTOR.idFromName(executionId);
        const stub = this.env.WORKFLOW_EXECUTOR.get(doId);
        const response = await stub.fetch(new Request('https://workflow-executor/cancel', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            executionId,
            reason,
          }),
        }));

        if (!response.ok) {
          const errorBody = await response.json<{ error?: string }>().catch((): { error?: string } => ({ error: undefined }));
          this.sendToRunner({
            type: 'execution-api-result',
            requestId,
            error: errorBody.error || `Failed to cancel execution (${response.status})`,
          } as any);
          return;
        }

        const result = await response.json<{ ok: boolean; status: string }>();
        this.sendToRunner({ type: 'execution-api-result', requestId, data: { success: true, status: result.status } } as any);
        return;
      }

      this.sendToRunner({ type: 'execution-api-result', requestId, error: `Unsupported execution action: ${action}` } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Execution API error:', err);
      this.sendToRunner({ type: 'execution-api-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleWorkflowExecutionResult(msg: RunnerMessage) {
    const executionId = msg.executionId || msg.envelope?.executionId;
    const envelope = msg.envelope;
    if (!executionId || !envelope) {
      console.error('[SessionAgentDO] Invalid workflow execution result payload');
      return;
    }

    const execution = await this.env.DB.prepare(`
      SELECT
        e.id,
        e.user_id,
        e.workflow_id,
        e.session_id,
        w.name AS workflow_name
      FROM workflow_executions e
      LEFT JOIN workflows w ON w.id = e.workflow_id
      WHERE e.id = ?
      LIMIT 1
    `).bind(executionId).first<{
      id: string;
      user_id: string;
      workflow_id: string | null;
      session_id: string | null;
      workflow_name: string | null;
    }>();

    if (!execution) {
      console.warn(`[SessionAgentDO] Received workflow result for unknown execution ${executionId}`);
      return;
    }

    const currentSessionId = this.getStateValue('sessionId');
    if (execution.session_id && currentSessionId && execution.session_id !== currentSessionId) {
      console.warn(
        `[SessionAgentDO] Ignoring workflow result for ${executionId}: execution bound to ${execution.session_id}, this DO is ${currentSessionId}`,
      );
      return;
    }

    const outputsJson = envelope.output ? JSON.stringify(envelope.output) : null;
    const stepsJson = envelope.steps ? JSON.stringify(envelope.steps) : null;

    let nextStatus: 'completed' | 'failed' | 'cancelled' | 'waiting_approval' = 'failed';
    let error: string | null = envelope.error || null;
    let resumeToken: string | null = null;
    let completedAt: string | null = new Date().toISOString();

    if (envelope.status === 'ok') {
      nextStatus = 'completed';
      error = null;
    } else if (envelope.status === 'failed') {
      nextStatus = 'failed';
      error = envelope.error || 'workflow_failed';
    } else if (envelope.status === 'cancelled') {
      nextStatus = 'cancelled';
      error = envelope.error || 'workflow_cancelled';
    } else if (envelope.status === 'needs_approval') {
      resumeToken = envelope.requiresApproval?.resumeToken || null;
      if (!resumeToken) {
        nextStatus = 'failed';
        error = 'approval_resume_token_missing';
      } else {
        nextStatus = 'waiting_approval';
        error = null;
        completedAt = null;
      }
    }

    await this.env.DB.prepare(`
      UPDATE workflow_executions
      SET status = ?,
          outputs = ?,
          steps = ?,
          error = ?,
          resume_token = ?,
          completed_at = ?
      WHERE id = ?
    `).bind(
      nextStatus,
      outputsJson,
      stepsJson,
      error,
      resumeToken,
      completedAt,
      executionId,
    ).run();

    if (Array.isArray(envelope.steps) && envelope.steps.length > 0) {
      for (const step of envelope.steps) {
        const attempt = step.attempt && step.attempt > 0 ? step.attempt : 1;
        await this.env.DB.prepare(`
          INSERT INTO workflow_execution_steps
            (id, execution_id, step_id, attempt, status, input_json, output_json, error, started_at, completed_at)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
          ON CONFLICT(execution_id, step_id, attempt) DO UPDATE SET
            status = excluded.status,
            input_json = COALESCE(excluded.input_json, workflow_execution_steps.input_json),
            output_json = COALESCE(excluded.output_json, workflow_execution_steps.output_json),
            error = excluded.error,
            started_at = COALESCE(excluded.started_at, workflow_execution_steps.started_at),
            completed_at = COALESCE(excluded.completed_at, workflow_execution_steps.completed_at)
        `).bind(
          crypto.randomUUID(),
          executionId,
          step.stepId,
          attempt,
          step.status,
          step.input !== undefined ? JSON.stringify(step.input) : null,
          step.output !== undefined ? JSON.stringify(step.output) : null,
          step.error || null,
          step.startedAt || null,
          step.completedAt || null,
        ).run();
      }
    }

    if (nextStatus === 'waiting_approval') {
      try {
        await enqueueWorkflowApprovalNotificationIfMissing(this.env.DB, {
          toUserId: execution.user_id,
          executionId,
          fromSessionId: execution.session_id || currentSessionId || undefined,
          contextSessionId: execution.session_id || currentSessionId || undefined,
          workflowName: execution.workflow_name,
          approvalPrompt: envelope.requiresApproval?.prompt,
        });
      } catch (notifyError) {
        console.error('[SessionAgentDO] Failed to enqueue workflow approval notification:', notifyError);
      }
    } else {
      try {
        await markWorkflowApprovalNotificationsRead(this.env.DB, execution.user_id, executionId);
      } catch (notifyError) {
        console.error('[SessionAgentDO] Failed to clear workflow approval notifications:', notifyError);
      }
    }

    if (nextStatus !== 'waiting_approval' && currentSessionId) {
      const sessionRow = await this.env.DB.prepare(`
        SELECT purpose
        FROM sessions
        WHERE id = ?
        LIMIT 1
      `).bind(currentSessionId).first<{ purpose: string | null }>();

      if (sessionRow?.purpose === 'workflow') {
        this.ctx.waitUntil(this.handleStop(`workflow_execution_${nextStatus}`));
      }
    }
  }

  private async handleListPullRequests(
    requestId: string,
    params: { owner?: string; repo?: string; state?: string; limit?: number },
  ) {
    try {
      const githubToken = await this.getGitHubToken();
      if (!githubToken) {
        this.sendToRunner({ type: 'list-pull-requests-result', requestId, error: 'No GitHub token found — user must connect GitHub in settings' } as any);
        return;
      }

      const { owner, repo } = await this.resolveOwnerRepo(params.owner, params.repo);
      const state = params.state || 'open';
      const limit = Math.min(Math.max(params.limit ?? 30, 1), 100);

      const res = await fetch(
        `https://api.github.com/repos/${owner}/${repo}/pulls?state=${encodeURIComponent(state)}&sort=updated&direction=desc&per_page=${limit}`,
        {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        },
      );

      if (!res.ok) {
        const errText = await res.text();
        this.sendToRunner({ type: 'list-pull-requests-result', requestId, error: `GitHub API error (${res.status}): ${errText}` } as any);
        return;
      }

      const pulls = await res.json() as Array<{
        number: number;
        title: string;
        state: string;
        draft: boolean;
        body: string | null;
        html_url: string;
        created_at: string;
        updated_at: string;
        user: { login: string; avatar_url: string };
        head: { ref: string; sha: string };
        base: { ref: string; sha: string };
        labels: Array<{ name: string }>;
      }>;

      this.sendToRunner({
        type: 'list-pull-requests-result',
        requestId,
        pulls: pulls.map((pr) => ({
          number: pr.number,
          title: pr.title,
          state: pr.state,
          draft: pr.draft,
          body: pr.body,
          url: pr.html_url,
          createdAt: pr.created_at,
          updatedAt: pr.updated_at,
          author: { login: pr.user.login, avatarUrl: pr.user.avatar_url },
          headRef: pr.head.ref,
          headSha: pr.head.sha,
          baseRef: pr.base.ref,
          baseSha: pr.base.sha,
          labels: pr.labels?.map((label) => label.name) ?? [],
        })),
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list pull requests:', err);
      this.sendToRunner({ type: 'list-pull-requests-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleInspectPullRequest(
    requestId: string,
    params: { prNumber: number; owner?: string; repo?: string; filesLimit?: number; commentsLimit?: number },
  ) {
    try {
      const githubToken = await this.getGitHubToken();
      if (!githubToken) {
        this.sendToRunner({ type: 'inspect-pull-request-result', requestId, error: 'No GitHub token found — user must connect GitHub in settings' } as any);
        return;
      }

      const { owner, repo } = await this.resolveOwnerRepo(params.owner, params.repo);
      const filesLimit = Math.min(Math.max(params.filesLimit ?? 200, 1), 300);
      const commentsLimit = Math.min(Math.max(params.commentsLimit ?? 100, 1), 300);

      const prResp = await fetch(`https://api.github.com/repos/${owner}/${repo}/pulls/${params.prNumber}`, {
        headers: {
          'Authorization': `Bearer ${githubToken}`,
          'Accept': 'application/vnd.github+json',
          'User-Agent': 'agent-ops',
        },
      });

      if (!prResp.ok) {
        const errText = await prResp.text();
        this.sendToRunner({ type: 'inspect-pull-request-result', requestId, error: `GitHub API error (${prResp.status}): ${errText}` } as any);
        return;
      }

      const pr = await prResp.json() as {
        number: number;
        title: string;
        state: string;
        draft: boolean;
        body: string | null;
        html_url: string;
        created_at: string;
        updated_at: string;
        closed_at: string | null;
        merged_at: string | null;
        user: { login: string; avatar_url: string };
        base: { ref: string; sha: string };
        head: { ref: string; sha: string };
        labels: Array<{ name: string }>;
        assignees: Array<{ login: string }>;
        requested_reviewers: Array<{ login: string }>;
        requested_teams: Array<{ name: string }>;
        mergeable: boolean | null;
        mergeable_state: string;
        commits: number;
        additions: number;
        deletions: number;
        changed_files: number;
      };

      const perPage = 100;
      let page = 1;
      const files: Array<{ filename: string; status: string; additions: number; deletions: number; changes: number }> = [];
      let filesTruncated = false;
      while (files.length < filesLimit) {
        const remaining = filesLimit - files.length;
        const pageSize = Math.min(perPage, remaining);
        const filesResp = await fetch(
          `https://api.github.com/repos/${owner}/${repo}/pulls/${params.prNumber}/files?per_page=${pageSize}&page=${page}`,
          {
            headers: {
              'Authorization': `Bearer ${githubToken}`,
              'Accept': 'application/vnd.github+json',
              'User-Agent': 'agent-ops',
            },
          },
        );
        if (!filesResp.ok) {
          const errText = await filesResp.text();
          throw new Error(`GitHub API error (${filesResp.status}) while fetching files: ${errText}`);
        }
        const pageFiles = await filesResp.json() as Array<{
          filename: string;
          status: string;
          additions: number;
          deletions: number;
          changes: number;
        }>;
        files.push(...pageFiles.map((f) => ({
          filename: f.filename,
          status: f.status,
          additions: f.additions,
          deletions: f.deletions,
          changes: f.changes,
        })));
        if (pageFiles.length < pageSize) break;
        page += 1;
      }
      if (files.length >= filesLimit && pr.changed_files > filesLimit) filesTruncated = true;

      const reviewsResp = await fetch(
        `https://api.github.com/repos/${owner}/${repo}/pulls/${params.prNumber}/reviews?per_page=100`,
        {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        },
      );

      const reviews = reviewsResp.ok
        ? await reviewsResp.json() as Array<{ id: number; user: { login: string }; state: string; submitted_at: string | null }>
        : [];
      const dismissedReviewIds = new Set(reviews.filter(r => r.state === 'DISMISSED').map(r => r.id));

      const reviewCounts = reviews.reduce<Record<string, number>>((acc, review) => {
        acc[review.state] = (acc[review.state] || 0) + 1;
        return acc;
      }, {});

      const reviewComments: Array<{
        id: number;
        user: { login: string };
        body: string;
        path: string;
        line: number | null;
        created_at: string;
        updated_at: string;
      }> = [];
      let commentsPage = 1;
      while (reviewComments.length < commentsLimit) {
        const remaining = commentsLimit - reviewComments.length;
        const pageSize = Math.min(perPage, remaining);
        const commentsResp = await fetch(
          `https://api.github.com/repos/${owner}/${repo}/pulls/${params.prNumber}/comments?per_page=${pageSize}&page=${commentsPage}`,
          {
            headers: {
              'Authorization': `Bearer ${githubToken}`,
              'Accept': 'application/vnd.github+json',
              'User-Agent': 'agent-ops',
            },
          },
        );
        if (!commentsResp.ok) {
          const errText = await commentsResp.text();
          throw new Error(`GitHub API error (${commentsResp.status}) while fetching review comments: ${errText}`);
        }
        const pageComments = await commentsResp.json() as Array<{
          id: number;
          user: { login: string };
          body: string;
          path: string;
          line: number | null;
          created_at: string;
          updated_at: string;
          pull_request_review_id?: number;
        }>;
        const filtered = pageComments.filter((comment) => {
          if (!comment.pull_request_review_id) return true;
          return !dismissedReviewIds.has(comment.pull_request_review_id);
        });
        reviewComments.push(...filtered.map((comment) => ({
          id: comment.id,
          user: { login: comment.user.login },
          body: comment.body,
          path: comment.path,
          line: comment.line,
          created_at: comment.created_at,
          updated_at: comment.updated_at,
        })));
        if (pageComments.length < pageSize) break;
        commentsPage += 1;
      }
      const commentsTruncated = reviewComments.length >= commentsLimit;

      const statusResp = await fetch(
        `https://api.github.com/repos/${owner}/${repo}/commits/${pr.head.sha}/status`,
        {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        },
      );
      const statusData = statusResp.ok ? await statusResp.json() as {
        state: string;
        statuses: Array<{ state: string; context: string; description: string | null; target_url: string | null; updated_at: string }>;
      } : null;

      const checksResp = await fetch(
        `https://api.github.com/repos/${owner}/${repo}/commits/${pr.head.sha}/check-runs?per_page=100`,
        {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        },
      );
      const checksData = checksResp.ok ? await checksResp.json() as {
        total_count: number;
        check_runs: Array<{ name: string; status: string; conclusion: string | null; html_url: string | null; app: { name: string } }>;
      } : null;

      const checkSummary = checksData?.check_runs.reduce<Record<string, number>>((acc, run) => {
        const key = run.conclusion || run.status || 'unknown';
        acc[key] = (acc[key] || 0) + 1;
        return acc;
      }, {}) ?? {};

      this.sendToRunner({
        type: 'inspect-pull-request-result',
        requestId,
        data: {
          repo: { owner, repo },
          pr: {
            number: pr.number,
            title: pr.title,
            state: pr.state,
            draft: pr.draft,
            url: pr.html_url,
            body: pr.body,
            createdAt: pr.created_at,
            updatedAt: pr.updated_at,
            closedAt: pr.closed_at,
            mergedAt: pr.merged_at,
            author: { login: pr.user.login, avatarUrl: pr.user.avatar_url },
            baseRef: pr.base.ref,
            baseSha: pr.base.sha,
            headRef: pr.head.ref,
            headSha: pr.head.sha,
            labels: pr.labels?.map((label) => label.name) ?? [],
            assignees: pr.assignees?.map((assignee) => assignee.login) ?? [],
            requestedReviewers: pr.requested_reviewers?.map((reviewer) => reviewer.login) ?? [],
            requestedTeams: pr.requested_teams?.map((team) => team.name) ?? [],
            mergeable: pr.mergeable,
            mergeableState: pr.mergeable_state,
            commits: pr.commits,
            additions: pr.additions,
            deletions: pr.deletions,
            changedFiles: pr.changed_files,
          },
          files: {
            totalChangedFiles: pr.changed_files,
            returned: files.length,
            truncated: filesTruncated,
            items: files,
          },
          reviews: {
            counts: reviewCounts,
            items: reviews.map((review) => ({
              id: review.id,
              user: { login: review.user.login },
              state: review.state,
              submittedAt: review.submitted_at,
            })),
          },
          reviewComments: {
            returned: reviewComments.length,
            truncated: commentsTruncated,
            items: reviewComments,
          },
          checks: {
            status: statusData
              ? {
                state: statusData.state,
                items: statusData.statuses.map((s) => ({
                  state: s.state,
                  context: s.context,
                  description: s.description,
                  targetUrl: s.target_url,
                  updatedAt: s.updated_at,
                })),
              }
              : null,
            checkRuns: checksData
              ? {
                total: checksData.total_count,
                summary: checkSummary,
                items: checksData.check_runs.map((run) => ({
                  name: run.name,
                  status: run.status,
                  conclusion: run.conclusion,
                  url: run.html_url,
                  app: run.app?.name,
                })),
              }
              : null,
          },
        },
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to inspect pull request:', err);
      this.sendToRunner({ type: 'inspect-pull-request-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleListPersonas(requestId: string) {
    try {
      const userId = this.getStateValue('userId')!;
      const personas = await listPersonas(this.env.DB, userId);
      this.sendToRunner({ type: 'list-personas-result', requestId, personas } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list personas:', err);
      this.sendToRunner({ type: 'list-personas-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleListChannels(requestId: string) {
    try {
      const userId = this.getStateValue('userId');
      const sessionId = this.getStateValue('sessionId')!;

      let bindings = userId
        ? await listUserChannelBindings(this.env.DB, userId)
        : [];

      // Fallback to session-scoped bindings if user-level bindings are unavailable.
      if (bindings.length === 0) {
        bindings = await getSessionChannelBindings(this.env.DB, sessionId);
      }

      // Deduplicate by destination while preserving recency ordering.
      const unique: typeof bindings = [];
      const seen = new Set<string>();
      for (const binding of bindings) {
        const key = `${binding.channelType}:${binding.channelId}`;
        if (seen.has(key)) continue;
        seen.add(key);
        unique.push(binding);
      }

      this.sendToRunner({ type: 'list-channels-result', requestId, channels: unique } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list channels:', err);
      this.sendToRunner({ type: 'list-channels-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleListChildSessions(requestId: string) {
    try {
      const sessionId = this.getStateValue('sessionId')!;
      const { children } = await getChildSessions(this.env.DB, sessionId);
      this.sendToRunner({ type: 'list-child-sessions-result', requestId, children } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to list child sessions:', err);
      this.sendToRunner({ type: 'list-child-sessions-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleReadRepoFile(
    requestId: string,
    params: { owner?: string; repo?: string; repoUrl?: string; path?: string; ref?: string },
  ) {
    try {
      const githubToken = await this.getGitHubToken();
      if (!githubToken) {
        this.sendToRunner({ type: 'read-repo-file-result', requestId, error: 'No GitHub token found — user must connect GitHub in settings' } as any);
        return;
      }

      if (!params.path) {
        this.sendToRunner({ type: 'read-repo-file-result', requestId, error: 'Missing file path' } as any);
        return;
      }

      let owner = params.owner;
      let repo = params.repo;
      if (params.repoUrl) {
        const ownerRepo = this.extractOwnerRepo(params.repoUrl);
        if (ownerRepo) {
          owner = ownerRepo.owner;
          repo = ownerRepo.repo;
        }
      }
      if (!owner || !repo) {
        // Allow repo in "owner/repo" format if passed in repo
        if (repo && repo.includes('/')) {
          const [o, r] = repo.split('/');
          owner = owner || o;
          repo = r;
        }
      }

      if (!owner || !repo) {
        const resolved = await this.resolveOwnerRepo(owner, repo);
        owner = resolved.owner;
        repo = resolved.repo;
      }

      const encodedPath = params.path.split('/').map(encodeURIComponent).join('/');
      const url = new URL(`https://api.github.com/repos/${owner}/${repo}/contents/${encodedPath}`);
      if (params.ref) url.searchParams.set('ref', params.ref);

      const res = await fetch(url.toString(), {
        headers: {
          'Authorization': `Bearer ${githubToken}`,
          'Accept': 'application/vnd.github+json',
          'User-Agent': 'agent-ops',
        },
      });

      if (!res.ok) {
        const errText = await res.text();
        this.sendToRunner({ type: 'read-repo-file-result', requestId, error: `GitHub API error (${res.status}): ${errText}` } as any);
        return;
      }

      const data = await res.json() as {
        type: 'file' | 'dir';
        encoding?: string;
        content?: string;
        path?: string;
        size?: number;
      };

      if (data.type === 'dir') {
        this.sendToRunner({ type: 'read-repo-file-result', requestId, error: `Path is a directory: ${params.path}` } as any);
        return;
      }

      const encoding = data.encoding || 'base64';
      let content = data.content || '';
      if (encoding === 'base64' && content) {
        content = atob(content.replace(/\n/g, ''));
      }

      const MAX_CHARS = 200_000;
      let truncated = false;
      if (content.length > MAX_CHARS) {
        content = content.slice(0, MAX_CHARS);
        truncated = true;
      }

      this.sendToRunner({
        type: 'read-repo-file-result',
        requestId,
        content,
        encoding,
        truncated,
        path: data.path || params.path,
        repo: `${owner}/${repo}`,
        ref: params.ref,
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to read repo file:', err);
      this.sendToRunner({ type: 'read-repo-file-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleGetSessionStatus(requestId: string, targetSessionId: string) {
    try {
      const userId = this.getStateValue('userId')!;
      const session = await getSession(this.env.DB, targetSessionId);
      if (!session || session.userId !== userId) {
        this.sendToRunner({ type: 'get-session-status-result', requestId, error: 'Session not found or access denied' } as any);
        return;
      }

      // Fetch recent messages from the target DO's local SQLite (not D1)
      const recentMessages = await this.fetchMessagesFromDO(targetSessionId, 10);

      // Fetch live runner/sandbox status from target DO
      let liveStatus: {
        runnerConnected?: boolean;
        runnerBusy?: boolean;
        queuedPrompts?: number;
        sandboxId?: string | null;
        status?: string;
        tunnelUrls?: Record<string, string> | null;
        tunnels?: Array<{ name: string; url?: string; path?: string; port?: number; protocol?: string }> | null;
      } | null = null;
      try {
        const doId = this.env.SESSIONS.idFromName(targetSessionId);
        const targetDO = this.env.SESSIONS.get(doId);
        const statusRes = await targetDO.fetch(new Request('http://do/status'));
        if (statusRes.ok) {
          liveStatus = await statusRes.json() as any;
        }
      } catch (err) {
        console.warn('[SessionAgentDO] Failed to fetch live status for session:', targetSessionId, err);
      }

      const runnerBusy = liveStatus?.runnerBusy ?? false;
      const queuedPrompts = liveStatus?.queuedPrompts ?? 0;
      const runnerConnected = liveStatus?.runnerConnected ?? false;
      const agentStatus = runnerBusy || queuedPrompts > 0 ? 'working' : 'idle';

      this.sendToRunner({
        type: 'get-session-status-result',
        requestId,
        sessionStatus: {
          id: session.id,
          status: session.status,
          workspace: session.workspace,
          title: session.title,
          createdAt: session.createdAt instanceof Date ? session.createdAt.toISOString() : String(session.createdAt),
          lastActiveAt: session.lastActiveAt instanceof Date ? session.lastActiveAt.toISOString() : String(session.lastActiveAt),
          runnerConnected,
          runnerBusy,
          queuedPrompts,
          agentStatus,
          recentMessages,
          tunnelUrls: liveStatus?.tunnelUrls ?? null,
          tunnels: liveStatus?.tunnels ?? null,
        },
      } as any);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to get session status:', err);
      this.sendToRunner({ type: 'get-session-status-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  // ─── D1 Message Archival ───────────────────────────────────────────
  // Flush messages from DO's internal SQLite to D1 for permanent archival.
  // Uses INSERT OR IGNORE to deduplicate with route-level saves.

  private async flushMessagesToD1(): Promise<void> {
    const sessionId = this.getStateValue('sessionId');
    if (!sessionId) return;

    const lastFlushStr = this.getStateValue('lastD1FlushAt');
    const lastFlushAt = lastFlushStr ? parseInt(lastFlushStr) : 0;

    // Query DO's internal messages for rows created after last flush
    const rows = this.ctx.storage.sql
      .exec(
        'SELECT id, role, content, parts, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, opencode_session_id, created_at FROM messages WHERE created_at > ? ORDER BY created_at ASC LIMIT 50',
        lastFlushAt
      )
      .toArray();

    if (rows.length === 0) return;

    // Batch write to D1 (cap at 50 per batch per D1 limits)
    const stmts = rows.map((row) =>
      this.env.DB.prepare(
        'INSERT OR IGNORE INTO messages (id, session_id, role, content, parts, author_id, author_email, author_name, author_avatar_url, channel_type, channel_id, opencode_session_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'
      ).bind(
        row.id as string,
        sessionId,
        row.role as string,
        row.content as string,
        row.parts as string | null,
        row.author_id as string | null,
        row.author_email as string | null,
        row.author_name as string | null,
        row.author_avatar_url as string | null,
        row.channel_type as string | null,
        row.channel_id as string | null,
        row.opencode_session_id as string | null,
      )
    );

    try {
      await this.env.DB.batch(stmts);
      // Update last flush timestamp to the latest row's created_at
      const latestTs = rows[rows.length - 1].created_at as number;
      this.setStateValue('lastD1FlushAt', String(latestTs));
      console.log(`[SessionAgentDO] Flushed ${rows.length} messages to D1 (up to ts=${latestTs})`);
    } catch (err) {
      console.error('[SessionAgentDO] Failed to flush messages to D1:', err);
    }
  }

  // ─── Per-Channel Busy State ──────────────────────────────────────────

  private channelKeyFrom(channelType?: string, channelId?: string): string {
    if (channelType && channelId) return `${channelType}:${channelId}`;
    return 'web:default';
  }

  private isChannelBusy(channelKey: string): boolean {
    const row = this.ctx.storage.sql
      .exec('SELECT busy FROM channel_state WHERE channel_key = ?', channelKey)
      .toArray();
    return row.length > 0 && (row[0].busy as number) === 1;
  }

  private setChannelBusy(channelKey: string, busy: boolean): void {
    this.ctx.storage.sql.exec(
      'INSERT INTO channel_state (channel_key, busy) VALUES (?, ?) ON CONFLICT(channel_key) DO UPDATE SET busy = excluded.busy',
      channelKey, busy ? 1 : 0
    );
  }

  private setChannelOcSessionId(channelKey: string, ocSessionId: string): void {
    this.ctx.storage.sql.exec(
      'INSERT INTO channel_state (channel_key, busy, opencode_session_id) VALUES (?, 0, ?) ON CONFLICT(channel_key) DO UPDATE SET opencode_session_id = excluded.opencode_session_id',
      channelKey, ocSessionId
    );
  }

  private getChannelOcSessionId(channelKey: string): string | undefined {
    const row = this.ctx.storage.sql
      .exec('SELECT opencode_session_id FROM channel_state WHERE channel_key = ?', channelKey)
      .toArray();
    const value = row[0]?.opencode_session_id as string | null | undefined;
    return value || undefined;
  }


  private async handlePromptComplete() {
    this.appendAuditLog('agent.turn_complete', 'Agent turn completed');

    // Mark any processing prompt_queue entries as completed
    this.ctx.storage.sql.exec(
      "UPDATE prompt_queue SET status = 'completed' WHERE status = 'processing'"
    );

    // Prune old completed entries to prevent unbounded storage growth
    this.ctx.storage.sql.exec(
      "DELETE FROM prompt_queue WHERE status = 'completed'"
    );

    if (await this.sendNextQueuedPrompt()) {
      // More work in the queue — flush messages in the background
      this.ctx.waitUntil(this.flushMessagesToD1());
      return;
    }

    // Runner is now idle — flush messages to D1
    this.ctx.waitUntil(this.flushMessagesToD1());

    // Runner is now idle
    this.setStateValue('runnerBusy', 'false');
    this.broadcastToClients({
      type: 'status',
      data: { runnerBusy: false },
    });
    await this.notifyParentIfIdle();
  }

  // ─── Internal Endpoints ────────────────────────────────────────────────

  private async handleStart(request: Request): Promise<Response> {
    const body = await request.json() as {
      sessionId: string;
      userId: string;
      workspace: string;
      runnerToken: string;
      sandboxId?: string;
      tunnelUrls?: {
        opencode: string;
        gateway: string;
        vscode?: string;
        vnc?: string;
        ttyd?: string;
      };
      // For async sandbox spawning (DO calls Modal in the background)
      backendUrl?: string;
      terminateUrl?: string;
      hibernateUrl?: string;
      restoreUrl?: string;
      spawnRequest?: Record<string, unknown>;
      idleTimeoutMs?: number;
      initialPrompt?: string;
      initialModel?: string;
    };

    // Clear old session data (messages, queue, audit log, followups) for a fresh start.
    // This is important for well-known DOs (orchestrators) that get reused.
    this.ctx.storage.sql.exec('DELETE FROM messages');
    this.ctx.storage.sql.exec('DELETE FROM prompt_queue');
    this.ctx.storage.sql.exec('DELETE FROM audit_log');
    this.ctx.storage.sql.exec('DELETE FROM channel_followups');

    // Store session state in durable SQLite
    this.setStateValue('sessionId', body.sessionId);
    this.setStateValue('userId', body.userId);
    this.setStateValue('workspace', body.workspace);
    this.setStateValue('runnerToken', body.runnerToken);
    this.setStateValue('status', 'initializing');
    this.setStateValue('runnerBusy', 'false');

    // Clear stale state from previous lifecycle
    this.setStateValue('sandboxId', '');
    this.setStateValue('tunnelUrls', '');
    this.setStateValue('tunnels', '');
    this.setStateValue('tunnels', '');
    this.setStateValue('runningStartedAt', '');

    if (body.sandboxId) {
      this.setStateValue('sandboxId', body.sandboxId);
    }
    if (body.tunnelUrls) {
      this.setStateValue('tunnelUrls', JSON.stringify(body.tunnelUrls));
    }
    if (body.terminateUrl) {
      this.setStateValue('terminateUrl', body.terminateUrl);
    }
    if (body.hibernateUrl) {
      this.setStateValue('hibernateUrl', body.hibernateUrl);
    }
    if (body.restoreUrl) {
      this.setStateValue('restoreUrl', body.restoreUrl);
    }
    if (body.idleTimeoutMs) {
      this.setStateValue('idleTimeoutMs', String(body.idleTimeoutMs));
    }
    if (body.backendUrl) {
      this.setStateValue('backendUrl', body.backendUrl);
    }
    if (body.spawnRequest) {
      this.setStateValue('spawnRequest', JSON.stringify(body.spawnRequest));
    }
    if (body.initialPrompt) {
      this.setStateValue('initialPrompt', body.initialPrompt);
    }
    if (body.initialModel) {
      this.setStateValue('initialModel', body.initialModel);
    }

    // Initialize queue mode (Phase D)
    this.setStateValue('queueMode', (body as any).queueMode || 'followup');
    this.setStateValue('collectDebounceMs', String((body as any).collectDebounceMs || 3000));

    // Channel follow-up reminder interval (default: 5 minutes)
    if ((body as any).channelFollowupIntervalMs) {
      this.setStateValue('channelFollowupIntervalMs', String((body as any).channelFollowupIntervalMs));
    }

    // Initialize idle tracking
    this.setStateValue('lastUserActivityAt', String(Date.now()));

    // If sandbox info was provided directly, we're already running
    if (body.sandboxId && body.tunnelUrls) {
      this.setStateValue('status', 'running');
      this.markRunningStarted();
      updateSessionStatus(this.env.DB, body.sessionId, 'running', body.sandboxId).catch((err) =>
        console.error('[SessionAgentDO] Failed to sync status to D1:', err),
      );
      this.broadcastToClients({
        type: 'status',
        data: {
          status: 'running',
          sandboxRunning: true,
          tunnelUrls: body.tunnelUrls,
        },
      });
      this.rescheduleIdleAlarm();
    } else if (body.backendUrl && body.spawnRequest) {
      // Spawn sandbox asynchronously — return immediately, DO continues in background
      this.broadcastToClients({
        type: 'status',
        data: { status: 'initializing' },
      });
      this.ctx.waitUntil(this.spawnSandbox(body.backendUrl, body.terminateUrl!, body.spawnRequest));
    }

    // Publish session.started to EventBus
    this.notifyEventBus({
      type: 'session.started',
      sessionId: body.sessionId,
      userId: body.userId,
      data: { workspace: body.workspace, sandboxId: body.sandboxId },
      timestamp: new Date().toISOString(),
    });

    this.appendAuditLog('session.started', `Session started for ${body.workspace}`, body.userId);
    // Skip lifecycle notifications for orchestrator sessions — they restart
    // frequently and the noise isn't useful since the user explicitly triggers refreshes.
    if (!body.sessionId?.startsWith('orchestrator:')) {
      await this.enqueueOwnerNotification({
        messageType: 'notification',
        eventType: 'session.lifecycle',
        content: `Session started: ${body.workspace}`,
        contextSessionId: body.sessionId,
      });
    }

    return Response.json({
      success: true,
      status: 'initializing',
    });
  }

  /**
   * Spawn a sandbox via the Modal backend. Runs in the background via waitUntil()
   * so the Worker request can return immediately.
   */
  private async spawnSandbox(
    backendUrl: string,
    terminateUrl: string,
    spawnRequest: Record<string, unknown>,
  ): Promise<void> {
    const sessionId = this.getStateValue('sessionId');
    try {
      const response = await fetch(backendUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(spawnRequest),
      });

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`Backend returned ${response.status}: ${err}`);
      }

      const result = await response.json() as {
        sandboxId: string;
        tunnelUrls: Record<string, string>;
      };

      // Store sandbox info
      this.setStateValue('sandboxId', result.sandboxId);
      this.setStateValue('tunnelUrls', JSON.stringify(result.tunnelUrls));
      this.setStateValue('status', 'running');
      this.markRunningStarted();

      // Sync status to D1 so sessions list shows correct status
      updateSessionStatus(this.env.DB, sessionId!, 'running', result.sandboxId).catch((err) =>
        console.error('[SessionAgentDO] Failed to sync status to D1:', err),
      );

      // Notify connected clients that sandbox is ready
      this.broadcastToClients({
        type: 'status',
        data: {
          status: 'running',
          sandboxRunning: true,
          tunnelUrls: result.tunnelUrls,
        },
      });

      this.rescheduleIdleAlarm();
      console.log(`[SessionAgentDO] Sandbox spawned: ${result.sandboxId} for session ${sessionId}`);
    } catch (err) {
      console.error(`[SessionAgentDO] Failed to spawn sandbox for session ${sessionId}:`, err);
      const errorText = `Failed to create sandbox: ${err instanceof Error ? err.message : String(err)}`;
      this.setStateValue('status', 'error');
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'error', undefined, errorText).catch((e) =>
          console.error('[SessionAgentDO] Failed to sync error status to D1:', e),
        );
      }
      // Persist error as a system message so it's visible on reconnect
      const errId = crypto.randomUUID();
      this.ctx.storage.sql.exec(
        'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
        errId, 'system', `Error: ${errorText}`
      );
      this.broadcastToClients({
        type: 'status',
        data: { status: 'error' },
      });
      this.broadcastToClients({
        type: 'error',
        messageId: errId,
        error: errorText,
      });

      // Publish session.errored to EventBus
      this.notifyEventBus({
        type: 'session.errored',
        sessionId: sessionId || undefined,
        userId: this.getStateValue('userId') || undefined,
        data: { error: err instanceof Error ? err.message : String(err) },
        timestamp: new Date().toISOString(),
      });
      await this.enqueueOwnerNotification({
        messageType: 'escalation',
        content: `Session failed to start: ${errorText}`,
        contextSessionId: sessionId || undefined,
      });
    }
  }

  private async handleStop(reason: string = 'user_stopped'): Promise<Response> {
    const sandboxId = this.getStateValue('sandboxId');
    const sessionId = this.getStateValue('sessionId');
    const terminateUrl = this.getStateValue('terminateUrl');
    const currentStatus = this.getStateValue('status');

    // Flush active time, metrics, and messages to D1 before termination
    if (currentStatus === 'running') {
      await this.flushActiveSeconds();
      this.clearRunningStarted();
    }
    await this.flushMetrics();
    await this.flushMessagesToD1();

    // Tell runner to stop
    this.sendToRunner({ type: 'stop' });

    // Close all runner connections
    const runnerSockets = this.ctx.getWebSockets('runner');
    for (const ws of runnerSockets) {
      try {
        ws.close(1000, 'Session terminated');
      } catch {
        // ignore
      }
    }

    // Cascade: terminate all active child sessions (best-effort)
    if (sessionId) {
      try {
        const { children } = await getChildSessions(this.env.DB, sessionId);
        const activeChildren = children.filter(
          (c) => c.status !== 'terminated' && c.status !== 'archived',
        );
        await Promise.allSettled(
          activeChildren.map(async (child) => {
            try {
              const childDoId = this.env.SESSIONS.idFromName(child.id);
              const childDO = this.env.SESSIONS.get(childDoId);
              await childDO.fetch(new Request('http://do/stop', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ reason: 'parent_stopped' }),
              }));
              console.log(`[SessionAgentDO] Cascade-terminated child ${child.id}`);
            } catch (err) {
              console.error(`[SessionAgentDO] Failed to cascade-terminate child ${child.id}:`, err);
            }
          }),
        );
      } catch (err) {
        console.error('[SessionAgentDO] Failed to fetch child sessions for cascade:', err);
      }
    }

    // Only terminate sandbox if it's actually running (not hibernated/hibernating)
    if (currentStatus !== 'hibernated' && currentStatus !== 'hibernating') {
      if (sandboxId && terminateUrl) {
        try {
          await fetch(terminateUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ sandboxId }),
          });
        } catch (err) {
          console.error('Failed to terminate sandbox:', err);
        }
      }
    }

    // Clear idle alarm
    this.ctx.storage.deleteAlarm();

    // Update state
    this.setStateValue('status', 'terminated');
    this.setStateValue('sandboxId', '');
    this.setStateValue('tunnelUrls', '');
    this.setStateValue('tunnels', '');
    this.setStateValue('snapshotImageId', '');
    this.setStateValue('runnerBusy', 'false');
    this.ctx.storage.sql.exec('DELETE FROM prompt_queue');

    // Sync status to D1
    if (sessionId) {
      updateSessionStatus(this.env.DB, sessionId, 'terminated').catch((e) =>
        console.error('[SessionAgentDO] Failed to sync terminated status to D1:', e),
      );
    }

    // Notify clients
    this.broadcastToClients({
      type: 'status',
      data: { status: 'terminated', sandboxRunning: false },
    });

    this.appendAuditLog('session.terminated', 'Session terminated');

    // Publish session.completed to EventBus
    this.notifyEventBus({
      type: 'session.completed',
      sessionId: sessionId || undefined,
      userId: this.getStateValue('userId') || undefined,
      data: { sandboxId: sandboxId || null, reason },
      timestamp: new Date().toISOString(),
    });
    if (!sessionId?.startsWith('orchestrator:')) {
      await this.enqueueOwnerNotification({
        messageType: 'notification',
        eventType: 'session.lifecycle',
        content: `Session completed (${reason}).`,
        contextSessionId: sessionId || undefined,
      });
    }

    await this.notifyParentEvent(`Child session event: ${sessionId} completed (reason: ${reason}).`, { wake: true });

    return Response.json({
      success: true,
      status: 'terminated',
      sandboxId,
      sessionId,
    });
  }

  private async handleStatus(): Promise<Response> {
    const status = this.getStateValue('status') || 'idle';
    const sandboxId = this.getStateValue('sandboxId');
    const sessionId = this.getStateValue('sessionId');
    const userId = this.getStateValue('userId');
    const workspace = this.getStateValue('workspace');
    const tunnelUrls = this.getStateValue('tunnelUrls');
    const tunnelsRaw = this.getStateValue('tunnels');
    const runnerBusy = this.getStateValue('runnerBusy') === 'true';

    const messageCount = this.ctx.storage.sql
      .exec('SELECT COUNT(*) as count FROM messages')
      .toArray()[0]?.count ?? 0;

    const queueLength = this.getQueueLength();
    const clientCount = this.getClientSockets().length;
    const runnerConnected = this.ctx.getWebSockets('runner').length > 0;
    const connectedUsers = this.getConnectedUserIds();
    const runningStartedAt = this.getStateValue('runningStartedAt');

    let tunnelUrlsParsed: Record<string, string> | null = null;
    if (tunnelUrls) {
      try {
        tunnelUrlsParsed = JSON.parse(tunnelUrls);
      } catch {
        tunnelUrlsParsed = null;
      }
    }

    let tunnelsParsed: Array<{ name: string; port: number; protocol?: string; path: string }> | null = null;
    if (tunnelsRaw) {
      try {
        tunnelsParsed = JSON.parse(tunnelsRaw);
      } catch {
        tunnelsParsed = null;
      }
    }
    const gatewayUrl = tunnelUrlsParsed?.gateway;
    const tunnels = Array.isArray(tunnelsParsed)
      ? tunnelsParsed.map((t) => ({
        ...t,
        url: gatewayUrl ? `${gatewayUrl}${t.path}` : undefined,
      }))
      : null;
    const runtimeStates = deriveRuntimeStates({
      lifecycleStatus: status,
      sandboxId: sandboxId || null,
      runnerConnected,
      runnerBusy,
      queuedPrompts: queueLength,
    });

    return Response.json({
      sessionId,
      userId,
      workspace,
      status,
      lifecycleStatus: status,
      sandboxId: sandboxId || null,
      tunnelUrls: tunnelUrlsParsed,
      tunnels,
      runnerConnected,
      runnerBusy,
      agentState: runtimeStates.agentState,
      sandboxState: runtimeStates.sandboxState,
      jointState: runtimeStates.jointState,
      messageCount,
      queuedPrompts: queueLength,
      connectedClients: clientCount,
      connectedUsers,
      runningStartedAt: runningStartedAt ? parseInt(runningStartedAt) : null,
    });
  }

  private async notifyParentIfIdle() {
    const sessionId = this.getStateValue('sessionId');
    if (!sessionId) return;
    const status = this.getStateValue('status');
    if (status !== 'running') return;
    const runnerBusy = this.getStateValue('runnerBusy') === 'true';
    const queued = this.getQueueLength();
    if (runnerBusy || queued > 0) return;

    const last = this.getStateValue('lastParentIdleNotice');
    if (last === 'true') return;
    this.setStateValue('lastParentIdleNotice', 'true');
    await this.notifyParentEvent(`Child session event: ${sessionId} is idle.`, { wake: true });
  }

  private async notifyParentEvent(content: string, options?: { wake?: boolean }) {
    try {
      const sessionId = this.getStateValue('sessionId');
      if (!sessionId) return;
      const session = await getSession(this.env.DB, sessionId);
      const parentSessionId = session?.parentSessionId;
      if (!parentSessionId) return;
      const childTitle = session?.title || session?.workspace || `Child ${sessionId.slice(0, 8)}`;
      const parentDoId = this.env.SESSIONS.idFromName(parentSessionId);
      const parentDO = this.env.SESSIONS.get(parentDoId);
      await parentDO.fetch(new Request('http://do/system-message', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          content,
          parts: {
            systemTitle: childTitle,
            systemAvatarKey: 'child-session',
          },
          wake: options?.wake ?? true,
        }),
      }));
    } catch (err) {
      console.error('[SessionAgentDO] Failed to notify parent session:', err);
    }
  }

  private async handleSystemMessage(content: string, parts?: Record<string, unknown>, wake?: boolean) {
    const messageId = crypto.randomUUID();
    const serializedParts = parts ? JSON.stringify(parts) : null;

    if (serializedParts) {
      this.ctx.storage.sql.exec(
        'INSERT INTO messages (id, role, content, parts) VALUES (?, ?, ?, ?)',
        messageId, 'system', content, serializedParts
      );
    } else {
      this.ctx.storage.sql.exec(
        'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
        messageId, 'system', content
      );
    }

    this.broadcastToClients({
      type: 'message',
      data: {
        id: messageId,
        role: 'system',
        content,
        parts: parts || undefined,
        createdAt: Math.floor(Date.now() / 1000),
      },
    });

    if (wake) {
      const status = this.getStateValue('status');
      if (status === 'hibernated') {
        // Queue the prompt so the runner picks it up after connecting.
        // performWake() does NOT dequeue — upgradeRunner() does when the runner connects.
        this.ctx.storage.sql.exec(
          "INSERT INTO prompt_queue (id, content, status) VALUES (?, ?, 'queued')",
          messageId, content
        );
        this.ctx.waitUntil(this.performWake());
      } else if (status === 'restoring') {
        // Wake already in progress — just queue the prompt for when the runner connects.
        this.ctx.storage.sql.exec(
          "INSERT INTO prompt_queue (id, content, status) VALUES (?, ?, 'queued')",
          messageId, content
        );
      } else if (status === 'running') {
        // Dispatch the system event as a prompt so the runner wakes up and can
        // decide whether to act on it (e.g. child session idle/completed events).
        const runnerBusy = this.getStateValue('runnerBusy') === 'true';
        const runnerSockets = this.ctx.getWebSockets('runner');
        if (runnerSockets.length > 0 && !runnerBusy) {
          // Runner is connected and idle — insert as 'processing' for recoverability, then dispatch
          this.ctx.storage.sql.exec(
            "INSERT INTO prompt_queue (id, content, status) VALUES (?, ?, 'processing')",
            messageId, content
          );
          this.setStateValue('runnerBusy', 'true');
          const ownerId = this.getStateValue('userId');
          const ownerDetails = ownerId ? await this.getUserDetails(ownerId) : undefined;
          const sysModelPrefs = await this.resolveModelPreferences(ownerDetails);
          const sysChannelKey = this.channelKeyFrom(undefined, undefined);
          const sysOcSessionId = this.getChannelOcSessionId(sysChannelKey);
          this.sendToRunner({
            type: 'prompt',
            messageId,
            content,
            opencodeSessionId: sysOcSessionId,
            modelPreferences: sysModelPrefs,
          });
        } else {
          // Runner busy or not connected — queue the prompt
          this.ctx.storage.sql.exec(
            "INSERT INTO prompt_queue (id, content, status) VALUES (?, ?, 'queued')",
            messageId, content
          );
        }
      }
    }
  }

  private async handleWorkflowExecuteDispatch(
    executionIdRaw?: string,
    payload?: WorkflowExecutionDispatchPayload,
  ): Promise<Response> {
    const executionId = (executionIdRaw || '').trim();
    if (!executionId) {
      return Response.json({ error: 'executionId is required' }, { status: 400 });
    }
    if (!payload || typeof payload !== 'object') {
      return Response.json({ error: 'payload is required' }, { status: 400 });
    }
    if (payload.kind !== 'run' && payload.kind !== 'resume') {
      return Response.json({ error: 'payload.kind must be run or resume' }, { status: 400 });
    }
    if (typeof payload.executionId !== 'string' || payload.executionId !== executionId) {
      return Response.json({ error: 'payload.executionId must match executionId' }, { status: 400 });
    }
    if (!payload.payload || typeof payload.payload !== 'object' || Array.isArray(payload.payload)) {
      return Response.json({ error: 'payload.payload must be an object' }, { status: 400 });
    }

    const status = this.getStateValue('status');
    const queueWorkflowDispatch = (reason: string) => {
      const queueId = crypto.randomUUID();
      this.ctx.storage.sql.exec(
        "INSERT INTO prompt_queue (id, content, queue_type, workflow_execution_id, workflow_payload, status) VALUES (?, '', 'workflow_execute', ?, ?, 'queued')",
        queueId,
        executionId,
        JSON.stringify(payload),
      );
      this.appendAuditLog(
        'workflow.dispatch_queued',
        `Workflow execution queued (${executionId.slice(0, 8)}): ${reason}`,
        undefined,
        { executionId, kind: payload.kind, reason },
      );
      return Response.json({ success: true, queued: true, reason }, { status: 202 });
    };

    if (status === 'hibernated') {
      this.ctx.waitUntil(this.performWake());
      return queueWorkflowDispatch('session_hibernated_waking');
    }
    if (status === 'restoring' || status === 'initializing' || status === 'hibernating') {
      return queueWorkflowDispatch(`session_not_ready:${status}`);
    }

    const runnerSockets = this.ctx.getWebSockets('runner');
    if (runnerSockets.length === 0) {
      return queueWorkflowDispatch('runner_not_connected');
    }

    const runnerBusy = this.getStateValue('runnerBusy') === 'true';
    if (runnerBusy) {
      return queueWorkflowDispatch('runner_busy');
    }

    this.setStateValue('lastUserActivityAt', String(Date.now()));
    this.rescheduleIdleAlarm();
    this.setStateValue('runnerBusy', 'true');
    this.setStateValue('lastParentIdleNotice', '');
    const dispatchOwnerId = this.getStateValue('userId');
    const dispatchOwnerDetails = dispatchOwnerId ? await this.getUserDetails(dispatchOwnerId) : undefined;
    const dispatchModelPrefs = await this.resolveModelPreferences(dispatchOwnerDetails);

    this.sendToRunner({
      type: 'workflow-execute',
      executionId,
      payload,
      modelPreferences: dispatchModelPrefs,
    });

    this.appendAuditLog(
      'workflow.dispatch',
      `Workflow execution dispatched (${executionId.slice(0, 8)})`,
      undefined,
      { executionId, kind: payload.kind },
    );

    return Response.json({ success: true });
  }

  private async sendNextQueuedPrompt(): Promise<boolean> {
    const runnerSockets = this.ctx.getWebSockets('runner');
    if (runnerSockets.length === 0) return false;

    const next = this.ctx.storage.sql
      .exec("SELECT id, content, attachments, model, author_id, author_email, author_name, channel_type, channel_id, queue_type, workflow_execution_id, workflow_payload FROM prompt_queue WHERE status = 'queued' ORDER BY created_at ASC LIMIT 1")
      .toArray();

    if (next.length === 0) return false;

    const prompt = next[0];
    this.ctx.storage.sql.exec(
      "UPDATE prompt_queue SET status = 'processing' WHERE id = ?",
      prompt.id as string
    );

    const queueType = ((prompt.queue_type as string) || 'prompt').trim() || 'prompt';
    if (queueType === 'workflow_execute') {
      const queuedExecutionId = ((prompt.workflow_execution_id as string) || '').trim();
      const queuedPayload = parseQueuedWorkflowPayload(prompt.workflow_payload);
      if (!queuedExecutionId || !queuedPayload) {
        this.ctx.storage.sql.exec(
          "UPDATE prompt_queue SET status = 'completed' WHERE id = ?",
          prompt.id as string
        );
        console.warn(`[SessionAgentDO] Dropping malformed queued workflow dispatch id=${String(prompt.id)}`);
        return this.sendNextQueuedPrompt();
      }

      this.pendingChannelReply = null;
      this.setStateValue('runnerBusy', 'true');
      this.setStateValue('lastParentIdleNotice', '');
      const queueOwnerId = this.getStateValue('userId');
      const queueOwnerDetails = queueOwnerId ? await this.getUserDetails(queueOwnerId) : undefined;
      const queueModelPrefs = await this.resolveModelPreferences(queueOwnerDetails);
      this.sendToRunner({
        type: 'workflow-execute',
        executionId: queuedExecutionId,
        payload: queuedPayload,
        modelPreferences: queueModelPrefs,
      });
      this.broadcastToClients({
        type: 'status',
        data: { promptDequeued: true, remaining: this.getQueueLength() },
      });
      this.appendAuditLog(
        'workflow.dispatch',
        `Workflow execution dispatched (${queuedExecutionId.slice(0, 8)})`,
        undefined,
        { executionId: queuedExecutionId, kind: queuedPayload.kind, queued: true },
      );
      return true;
    }

    // Look up git details from cache for the prompt author
    const authorId = prompt.author_id as string | null;
    const authorDetails = authorId ? this.userDetailsCache.get(authorId) : undefined;
    const attachments = parseQueuedPromptAttachments(prompt.attachments);

    // Track current prompt author for PR attribution
    if (authorId) {
      this.setStateValue('currentPromptAuthorId', authorId);
    }

    // Track channel context for auto-reply on completion
    const queueChannelType = (prompt.channel_type as string) || undefined;
    const queueChannelId = (prompt.channel_id as string) || undefined;
    if (queueChannelType && queueChannelId) {
      this.pendingChannelReply = { channelType: queueChannelType, channelId: queueChannelId, resultContent: null, resultMessageId: null, handled: false };

      // Record a follow-up reminder so the agent gets nudged if it doesn't send a substantive reply
      this.insertChannelFollowup(queueChannelType, queueChannelId, prompt.content as string);
    } else {
      this.pendingChannelReply = null;
    }

    // Resolve model preferences from session owner (with org fallback)
    const queueOwnerId = this.getStateValue('userId');
    const queueOwnerDetails = queueOwnerId ? await this.getUserDetails(queueOwnerId) : undefined;
    const queueModelPrefs = await this.resolveModelPreferences(queueOwnerDetails);
    const queueChannelKey = this.channelKeyFrom(queueChannelType, queueChannelId);
    const queueOcSessionId = this.getChannelOcSessionId(queueChannelKey);
    this.sendToRunner({
      type: 'prompt',
      messageId: prompt.id as string,
      content: prompt.content as string,
      model: (prompt.model as string) || undefined,
      attachments: attachments.length > 0 ? attachments : undefined,
      channelType: queueChannelType,
      channelId: queueChannelId,
      authorId: authorId || undefined,
      authorEmail: (prompt.author_email as string) || undefined,
      authorName: (prompt.author_name as string) || undefined,
      gitName: authorDetails?.gitName,
      gitEmail: authorDetails?.gitEmail,
      opencodeSessionId: queueOcSessionId,
      modelPreferences: queueModelPrefs,
    });
    this.setStateValue('runnerBusy', 'true');
    this.broadcastToClients({
      type: 'status',
      data: { promptDequeued: true, remaining: this.getQueueLength() },
    });
    return true;
  }

  /**
   * HTTP endpoint: returns messages from this DO's local SQLite.
   * Used by other DOs for cross-session message reads.
   * Query params: limit (default 20), after (ISO timestamp cursor)
   */
  private handleMessagesEndpoint(url: URL): Response {
    const limit = parseInt(url.searchParams.get('limit') || '20', 10);
    const after = url.searchParams.get('after');

    let query: string;
    const params: (string | number)[] = [];

    if (after) {
      // Pagination: get messages after a cursor, oldest-first
      query = 'SELECT id, role, content, parts, created_at FROM messages WHERE created_at > ? ORDER BY created_at ASC LIMIT ?';
      params.push(after, limit);
    } else {
      // Default: get the MOST RECENT messages, returned in chronological order.
      // Subquery selects newest N rows (DESC), outer query re-sorts ASC.
      query = 'SELECT * FROM (SELECT id, role, content, parts, created_at FROM messages ORDER BY created_at DESC LIMIT ?) ORDER BY created_at ASC';
      params.push(limit);
    }

    const rows = this.ctx.storage.sql
      .exec(query, ...params)
      .toArray();

    const messages = rows.map((r) => ({
      id: r.id as string,
      role: r.role as string,
      content: r.content as string,
      parts: r.parts ? JSON.parse(r.parts as string) : undefined,
      createdAt: r.created_at as string,
    }));

    return Response.json({ messages });
  }


  private async handleClearQueue(): Promise<Response> {
    const cleared = this.getQueueLength();
    this.ctx.storage.sql.exec("DELETE FROM prompt_queue WHERE status = 'queued'");

    this.broadcastToClients({
      type: 'status',
      data: { queueCleared: true, cleared },
    });

    return Response.json({ success: true, cleared });
  }

  private async handleFlushMetrics(): Promise<Response> {
    await this.flushMetrics();
    return Response.json({ success: true });
  }

  private async handleGarbageCollect(): Promise<Response> {
    try {
      await this.flushMetrics();
    } catch (err) {
      console.error('[SessionAgentDO] Failed to flush metrics during GC:', err);
    }
    await this.ctx.storage.deleteAll();
    return Response.json({ success: true });
  }

  private async handleProxy(request: Request, url: URL): Promise<Response> {
    const tunnelUrlsRaw = this.getStateValue('tunnelUrls');
    if (!tunnelUrlsRaw) {
      return Response.json({ error: 'Sandbox not running' }, { status: 503 });
    }

    const tunnelUrls = JSON.parse(tunnelUrlsRaw);
    // Route through gateway's /opencode proxy to avoid Modal encrypted tunnel issues
    // on the direct OpenCode port. Fall back to direct opencode URL if gateway not available.
    const gatewayUrl = tunnelUrls.gateway;
    const opencodeUrl = tunnelUrls.opencode;
    const baseUrl = gatewayUrl ? `${gatewayUrl}/opencode` : opencodeUrl;
    if (!baseUrl) {
      return Response.json({ error: 'OpenCode URL not available' }, { status: 503 });
    }

    // Strip /proxy prefix
    const proxyPath = url.pathname.replace(/^\/proxy/, '') + url.search;
    const proxyUrl = baseUrl + proxyPath;

    try {
      const resp = await fetch(proxyUrl, {
        method: request.method,
        body: request.body,
      });
      return resp;
    } catch (error) {
      console.error('[SessionAgentDO] Proxy error:', proxyUrl, error);
      return Response.json({ error: 'Failed to reach sandbox' }, { status: 502 });
    }
  }

  // ─── Webhook Update Handler ────────────────────────────────────────────

  private async handleWebhookUpdate(request: Request): Promise<Response> {
    try {
      const body = await request.json() as {
        type: string;
        prState?: string;
        prTitle?: string;
        prUrl?: string;
        prMergedAt?: string | null;
        commitCount?: number;
        branch?: string;
      };

      // Broadcast git-state update to all connected clients
      this.broadcastToClients({
        type: 'git-state',
        data: {
          ...(body.prState !== undefined && { prState: body.prState }),
          ...(body.prTitle !== undefined && { prTitle: body.prTitle }),
          ...(body.prUrl !== undefined && { prUrl: body.prUrl }),
          ...(body.prMergedAt !== undefined && { prMergedAt: body.prMergedAt }),
          ...(body.commitCount !== undefined && { commitCount: body.commitCount }),
          ...(body.branch !== undefined && { branch: body.branch }),
        },
      });

      return new Response(JSON.stringify({ ok: true }), { status: 200 });
    } catch (err) {
      return new Response(JSON.stringify({ error: 'Invalid request' }), { status: 400 });
    }
  }

  // ─── GitHub API Helpers ──────────────────────────────────────────────

  /**
   * Get a decrypted GitHub access token for the session.
   * Fallback chain:
   *   1. Active prompt author's GitHub token (if they have one connected)
   *   2. Session creator's GitHub token
   *   3. null (no token available)
   */
  private async getGitHubToken(): Promise<string | null> {
    // Try the current prompt author first (for multiplayer attribution)
    const promptAuthorId = this.getStateValue('currentPromptAuthorId');
    if (promptAuthorId) {
      const authorToken = await getOAuthToken(this.env.DB, promptAuthorId, 'github');
      if (authorToken) {
        return decryptString(authorToken.encryptedAccessToken, this.env.ENCRYPTION_KEY);
      }
    }

    // Fall back to session creator
    const userId = this.getStateValue('userId');
    if (!userId) return null;

    const oauthToken = await getOAuthToken(this.env.DB, userId, 'github');
    if (!oauthToken) return null;

    return decryptString(oauthToken.encryptedAccessToken, this.env.ENCRYPTION_KEY);
  }

  /**
   * Extract owner/repo from a GitHub URL (https or git@ format).
   * Returns null if not a GitHub URL.
   */
  private extractOwnerRepo(repoUrl: string): { owner: string; repo: string } | null {
    const match = repoUrl.match(/github\.com[/:]([^/]+)\/([^/.]+)/);
    if (!match) return null;
    return { owner: match[1], repo: match[2] };
  }

  private async resolveOwnerRepo(owner?: string, repo?: string): Promise<{ owner: string; repo: string }> {
    if (owner && repo) {
      return { owner, repo };
    }

    const sessionId = this.getStateValue('sessionId');
    const gitState = sessionId ? await getSessionGitState(this.env.DB, sessionId) : null;
    const repoUrl = gitState?.sourceRepoUrl;
    if (!repoUrl) {
      throw new Error('No repository URL found for this session');
    }

    const ownerRepo = this.extractOwnerRepo(repoUrl);
    if (!ownerRepo) {
      throw new Error(`Cannot extract owner/repo from URL: ${repoUrl}`);
    }

    return ownerRepo;
  }

  // ─── PR Creation ──────────────────────────────────────────────────────

  private async handleCreatePR(msg: { requestId?: string; branch: string; title: string; body?: string; base?: string }) {
    const sessionId = this.getStateValue('sessionId');
    const requestId = msg.requestId;

    // Notify clients that PR creation is in progress
    this.broadcastToClients({
      type: 'status',
      data: { prCreating: true, branch: msg.branch },
    });

    try {
      const githubToken = await this.getGitHubToken();
      if (!githubToken) {
        throw new Error('No GitHub token found — user must connect GitHub in settings');
      }

      // Get repo URL from git state
      const gitState = sessionId ? await getSessionGitState(this.env.DB, sessionId) : null;
      const repoUrl = gitState?.sourceRepoUrl;
      if (!repoUrl) {
        throw new Error('No repository URL found for this session');
      }

      const ownerRepo = this.extractOwnerRepo(repoUrl);
      if (!ownerRepo) {
        throw new Error(`Cannot extract owner/repo from URL: ${repoUrl}`);
      }

      // Determine base branch
      let baseBranch = msg.base;
      if (!baseBranch) {
        // Fetch default branch from GitHub API
        const repoResp = await fetch(`https://api.github.com/repos/${ownerRepo.owner}/${ownerRepo.repo}`, {
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
          },
        });
        if (repoResp.ok) {
          const repoData = await repoResp.json() as { default_branch: string };
          baseBranch = repoData.default_branch;
        } else {
          baseBranch = 'main'; // fallback
        }
      }

      // Create PR via GitHub API
      const createResp = await fetch(`https://api.github.com/repos/${ownerRepo.owner}/${ownerRepo.repo}/pulls`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${githubToken}`,
          'Accept': 'application/vnd.github+json',
          'User-Agent': 'agent-ops',
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          title: msg.title,
          body: msg.body || '',
          head: msg.branch,
          base: baseBranch,
        }),
      });

      if (!createResp.ok) {
        const errBody = await createResp.text();
        throw new Error(`GitHub API returned ${createResp.status}: ${errBody}`);
      }

      const prData = await createResp.json() as { number: number; html_url: string; title: string; state: string };

      // Update D1 git state with PR info
      if (sessionId) {
        updateSessionGitState(this.env.DB, sessionId, {
          branch: msg.branch,
          baseBranch,
          prNumber: prData.number,
          prTitle: prData.title,
          prUrl: prData.html_url,
          prState: prData.state as any,
          prCreatedAt: new Date().toISOString(),
        }).catch((err) =>
          console.error('[SessionAgentDO] Failed to update git state after PR creation:', err),
        );
      }

      // Broadcast PR created to clients
      this.broadcastToClients({
        type: 'pr-created',
        data: {
          number: prData.number,
          title: prData.title,
          url: prData.html_url,
          state: prData.state,
        },
      } as any);

      // Send result back to runner
      if (requestId) {
        this.sendToRunner({
          type: 'create-pr-result',
          requestId,
          number: prData.number,
          url: prData.html_url,
          title: prData.title,
          state: prData.state,
        });
      }

      console.log(`[SessionAgentDO] PR #${prData.number} created: ${prData.html_url}`);
    } catch (err) {
      const errorText = err instanceof Error ? err.message : String(err);
      console.error('[SessionAgentDO] Failed to create PR:', errorText);

      // Send error result back to runner
      if (requestId) {
        this.sendToRunner({
          type: 'create-pr-result',
          requestId,
          error: errorText,
        });
      }

      // Broadcast failure to clients
      this.broadcastToClients({
        type: 'status',
        data: { prCreating: false, prError: errorText },
      });
    }
  }

  // ─── PR Update ────────────────────────────────────────────────────────

  private async handleUpdatePR(msg: { requestId?: string; prNumber: number; title?: string; body?: string; state?: string; labels?: string[] }) {
    const sessionId = this.getStateValue('sessionId');
    const requestId = msg.requestId;

    try {
      const githubToken = await this.getGitHubToken();
      if (!githubToken) {
        throw new Error('No GitHub token found — user must connect GitHub in settings');
      }

      // Get repo URL from git state
      const gitState = sessionId ? await getSessionGitState(this.env.DB, sessionId) : null;
      const repoUrl = gitState?.sourceRepoUrl;
      if (!repoUrl) {
        throw new Error('No repository URL found for this session');
      }

      const ownerRepo = this.extractOwnerRepo(repoUrl);
      if (!ownerRepo) {
        throw new Error(`Cannot extract owner/repo from URL: ${repoUrl}`);
      }

      // Update PR via GitHub API
      const updateBody: Record<string, unknown> = {};
      if (msg.title !== undefined) updateBody.title = msg.title;
      if (msg.body !== undefined) updateBody.body = msg.body;
      if (msg.state !== undefined) updateBody.state = msg.state;

      const patchResp = await fetch(`https://api.github.com/repos/${ownerRepo.owner}/${ownerRepo.repo}/pulls/${msg.prNumber}`, {
        method: 'PATCH',
        headers: {
          'Authorization': `Bearer ${githubToken}`,
          'Accept': 'application/vnd.github+json',
          'User-Agent': 'agent-ops',
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(updateBody),
      });

      if (!patchResp.ok) {
        const errBody = await patchResp.text();
        throw new Error(`GitHub API returned ${patchResp.status}: ${errBody}`);
      }

      const prData = await patchResp.json() as { number: number; html_url: string; title: string; state: string };

      // If labels were provided, set them via issues API
      if (msg.labels && msg.labels.length > 0) {
        await fetch(`https://api.github.com/repos/${ownerRepo.owner}/${ownerRepo.repo}/issues/${msg.prNumber}/labels`, {
          method: 'PUT',
          headers: {
            'Authorization': `Bearer ${githubToken}`,
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'agent-ops',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ labels: msg.labels }),
        }).catch((err) =>
          console.error('[SessionAgentDO] Failed to set labels:', err),
        );
      }

      // Update D1 git state
      if (sessionId) {
        const gitUpdates: Record<string, unknown> = {
          prTitle: prData.title,
          prState: prData.state,
        };
        updateSessionGitState(this.env.DB, sessionId, gitUpdates as any).catch((err) =>
          console.error('[SessionAgentDO] Failed to update git state after PR update:', err),
        );
      }

      // Broadcast update to clients
      this.broadcastToClients({
        type: 'pr-created',
        data: {
          number: prData.number,
          title: prData.title,
          url: prData.html_url,
          state: prData.state,
        },
      } as any);

      // Send result back to runner
      if (requestId) {
        this.sendToRunner({
          type: 'update-pr-result',
          requestId,
          number: prData.number,
          url: prData.html_url,
          title: prData.title,
          state: prData.state,
        });
      }

      console.log(`[SessionAgentDO] PR #${prData.number} updated: ${prData.html_url}`);
    } catch (err) {
      const errorText = err instanceof Error ? err.message : String(err);
      console.error('[SessionAgentDO] Failed to update PR:', errorText);

      if (requestId) {
        this.sendToRunner({
          type: 'update-pr-result',
          requestId,
          error: errorText,
        });
      }
    }
  }

  // ─── Hibernate / Wake ──────────────────────────────────────────────────

  private async handleHibernate(): Promise<Response> {
    const status = this.getStateValue('status');

    if (status === 'hibernated' || status === 'hibernating') {
      return Response.json({ status, message: 'Already hibernated or hibernating' });
    }

    if (status !== 'running') {
      return Response.json({ status, message: 'Can only hibernate a running session' });
    }

    this.ctx.waitUntil(this.performHibernate());
    return Response.json({ status: 'hibernating', message: 'Hibernate initiated' });
  }

  private async handleWake(): Promise<Response> {
    const status = this.getStateValue('status');

    if (status === 'running' || status === 'restoring') {
      return Response.json({ status, message: 'Already running or restoring' });
    }

    if (status === 'hibernated') {
      this.ctx.waitUntil(this.performWake());
      return Response.json({ status: 'restoring', message: 'Restore initiated' });
    }

    return Response.json({ status, message: 'Cannot wake from current status' });
  }

  private async performHibernate(): Promise<void> {
    const sessionId = this.getStateValue('sessionId');
    const sandboxId = this.getStateValue('sandboxId');
    const hibernateUrl = this.getStateValue('hibernateUrl');

    if (!sandboxId || !hibernateUrl) {
      console.error('[SessionAgentDO] Cannot hibernate: missing sandboxId or hibernateUrl');
      return;
    }

    try {
      // Flush active time and metrics to D1 before hibernate
      await this.flushActiveSeconds();
      this.clearRunningStarted();
      await this.flushMetrics();

      // Set status to hibernating
      this.setStateValue('status', 'hibernating');
      this.broadcastToClients({
        type: 'status',
        data: { status: 'hibernating' },
      });
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'hibernating').catch((e) =>
          console.error('[SessionAgentDO] Failed to sync hibernating status to D1:', e),
        );
      }

      // Call Modal backend to snapshot filesystem FIRST (while sandbox is still alive),
      // then terminate. We must NOT stop the runner before snapshotting — stopping the
      // runner causes the sandbox process to exit, making snapshot_filesystem fail with
      // "Sandbox has already finished".
      const response = await fetch(hibernateUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ sandboxId }),
      });

      if (response.status === 409) {
        // Sandbox already exited (idle timeout) — can't snapshot, treat as stopped
        console.log(`[SessionAgentDO] Session ${sessionId} sandbox already finished, marking as terminated`);
        this.sendToRunner({ type: 'stop' });
        const runnerSockets409 = this.ctx.getWebSockets('runner');
        for (const ws of runnerSockets409) {
          try { ws.close(1000, 'Sandbox already exited'); } catch { /* ignore */ }
        }
        this.setStateValue('sandboxId', '');
        this.setStateValue('tunnelUrls', '');
        this.setStateValue('tunnels', '');
        this.setStateValue('runnerBusy', 'false');
        this.setStateValue('status', 'terminated');
        this.broadcastToClients({
          type: 'status',
          data: { status: 'terminated', sandboxRunning: false },
        });
        if (sessionId) {
          updateSessionStatus(this.env.DB, sessionId, 'terminated').catch((e) =>
            console.error('[SessionAgentDO] Failed to sync terminated status to D1:', e),
          );
        }
        return;
      }

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`Backend returned ${response.status}: ${err}`);
      }

      const result = await response.json() as { snapshotImageId: string };

      // Now that snapshot is taken and sandbox terminated, stop runner and close connections
      this.sendToRunner({ type: 'stop' });
      const runnerSockets = this.ctx.getWebSockets('runner');
      for (const ws of runnerSockets) {
        try { ws.close(1000, 'Session hibernating'); } catch { /* ignore */ }
      }

      // Store snapshot info and clear sandbox info
      this.setStateValue('snapshotImageId', result.snapshotImageId);
      this.setStateValue('sandboxId', '');
      this.setStateValue('tunnelUrls', '');
      this.setStateValue('tunnels', '');
      this.setStateValue('runnerBusy', 'false');
      this.setStateValue('status', 'hibernated');

      this.broadcastToClients({
        type: 'status',
        data: { status: 'hibernated', sandboxRunning: false },
      });

      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'hibernated').catch((e) =>
          console.error('[SessionAgentDO] Failed to sync hibernated status to D1:', e),
        );
      }

      this.appendAuditLog('session.hibernated', 'Session hibernated');
      console.log(`[SessionAgentDO] Session ${sessionId} hibernated, snapshot: ${result.snapshotImageId}`);
    } catch (err) {
      console.error(`[SessionAgentDO] Failed to hibernate session ${sessionId}:`, err);
      const errorText = `Failed to hibernate: ${err instanceof Error ? err.message : String(err)}`;
      this.setStateValue('status', 'error');
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'error', undefined, errorText).catch((e) =>
          console.error('[SessionAgentDO] Failed to sync error status to D1:', e),
        );
      }
      // Persist error as a system message
      const errId = crypto.randomUUID();
      this.ctx.storage.sql.exec(
        'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
        errId, 'system', `Error: ${errorText}`
      );
      this.broadcastToClients({
        type: 'status',
        data: { status: 'error' },
      });
      this.broadcastToClients({
        type: 'error',
        messageId: errId,
        error: errorText,
      });
    }
  }

  private async performWake(): Promise<void> {
    // Guard against concurrent wake calls (e.g. two prompts arriving while hibernated)
    const currentStatus = this.getStateValue('status');
    if (currentStatus === 'restoring' || currentStatus === 'running') {
      console.log(`[SessionAgentDO] performWake skipped — already ${currentStatus}`);
      return;
    }

    const sessionId = this.getStateValue('sessionId');
    const snapshotImageId = this.getStateValue('snapshotImageId');
    const restoreUrl = this.getStateValue('restoreUrl');
    const spawnRequestStr = this.getStateValue('spawnRequest');

    if (!snapshotImageId || !restoreUrl || !spawnRequestStr) {
      const errorText = 'Cannot wake: missing snapshotImageId, restoreUrl, or spawnRequest';
      console.error(`[SessionAgentDO] ${errorText}`);
      this.setStateValue('status', 'error');
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'error', undefined, errorText).catch((e) =>
          console.error('[SessionAgentDO] Failed to sync error status to D1:', e),
        );
      }
      this.broadcastToClients({ type: 'status', data: { status: 'error' } });
      this.broadcastToClients({ type: 'error', error: errorText });
      return;
    }

    try {
      this.setStateValue('status', 'restoring');
      this.broadcastToClients({
        type: 'status',
        data: { status: 'restoring' },
      });
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'restoring').catch((e) =>
          console.error('[SessionAgentDO] Failed to sync restoring status to D1:', e),
        );
      }

      const spawnRequest = JSON.parse(spawnRequestStr);

      const response = await fetch(restoreUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          ...spawnRequest,
          snapshotImageId,
        }),
      });

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`Backend returned ${response.status}: ${err}`);
      }

      const result = await response.json() as {
        sandboxId: string;
        tunnelUrls: Record<string, string>;
      };

      // Update state with new sandbox info
      this.setStateValue('sandboxId', result.sandboxId);
      this.setStateValue('tunnelUrls', JSON.stringify(result.tunnelUrls));
      this.setStateValue('snapshotImageId', '');
      this.setStateValue('status', 'running');
      this.markRunningStarted();
      this.setStateValue('lastUserActivityAt', String(Date.now()));

      this.rescheduleIdleAlarm();

      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'running', result.sandboxId).catch((e) =>
          console.error('[SessionAgentDO] Failed to sync running status to D1:', e),
        );
      }

      this.broadcastToClients({
        type: 'status',
        data: {
          status: 'running',
          sandboxRunning: true,
          tunnelUrls: result.tunnelUrls,
        },
      });

      this.appendAuditLog('session.restored', 'Session restored from hibernation');
      console.log(`[SessionAgentDO] Session ${sessionId} restored, new sandbox: ${result.sandboxId}`);
    } catch (err) {
      console.error(`[SessionAgentDO] Failed to restore session ${sessionId}:`, err);
      const errorText = `Failed to restore session: ${err instanceof Error ? err.message : String(err)}`;
      this.setStateValue('status', 'error');
      if (sessionId) {
        updateSessionStatus(this.env.DB, sessionId, 'error', undefined, errorText).catch((e) =>
          console.error('[SessionAgentDO] Failed to sync error status to D1:', e),
        );
      }
      // Persist error as a system message
      const errId = crypto.randomUUID();
      this.ctx.storage.sql.exec(
        'INSERT INTO messages (id, role, content) VALUES (?, ?, ?)',
        errId, 'system', `Error: ${errorText}`
      );
      this.broadcastToClients({
        type: 'status',
        data: { status: 'error' },
      });
      this.broadcastToClients({
        type: 'error',
        messageId: errId,
        error: errorText,
      });
    }
  }

  /**
   * Schedule the idle alarm based on the configured idle timeout.
   * Called after any user activity and after sandbox transitions to running.
   */
  private rescheduleIdleAlarm(): void {
    const idleTimeoutMsStr = this.getStateValue('idleTimeoutMs');
    if (!idleTimeoutMsStr) return;

    const idleTimeoutMs = parseInt(idleTimeoutMsStr);
    if (isNaN(idleTimeoutMs) || idleTimeoutMs <= 0) return;

    // Schedule alarm for now + idle timeout
    // Note: this overwrites any existing alarm — we'll re-check question expiry in alarm() too
    const alarmTime = Date.now() + idleTimeoutMs;

    // But also consider pending question expiry — use the earliest time
    const nextExpiry = this.ctx.storage.sql
      .exec(
        "SELECT MIN(expires_at) as next FROM questions WHERE status = 'pending' AND expires_at IS NOT NULL"
      )
      .toArray();

    let earliestAlarm = alarmTime;
    if (nextExpiry.length > 0 && nextExpiry[0].next) {
      const questionExpiryMs = (nextExpiry[0].next as number) * 1000;
      if (questionExpiryMs < earliestAlarm) {
        earliestAlarm = questionExpiryMs;
      }
    }

    // Also consider pending channel followup reminders
    const nextFollowup = this.ctx.storage.sql
      .exec("SELECT MIN(next_reminder_at) as next FROM channel_followups WHERE status = 'pending'")
      .toArray();
    if (nextFollowup.length > 0 && nextFollowup[0].next) {
      const followupMs = nextFollowup[0].next as number;
      if (followupMs < earliestAlarm) {
        earliestAlarm = followupMs;
      }
    }

    this.ctx.storage.setAlarm(earliestAlarm);
  }

  // ─── Helpers ───────────────────────────────────────────────────────────

  private getStateValue(key: string): string | undefined {
    const rows = this.ctx.storage.sql
      .exec('SELECT value FROM state WHERE key = ?', key)
      .toArray();
    return rows.length > 0 ? (rows[0].value as string) : undefined;
  }

  private setStateValue(key: string, value: string): void {
    this.ctx.storage.sql.exec(
      'INSERT OR REPLACE INTO state (key, value) VALUES (?, ?)',
      key, value
    );
  }

  private getQueueLength(): number {
    const result = this.ctx.storage.sql
      .exec("SELECT COUNT(*) as count FROM prompt_queue WHERE status = 'queued'")
      .toArray();
    return (result[0]?.count as number) ?? 0;
  }

  private getClientSockets(): WebSocket[] {
    // Get all websockets, then filter to client-tagged ones
    const all = this.ctx.getWebSockets();
    return all.filter((ws) => {
      const tags = this.ctx.getTags(ws);
      return tags.some((t) => t.startsWith('client:'));
    });
  }

  private broadcastToClients(message: ClientOutbound): void {
    const payload = JSON.stringify(message);
    for (const ws of this.getClientSockets()) {
      try {
        ws.send(payload);
      } catch {
        // Socket may be closed
      }
    }
  }

  private getConnectedUserIds(): string[] {
    return this.ctx.storage.sql
      .exec('SELECT user_id FROM connected_users ORDER BY connected_at ASC')
      .toArray()
      .map((row) => row.user_id as string);
  }

  private isUserConnected(userId: string): boolean {
    return this.getConnectedUserIds().includes(userId);
  }

  private sendToastToUser(userId: string, toast: {
    title: string;
    description?: string;
    variant?: 'default' | 'success' | 'error' | 'warning';
    duration?: number;
  }): void {
    const sockets = this.ctx.getWebSockets(`client:${userId}`);
    if (sockets.length === 0) return;

    const payload = JSON.stringify({
      type: 'toast',
      title: toast.title,
      description: toast.description,
      variant: toast.variant,
      duration: toast.duration,
    });
    for (const ws of sockets) {
      try {
        ws.send(payload);
      } catch {
        // Socket may be closed
      }
    }
  }

  private async getConnectedUsersWithDetails(): Promise<Array<{ id: string; name?: string; email?: string; avatarUrl?: string }>> {
    const userIds = this.getConnectedUserIds();

    // Backfill cache for any users missing after hibernation
    const uncachedIds = userIds.filter((id) => !this.userDetailsCache.has(id));
    if (uncachedIds.length > 0) {
      try {
        const placeholders = uncachedIds.map(() => '?').join(',');
        const rows = await this.env.DB.prepare(
          `SELECT id, email, name, avatar_url, git_name, git_email, model_preferences FROM users WHERE id IN (${placeholders})`
        ).bind(...uncachedIds).all<{ id: string; email: string; name: string | null; avatar_url: string | null; git_name: string | null; git_email: string | null; model_preferences: string | null }>();
        for (const row of rows.results) {
          this.userDetailsCache.set(row.id, {
            id: row.id,
            email: row.email,
            name: row.name || undefined,
            avatarUrl: row.avatar_url || undefined,
            gitName: row.git_name || undefined,
            gitEmail: row.git_email || undefined,
            modelPreferences: row.model_preferences ? JSON.parse(row.model_preferences) : undefined,
          });
        }
      } catch (err) {
        console.error('Failed to backfill user details cache:', err);
      }
    }

    return userIds.map((id) => {
      const details = this.userDetailsCache.get(id);
      return {
        id,
        name: details?.name,
        email: details?.email,
        avatarUrl: details?.avatarUrl,
      };
    });
  }

  private notifyEventBus(event: {
    type: string;
    sessionId?: string;
    userId?: string;
    data: Record<string, unknown>;
    timestamp: string;
  }): void {
    // Fire-and-forget notification to EventBusDO
    try {
      const id = this.env.EVENT_BUS.idFromName('global');
      const stub = this.env.EVENT_BUS.get(id);
      stub.fetch(new Request('https://event-bus/publish', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          userId: event.userId,
          event,
        }),
      })).catch(() => {
        // Ignore EventBus errors — non-critical
      });
    } catch {
      // EventBus not available
    }
  }

  private async enqueueOwnerNotification(params: {
    messageType?: 'notification' | 'question' | 'escalation' | 'approval';
    eventType?: string;
    content: string;
    contextSessionId?: string;
    contextTaskId?: string;
    replyToId?: string;
  }): Promise<void> {
    const toUserId = this.getStateValue('userId');
    if (!toUserId) return;

    const normalizedContent = params.content.trim();
    if (!normalizedContent) return;

    try {
      const messageType = params.messageType || 'notification';
      const webEnabled = await isNotificationWebEnabled(
        this.env.DB,
        toUserId,
        messageType,
        params.eventType,
      );
      if (!webEnabled) return;

      await createMailboxMessage(this.env.DB, {
        fromSessionId: this.getStateValue('sessionId') || undefined,
        toUserId,
        messageType,
        content: normalizedContent.slice(0, 10_000),
        contextSessionId: params.contextSessionId,
        contextTaskId: params.contextTaskId,
        replyToId: params.replyToId,
      });
    } catch (err) {
      console.error('[SessionAgentDO] Failed to enqueue owner notification:', err);
    }
  }

  /**
   * Record that the sandbox just entered the 'running' state.
   * Stores a timestamp so we can later compute elapsed active seconds.
   */
  private markRunningStarted(): void {
    this.setStateValue('runningStartedAt', String(Date.now()));
  }

  /**
   * Flush accumulated active seconds to D1.
   * Called when leaving the 'running' state (hibernate, terminate, error).
   * Also called periodically from flushMetrics to avoid losing time if the DO restarts.
   */
  private async flushActiveSeconds(): Promise<void> {
    const sessionId = this.getStateValue('sessionId');
    const startStr = this.getStateValue('runningStartedAt');
    if (!sessionId || !startStr) return;

    const startMs = parseInt(startStr);
    if (isNaN(startMs)) return;

    const elapsedSeconds = Math.floor((Date.now() - startMs) / 1000);
    if (elapsedSeconds > 0) {
      try {
        await addActiveSeconds(this.env.DB, sessionId, elapsedSeconds);
      } catch (err) {
        console.error('[SessionAgentDO] Failed to flush active seconds:', err);
      }
    }
    // Reset the start marker to now so we don't double-count on next flush
    this.setStateValue('runningStartedAt', String(Date.now()));
  }

  /**
   * Clear the running start marker (when leaving running state permanently).
   */
  private clearRunningStarted(): void {
    this.setStateValue('runningStartedAt', '');
  }

  /**
   * Flush message/tool-call counts from local SQLite to D1.
   * Called at lifecycle boundaries (stop, hibernate, alarm) and after each agent turn.
   */
  private async flushMetrics(): Promise<void> {
    const sessionId = this.getStateValue('sessionId');
    if (!sessionId) return;

    try {
      const msgRow = this.ctx.storage.sql
        .exec('SELECT COUNT(*) as count FROM messages')
        .toArray()[0];
      const toolRow = this.ctx.storage.sql
        .exec("SELECT COUNT(*) as count FROM messages WHERE role = 'tool'")
        .toArray()[0];

      const messageCount = (msgRow?.count as number) ?? 0;
      const toolCallCount = (toolRow?.count as number) ?? 0;

      await updateSessionMetrics(this.env.DB, sessionId, { messageCount, toolCallCount });

      // Also flush active seconds if currently running
      const status = this.getStateValue('status');
      if (status === 'running') {
        await this.flushActiveSeconds();
      }

      // Flush unflushed audit log entries to D1
      const unflushed = this.ctx.storage.sql
        .exec('SELECT id, event_type, summary, actor_id, metadata, created_at FROM audit_log WHERE flushed = 0 ORDER BY id ASC LIMIT 50')
        .toArray();

      if (unflushed.length > 0) {
        const stmts = unflushed.map((row) =>
          this.env.DB.prepare(
            'INSERT OR IGNORE INTO session_audit_log (id, session_id, event_type, summary, actor_id, metadata, created_at, flushed_at) VALUES (?, ?, ?, ?, ?, ?, ?, datetime(\'now\'))'
          ).bind(
            `${sessionId}:${row.id}`,
            sessionId,
            row.event_type as string,
            row.summary as string,
            (row.actor_id as string) || null,
            (row.metadata as string) || null,
            row.created_at as string,
          )
        );
        try {
          await this.env.DB.batch(stmts);
          // Mark as flushed
          const flushedIds = unflushed.map((r) => r.id as number);
          const placeholders = flushedIds.map(() => '?').join(',');
          this.ctx.storage.sql.exec(
            `UPDATE audit_log SET flushed = 1 WHERE id IN (${placeholders})`,
            ...flushedIds,
          );
        } catch (flushErr) {
          console.error('[SessionAgentDO] Failed to flush audit log to D1:', flushErr);
        }
      }
    } catch (err) {
      console.error('[SessionAgentDO] Failed to flush metrics:', err);
    }
  }

  private appendAuditLog(
    eventType: string,
    summary: string,
    actorId?: string,
    metadata?: Record<string, unknown>,
  ): void {
    const metadataJson = metadata ? JSON.stringify(metadata) : null;
    this.ctx.storage.sql.exec(
      'INSERT INTO audit_log (event_type, summary, actor_id, metadata) VALUES (?, ?, ?, ?)',
      eventType, summary, actorId || null, metadataJson,
    );
    // Broadcast to connected clients in real-time
    this.broadcastToClients({
      type: 'audit_log',
      entry: {
        eventType,
        summary,
        actorId: actorId || undefined,
        metadata: metadata || undefined,
        createdAt: new Date().toISOString(),
      },
    });
  }

  private async handleTunnelDelete(
    name: string,
    actor?: { actorId?: string; actorName?: string; actorEmail?: string },
  ) {
    if (!name) return;

    this.sendToRunner({
      type: 'tunnel-delete',
      name,
      actorId: actor?.actorId,
      actorName: actor?.actorName,
      actorEmail: actor?.actorEmail,
    });

    const who = actor?.actorName || actor?.actorEmail || actor?.actorId || 'User';
    const summary = `${who} disabled tunnel "${name}"`;
    this.appendAuditLog('tunnel.disabled', summary, actor?.actorId, { name });
    await this.handleSystemMessage(summary, { type: 'tunnel.disabled', name });
  }

  // ─── Phase C: Mailbox + Task Board Handlers ─────────────────────────

  private async handleMailboxSend(requestId: string, msg: RunnerMessage) {
    try {
      const sessionId = this.getStateValue('sessionId');
      const userId = this.getStateValue('userId');

      // Resolve @handle to userId if provided
      let toUserId = msg.toUserId;
      if (msg.toHandle && !toUserId && !msg.toSessionId) {
        const identity = await getOrchestratorIdentityByHandle(this.env.DB, msg.toHandle);
        if (!identity) {
          this.sendToRunner({ type: 'mailbox-send-result', requestId, error: `Handle @${msg.toHandle} not found` } as any);
          return;
        }
        toUserId = identity.userId;
      }

      const message = await createMailboxMessage(this.env.DB, {
        fromSessionId: sessionId || undefined,
        fromUserId: userId || undefined,
        toSessionId: msg.toSessionId,
        toUserId,
        messageType: msg.messageType,
        content: msg.content!,
        contextSessionId: msg.contextSessionId,
        contextTaskId: msg.contextTaskId,
        replyToId: msg.replyToId,
      });

      this.sendToRunner({ type: 'mailbox-send-result', requestId, messageId: message.id } as any);
    } catch (err) {
      this.sendToRunner({ type: 'mailbox-send-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleMailboxCheck(requestId: string, limit?: number, after?: string) {
    try {
      const sessionId = this.getStateValue('sessionId');
      if (!sessionId) {
        this.sendToRunner({ type: 'mailbox-check-result', requestId, error: 'No session ID' } as any);
        return;
      }

      const messages = await getSessionMailbox(this.env.DB, sessionId, {
        unreadOnly: true,
        limit,
        after,
      });

      // Auto-mark as read
      if (messages.length > 0) {
        await markSessionMailboxRead(this.env.DB, sessionId);
      }

      this.sendToRunner({ type: 'mailbox-check-result', requestId, messages } as any);
    } catch (err) {
      this.sendToRunner({ type: 'mailbox-check-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleTaskCreate(requestId: string, msg: RunnerMessage) {
    try {
      const sessionId = this.getStateValue('sessionId');
      if (!sessionId) {
        this.sendToRunner({ type: 'task-create-result', requestId, error: 'No session ID' } as any);
        return;
      }

      // Determine orchestrator session ID: own session for orchestrators,
      // or look up parent for child sessions
      let orchestratorSessionId = sessionId;
      const session = await getSession(this.env.DB, sessionId);
      if (session?.parentSessionId) {
        orchestratorSessionId = session.parentSessionId;
      }

      const task = await createSessionTask(this.env.DB, {
        orchestratorSessionId,
        sessionId: msg.sessionId,
        title: msg.title!,
        description: msg.description,
        parentTaskId: msg.parentTaskId,
        blockedBy: msg.blockedBy,
      });

      this.sendToRunner({ type: 'task-create-result', requestId, task } as any);
    } catch (err) {
      this.sendToRunner({ type: 'task-create-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleTaskList(requestId: string, status?: string, limit?: number) {
    try {
      const sessionId = this.getStateValue('sessionId');
      if (!sessionId) {
        this.sendToRunner({ type: 'task-list-result', requestId, error: 'No session ID' } as any);
        return;
      }

      let orchestratorSessionId = sessionId;
      const session = await getSession(this.env.DB, sessionId);
      if (session?.parentSessionId) {
        orchestratorSessionId = session.parentSessionId;
      }

      const tasks = await getSessionTasks(this.env.DB, orchestratorSessionId, { status, limit });
      this.sendToRunner({ type: 'task-list-result', requestId, tasks } as any);
    } catch (err) {
      this.sendToRunner({ type: 'task-list-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleTaskUpdate(requestId: string, taskId: string, msg: RunnerMessage) {
    try {
      const task = await updateSessionTask(this.env.DB, taskId, {
        status: msg.status as string | undefined,
        result: msg.result as string | undefined,
        description: msg.description,
        sessionId: msg.sessionId,
        title: msg.title,
      });

      if (!task) {
        this.sendToRunner({ type: 'task-update-result', requestId, error: 'Task not found' } as any);
        return;
      }

      this.sendToRunner({ type: 'task-update-result', requestId, task } as any);
    } catch (err) {
      this.sendToRunner({ type: 'task-update-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  private async handleTaskMy(requestId: string, status?: string) {
    try {
      const sessionId = this.getStateValue('sessionId');
      if (!sessionId) {
        this.sendToRunner({ type: 'task-my-result', requestId, error: 'No session ID' } as any);
        return;
      }

      const tasks = await getMyTasks(this.env.DB, sessionId, { status });
      this.sendToRunner({ type: 'task-my-result', requestId, tasks } as any);
    } catch (err) {
      this.sendToRunner({ type: 'task-my-result', requestId, error: err instanceof Error ? err.message : String(err) } as any);
    }
  }

  // ─── Phase D: Channel Reply Handler ──────────────────────────────────

  private async handleChannelReply(requestId: string, channelType: string, channelId: string, message: string, imageBase64?: string, imageMimeType?: string, followUp?: boolean) {
    try {
      const userId = this.getStateValue('userId');
      if (!userId) {
        this.sendToRunner({ type: 'channel-reply-result', requestId, error: 'No userId on session' } as any);
        return;
      }

      switch (channelType) {
        case 'telegram': {
          const telegramData = await getUserTelegramToken(this.env.DB, userId, this.env.ENCRYPTION_KEY);
          if (!telegramData) {
            this.sendToRunner({ type: 'channel-reply-result', requestId, error: 'No Telegram config for user' } as any);
            return;
          }
          let ok: boolean;
          if (imageBase64) {
            ok = await sendTelegramPhoto(
              telegramData.botToken, channelId, imageBase64,
              imageMimeType || 'image/jpeg', message || undefined,
            );
          } else {
            ok = await sendTelegramMessage(telegramData.botToken, channelId, message);
          }
          if (!ok) {
            this.sendToRunner({ type: 'channel-reply-result', requestId, error: 'Telegram API error' } as any);
            return;
          }

          // Mark auto-reply as handled so we don't double-send on complete
          if (this.pendingChannelReply
            && this.pendingChannelReply.channelType === channelType
            && this.pendingChannelReply.channelId === channelId) {
            this.pendingChannelReply.handled = true;
          }

          // Resolve follow-up reminder if this is a substantive reply (followUp !== false)
          if (followUp !== false) {
            this.resolveChannelFollowups(channelType, channelId);
          }

          this.sendToRunner({ type: 'channel-reply-result', requestId, success: true } as any);
          break;
        }
        default:
          this.sendToRunner({ type: 'channel-reply-result', requestId, error: `Unsupported channel type: ${channelType}` } as any);
      }

      // Store image as a system message for web UI visibility
      if (imageBase64) {
        const msgId = crypto.randomUUID();
        const channelLabel = `Sent image to ${channelType}`;
        this.ctx.storage.sql.exec(
          'INSERT INTO messages (id, role, content, parts, channel_type, channel_id) VALUES (?, ?, ?, ?, ?, ?)',
          msgId, 'system', message || channelLabel,
          JSON.stringify({ type: 'image', data: imageBase64, mimeType: imageMimeType || 'image/jpeg' }),
          channelType, channelId,
        );
        this.broadcastToClients({
          type: 'message',
          data: {
            id: msgId,
            role: 'system',
            content: message || channelLabel,
            parts: { type: 'image', data: imageBase64, mimeType: imageMimeType || 'image/jpeg' },
            createdAt: Math.floor(Date.now() / 1000),
            channelType,
            channelId,
          },
        });
      }
    } catch (err) {
      this.sendToRunner({
        type: 'channel-reply-result',
        requestId,
        error: err instanceof Error ? err.message : String(err),
      } as any);
    }
  }

  /**
   * Auto-send the agent's result text to the originating channel if the agent
   * didn't explicitly call channel_reply during this prompt cycle.
   * On success, stamps the assistant message with channel metadata so the
   * web UI can show a "sent to <channel>" badge.
   */
  private async flushPendingChannelReply() {
    const pending = this.pendingChannelReply;
    if (!pending || pending.handled || !pending.resultContent) {
      this.pendingChannelReply = null;
      return;
    }
    this.pendingChannelReply = null;

    const userId = this.getStateValue('userId');
    if (!userId) return;

    let sent = false;
    try {
      switch (pending.channelType) {
        case 'telegram': {
          const telegramData = await getUserTelegramToken(this.env.DB, userId, this.env.ENCRYPTION_KEY);
          if (!telegramData) {
            console.log('[SessionAgentDO] Auto channel reply: no Telegram config, skipping');
            return;
          }
          const ok = await sendTelegramMessage(telegramData.botToken, pending.channelId, pending.resultContent);
          if (ok) {
            console.log(`[SessionAgentDO] Auto channel reply sent to ${pending.channelType}:${pending.channelId}`);
            sent = true;
          } else {
            console.error(`[SessionAgentDO] Auto channel reply failed for ${pending.channelType}:${pending.channelId}`);
          }
          break;
        }
        default:
          console.log(`[SessionAgentDO] Auto channel reply: unsupported channel type ${pending.channelType}`);
      }
    } catch (err) {
      console.error('[SessionAgentDO] Auto channel reply error:', err);
    }

    // Auto-reply counts as a substantive reply — resolve any pending followup reminders
    if (sent) {
      this.resolveChannelFollowups(pending.channelType, pending.channelId);
    }

    // Stamp the assistant message with channel metadata so the UI shows a badge
    if (sent && pending.resultMessageId) {
      this.ctx.storage.sql.exec(
        'UPDATE messages SET channel_type = ?, channel_id = ? WHERE id = ?',
        pending.channelType, pending.channelId, pending.resultMessageId,
      );
      this.broadcastToClients({
        type: 'message.updated',
        data: {
          id: pending.resultMessageId,
          role: 'assistant',
          content: pending.resultContent,
          channelType: pending.channelType,
          channelId: pending.channelId,
          createdAt: Math.floor(Date.now() / 1000),
        },
      });
    }
  }

  // ─── Channel Follow-up Helpers ─────────────────────────────────────

  private requiresExplicitChannelReply(channelType?: string): boolean {
    return !!channelType && channelType !== 'web';
  }

  private insertChannelFollowup(channelType: string, channelId: string, content: string): void {
    if (!this.requiresExplicitChannelReply(channelType)) {
      return;
    }

    const id = crypto.randomUUID();
    const now = Date.now();
    const intervalMs = parseInt(this.getStateValue('channelFollowupIntervalMs') || '300000');
    const truncated = (content || '').slice(0, 200);

    this.ctx.storage.sql.exec(
      'INSERT INTO channel_followups (id, channel_type, channel_id, original_content, created_at, next_reminder_at, reminder_count, status) VALUES (?, ?, ?, ?, ?, ?, 0, ?)',
      id, channelType, channelId, truncated, now, now + intervalMs, 'pending'
    );

    // Ensure the alarm is scheduled to cover this new followup
    this.rescheduleIdleAlarm();
  }

  private resolveChannelFollowups(channelType: string, channelId: string): void {
    this.ctx.storage.sql.exec(
      "UPDATE channel_followups SET status = 'resolved' WHERE status = 'pending' AND channel_type = ? AND channel_id = ?",
      channelType, channelId
    );
  }

  private sendToRunner(message: RunnerOutbound): void {
    const runners = this.ctx.getWebSockets('runner');
    const payload = JSON.stringify(message);
    for (const ws of runners) {
      try {
        ws.send(payload);
      } catch {
        // Runner may have disconnected
      }
    }
  }
}
